# anndata

[üîô Back to Main Repo](../../../README.md) | [üîó Original Repo](https://github.com/scverse/anndata)

![Tool Count](https://img.shields.io/badge/Agent_Tools-8-blue?style=flat-square)
![Category](https://img.shields.io/badge/Category-Biology-green?style=flat-square)
![Status](https://img.shields.io/badge/Import_Test-Passed-success?style=flat-square)

## üìñ Overview

anndata is a Python package for storing and working with annotated data matrices in memory or on disk, providing efficient support for sparse data, lazy operations, and integrations like a PyTorch interface (commonly used for single-cell analysis).

> **Note**: This documentation lists the **agent-ready wrapper functions** generated for this package. These functions have been strictly typed, docstring-enhanced, and tested for import stability within a standardized Apptainer environment.

## üõ†Ô∏è Available Agent Tools

Below is the list of **8** functions optimized for LLM tool-use.

| **Tool Name (Wrapper)**   | **Source**          | **File Path**     | **Arguments (Type)**        | **Description**                |
| ------------------------- | ------------------- | ----------------- | --------------------------- | ------------------------------ |
| `anndata__core_merge_default_fill_value` | `anndata._core.merge.default_fill_value` | `anndata/_core/merge.py` | `els: list` | `Given some arrays, return the default fill value that should be used when merging them for anndata operations. This function exists for backwards compatibility in anndata's merging logic for annotated data matrices (used for single-cell and other omics data). It inspects the provided elements to decide whether the merged result should use a sparse- friendly fill value (0) or a dense/missing-value sentinel (numpy.nan). In practice this affects how missing entries are represented when combining layers, observations, variables, or other array-like components inside an AnnData object, and therefore influences memory use and downstream numeric semantics (e.g., treating missing entries as zeros for sparse data versus NaN for dense data).` |
| `anndata__io_utils_check_key` | `anndata._io.utils.check_key` | `anndata/_io/utils.py` | `key: str` | `anndata._io.utils.check_key validates and normalizes a candidate HDF5 key used by anndata's I/O routines. Checks that the provided key is a valid h5py key for use as a group or dataset name in on-disk AnnData (HDF5) storage. In the anndata codebase this function is used by the file I/O pipeline when creating or accessing HDF5 groups and datasets so that keys passed into h5py are guaranteed to be Python built-in str objects. The function accepts values that are instances of str or of subclasses of str and returns a built-in str; it does not perform any other conversions (for example, it does not decode bytes) and has no side effects.` |
| `anndata__io_utils_convert_bool` | `anndata._io.utils.convert_bool` | `anndata/_io/utils.py` | `string: str` | `anndata._io.utils.convert_bool: Determine whether a text token represents a boolean literal and return a normalized boolean indicator and value. This helper is used in the anndata I/O utilities when parsing textual metadata or serialized fields (for example, when reading annotation columns from CSV or other plain-text representations of AnnData objects used in single-cell workflows). The function implements a strict, deterministic conversion: it recognizes only the exact, case-sensitive string literals "True" and "False" and maps them to Python boolean values. Callers (code that constructs or populates AnnData.obs / AnnData.var or other metadata fields from text) should use the first element of the returned tuple to decide whether the input was recognized as a boolean literal before trusting the second element as the boolean value.` |
| `anndata__io_utils_convert_string` | `anndata._io.utils.convert_string` | `anndata/_io/utils.py` | `string: str` | `anndata._io.utils.convert_string converts a textual token (Python str) into an appropriate Python scalar type used by anndata I/O utilities: it will attempt to interpret the input as an int, then a float, then a boolean, then the Python None singleton, and if none of those match it returns the original string. This function is used when parsing annotation/metadata fields and other text-based values read by anndata (for example when reading from text-based files or serialisations) so that numeric and boolean values become native Python types suitable for numeric computation, indexing, and logical masking rather than remaining untyped strings.` |
| `anndata__io_utils_idx_chunks_along_axis` | `anndata._io.utils.idx_chunks_along_axis` | `anndata/_io/utils.py` | `shape: tuple, axis: int, chunk_size: int` | `anndata._io.utils.idx_chunks_along_axis Gives an iterator that yields indexer tuples which partition (chunk) an array shape along a single axis. This utility is used in anndata I/O and array processing code to iterate over contiguous blocks (batches) along a specified axis of an array-like object (for example, a 2-D expression matrix stored in memory or on disk via HDF5). By producing tuples of slice objects that can be passed directly to NumPy-like indexing (array[tuple_of_slices]), callers can read or process the array in fixed-size chunks to limit memory use, enable streaming I/O, or apply batch computations.` |
| `anndata__io_utils_is_float` | `anndata._io.utils.is_float` | `anndata/_io/utils.py` | `string: str` | `anndata._io.utils.is_float determines whether the provided string can be converted to a floating-point number using Python's built-in float() conversion. This function is used in anndata's I/O utilities when parsing textual representations of data (for example, when reading numeric annotations, matrix entries, or metadata from files) to decide whether a token should be interpreted as a numeric value or treated as non-numeric text. The implementation attempts float(string) and returns a Boolean result: True when conversion succeeds, False when conversion raises ValueError. The function has no side effects and does not mutate its input. It is a small, local utility intended to help with robust parsing of annotated data matrices in the anndata codebase; see the original reference used when implementing this approach (a StackOverflow discussion on checking float convertibility).` |
| `anndata__io_utils_is_int` | `anndata._io.utils.is_int` | `anndata/_io/utils.py` | `string: str` | `anndata._io.utils.is_int: Determine whether a given string can be converted to an integer using Python's built-in int() conversion. Checks whether the input text token commonly produced by I/O and parsing routines in the anndata codebase represents an integer value. This helper is used when reading or interpreting textual fields (for example, column or index values from files or metadata strings) to decide whether a token should be treated as an integer. The function performs no I/O, has no side effects, and is intended to be a small, fast utility called by higher-level parsers in the anndata I/O utilities.` |
| `anndata_logging_get_logger` | `anndata.logging.get_logger` | `anndata/logging.py` | `name: str` | `Creates and returns a named child logger that is attached to the anndata library's central logger manager so that messages from library submodules and user code using anndata integrate with the package-wide logging configuration. This function is used across the anndata codebase and by downstream packages (for example, Scanpy and other scverse projects) to obtain a logger that delegates to the module-level anndata_logger manager instead of the global logging.root. The practical significance is that callers who obtain a logger with this function will inherit handlers, levels, and formatting configured for anndata, ensuring consistent logging behavior for annotated-data workflows (single-cell omics and related analyses) that rely on anndata for in-memory and on-disk annotated data handling.` |

## ‚öñÔ∏è License

Original Code License: BSD-3-Clause

Wrapper Code & Documentation: Apache-2.0

*This file was automatically generated on February 26, 2026.*
