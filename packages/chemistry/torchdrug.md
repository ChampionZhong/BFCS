# torchdrug

[üîô Back to Main Repo](../../../README.md) | [üîó Original Repo](https://github.com/DeepGraphLearning/torchdrug)

![Tool Count](https://img.shields.io/badge/Agent_Tools-16-blue?style=flat-square)
![Category](https://img.shields.io/badge/Category-Chemistry-green?style=flat-square)
![Status](https://img.shields.io/badge/Import_Test-Passed-success?style=flat-square)

## üìñ Overview

TorchDrug is a PyTorch-based toolbox for graph machine learning in drug discovery, providing GPU-accelerated graph operations and ready-to-use components for rapidly prototyping and benchmarking models on molecular and protein datasets.

> **Note**: This documentation lists the **agent-ready wrapper functions** generated for this package. These functions have been strictly typed, docstring-enhanced, and tested for import stability within a standardized Apptainer environment.

## üõ†Ô∏è Available Agent Tools

Below is the list of **16** functions optimized for LLM tool-use.

| **Tool Name (Wrapper)**   | **Source**          | **File Path**     | **Arguments (Type)**        | **Description**                |
| ------------------------- | ------------------- | ----------------- | --------------------------- | ------------------------------ |
| `torchdrug_data_dataloader_graph_collate` | `torchdrug.data.dataloader.graph_collate` | `torchdrug/data/dataloader.py` | `batch: list` | `torchdrug.data.dataloader.graph_collate Collate a list of identically-structured samples into a single batched container suitable for model input and DataLoader output. This function is used in TorchDrug to prepare batches of graph-structured data (for example, molecules or interaction graphs used in drug discovery tasks) and other nested containers so they can be processed efficiently by downstream models and by PyTorch DataLoader workers. It supports torch.Tensor stacking with optional shared-memory allocation when running in a DataLoader worker process, conversion of numeric scalars into tensors, preservation of raw string/bytes lists, packing of Graph objects via data.Graph.pack for batched graph processing, and recursive collation of Mapping and Sequence containers. The caller must provide a non-empty list of samples where each sample has the same nested container structure and element types; mismatches or empty input are failure modes documented below.` |
| `torchdrug_utils_comm_init_process_group` | `torchdrug.utils.comm.init_process_group` | `torchdrug/utils/comm.py` | `backend: str, init_method: str = None, **kwargs` | `Initialize CPU and/or GPU process groups used by TorchDrug to enable inter-process communication for distributed training and data-parallel execution. This function is a thin wrapper around torch.distributed.init_process_group and is used throughout TorchDrug to prepare the communication primitives that other modules (for example core.Engine and models) rely on when running on multiple CPUs or GPUs. It sets two module-level globals, cpu_group and gpu_group, which represent process groups for CPU-side and GPU-side collective operations respectively. After calling this function, collective operations in TorchDrug that depend on cpu_group or gpu_group can be used for synchronizing parameters, gradients, or other tensors across processes.` |
| `torchdrug_utils_file_compute_md5` | `torchdrug.utils.file.compute_md5` | `torchdrug/utils/file.py` | `file_name: str, chunk_size: int = 65536` | `torchdrug.utils.file.compute_md5: Compute the MD5 checksum of a file. This function reads the file specified by file_name in binary mode and computes its MD5 digest using hashlib.md5. It processes the file in chunks of size chunk_size to limit peak memory usage when handling large files. In the TorchDrug project, this function is intended for practical tasks such as verifying downloaded dataset or model file integrity, generating stable cache keys for file-based caching, and detecting unintended file modifications to support reproducibility of experiments.` |
| `torchdrug_utils_file_download` | `torchdrug.utils.file.download` | `torchdrug/utils/file.py` | `url: str, path: str, save_file: str = None, md5: str = None` | `torchdrug.utils.file.download downloads a file from a URL and saves it to a local path, with an optional MD5-based skip mechanism commonly used by TorchDrug dataset and model asset installers to avoid re-downloading already-available files. This function is used throughout TorchDrug to fetch dataset files, pretrained model weights, and other remote assets required by the library. It writes a file to disk (side effect), logs the download action via the module logger, and returns the local pathname of the saved file for subsequent use by dataset loaders or model constructors. The function will skip downloading only when a file already exists at the target location and its MD5 matches the provided md5 parameter; otherwise, it will perform the network download using urlretrieve from six.moves.urllib.request.` |
| `torchdrug_utils_file_extract` | `torchdrug.utils.file.extract` | `torchdrug/utils/file.py` | `zip_file: str, member: str = None` | `Extract files from a compressed archive used by TorchDrug. This utility unpacks archives commonly used to distribute datasets, pretrained model weights, or other resources in the TorchDrug project and related workflows. Supported archive types are .zip, .gz, .tar.gz, .tgz and .tar. The function writes extracted files into the directory containing the archive (the save path) and returns either the single extracted file path or the save directory path. The function is typically used in the TorchDrug data-loading and setup pipelines to materialize files from downloaded compressed archives so subsequent dataset, model loading, or preprocessing code can read them from disk. Behavior summary and practical details: - The save directory is determined as os.path.dirname(zip_file), i.e., files are extracted next to the archive by default. - For .gz (single-file gzip) archives, the function derives the original member name from the gzip file name (the archive name without the .gz suffix or .tar.gz handling) and extracts that single file. - For .tar, .tar.gz and .tgz archives, the function iterates over archive members (tar.getnames()). For each member, directory members are created with os.makedirs(save_file, exist_ok=True). Non-directory members are extracted via tar.extractfile and written to disk. - For .zip archives, the function iterates over zip.namelist(), creates directories for directory members, and writes each file via zipped.open and a streaming copy to disk. - When member is provided, only that member is extracted. In that case the extracted file is written into the save path using the basename of the member (i.e., nested archive path information is not preserved when extracting a single member; the output file is save_path / os.path.basename(member)). - Before writing a member, the function compares the existing destination file size with the archived file size (for .gz the original file length is obtained via the gzip trailer and struct.unpack("<I", ...)). If sizes match, extraction of that member is skipped to avoid unnecessarily overwriting identical content. - The function logs extraction actions via logger.info calls present in the implementation. - Unknown or unsupported archive extensions will raise ValueError("Unknown file extension `%s`" % extension). Other errors from the underlying libraries (gzip, tarfile, zipfile) or I/O (e.g., permission errors) are propagated.` |
| `torchdrug_utils_file_get_line_count` | `torchdrug.utils.file.get_line_count` | `torchdrug/utils/file.py` | `file_name: str, chunk_size: int = 8388608` | `Get the number of newline characters in a file by scanning it in binary chunks.` |
| `torchdrug_utils_file_smart_open` | `torchdrug.utils.file.smart_open` | `torchdrug/utils/file.py` | `file_name: str, mode: str = "rb"` | `Open a regular or compressed file and return a file-like object. This function is a drop-in replacement for the built-in open() that transparently handles files compressed with bzip2 (.bz2) and gzip (.gz). The implementation determines the compression type by examining the file extension using os.path.splitext(file_name)[1]; if the extension equals ".bz2" it opens the file with bz2.BZ2File, if the extension equals ".gz" it opens the file with gzip.GzipFile, otherwise it falls back to the builtin open(). In the TorchDrug project this is used to simplify code that loads datasets, model checkpoints, and other data files so callers do not need to handle compressed and uncompressed files separately. The default mode is "rb" (binary read) because many TorchDrug artifacts (for example PyTorch checkpoint files and binary dataset formats) are read in binary mode.` |
| `torchdrug_utils_io_input_choice` | `torchdrug.utils.io.input_choice` | `torchdrug/utils/io.py` | `prompt: str, choice: tuple = ('y', 'n')` | `torchdrug.utils.io.input_choice prints a formatted prompt to standard output and blocks until the user supplies a string that matches one of the allowed choices. This function is a small command-line I/O utility intended for interactive TorchDrug workflows (for example, confirming dataset downloads, overwriting files, or proceeding with potentially destructive operations during training or data preparation). It formats the displayed prompt by appending the allowed choices in parentheses and repeatedly calls the built-in input() until a valid choice is entered.` |
| `torchdrug_utils_io_literal_eval` | `torchdrug.utils.io.literal_eval` | `torchdrug/utils/io.py` | `string: str` | `torchdrug.utils.io.literal_eval evaluates a string into a Python literal value using Python's ast.literal_eval and returns the original string unchanged if parsing fails. This utility is used in TorchDrug to convert textual representations (for example, attributes read from datasets, configuration files, or user-provided strings when registering custom node/edge/graph attributes) into native Python literal objects so downstream code (indexing, feature processing, model configuration) can operate on proper Python types rather than raw text.` |
| `torchdrug_utils_plot_reaction` | `torchdrug.utils.plot.reaction` | `torchdrug/utils/plot.py` | `reactants: list, products: list, save_file: str = None, figure_size: tuple = (3, 3), atom_map: bool = False` | `torchdrug.utils.plot.reaction visualizes a chemical reaction by converting TorchDrug Molecule objects into RDKit reaction templates, rendering the combined reactant and product depiction, and either displaying the image in a viewer or saving it to a PNG file. This function is intended for use in drug discovery and molecular modeling workflows built with TorchDrug (a PyTorch-based toolbox) where quick visual inspection of reaction transformations, including optional atom mapping, is required.` |
| `torchdrug_utils_pretty_long_array` | `torchdrug.utils.pretty.long_array` | `torchdrug/utils/pretty.py` | `array: list, truncation: int = 10, display: int = 3` | `Format a list as a concise, human-readable string suitable for logging and display in TorchDrug utilities. This function is used throughout TorchDrug to produce compact textual summaries of potentially long Python lists (for example, lists of node indices for graphs, atom or bond index lists for molecules, dataset index lists, or other long enumerations) so that logs, visualizations, and printed representations remain readable. If the list length does not exceed the truncation threshold, the full list is returned as its standard Python string representation. If the list is longer than the truncation threshold, the function returns a summary that shows the first few and last few elements separated by the literal ", ..., " to indicate omitted middle elements. The function does not modify the input list.` |
| `torchdrug_utils_pretty_time` | `torchdrug.utils.pretty.time` | `torchdrug/utils/pretty.py` | `seconds: float` | `torchdrug.utils.pretty.time formats a duration given in seconds into a concise, human-readable string suitable for logging and display in TorchDrug training, evaluation, and data processing workflows (for example, epoch time, batch processing time, or dataset loading time). This function converts a numeric elapsed time in seconds to one of four unit strings ("secs", "mins", "hours", "days") using fixed thresholds. It is intended to be used in monitoring and reporting runtime information in the TorchDrug domain (PyTorch-based graph and molecular ML tasks) where readable elapsed-time strings simplify experiment logs and user-facing output. The conversion uses constant thresholds sec_per_min = 60, sec_per_hour = 3600, and sec_per_day = 86400 and selects units by strict greater-than comparisons: values strictly greater than a threshold are expressed in the next larger unit. Formatting is performed with two decimal places using "%.2f". Behavior details, side effects, defaults, and failure modes: The function has no side effects and does not modify input. There is no default for seconds; the caller must supply a float. Numeric values that exactly equal the thresholds (60, 3600, 86400) are formatted in the smaller unit because the comparisons are strict (for example, 60.0 -> "60.00 secs", 3600.0 -> "60.00 mins", 86400.0 -> "24.00 hours"). Negative float values are accepted by the implementation and will be formatted as negative durations in seconds (for example, -5.0 -> "-5.00 secs"). Non-numeric inputs or types incompatible with Python float formatting may raise a TypeError or produce unexpected output; callers should pass a float or a value coercible to float. Special float values such as NaN or infinity will be formatted according to Python's float-to-string behavior.` |
| `torchdrug_utils_torch_cat` | `torchdrug.utils.torch.cat` | `torchdrug/utils/torch.py` | `objs: list, *args, **kwargs` | `Concatenate a list of nested containers with the same structure used in TorchDrug graph and molecular data processing.` |
| `torchdrug_utils_torch_load_extension` | `torchdrug.utils.torch.load_extension` | `torchdrug/utils/torch.py` | `name: str, sources: list, extra_cflags: list = None, extra_cuda_cflags: list = None, **kwargs` | `Load a PyTorch C++ extension just-in-time (JIT) and return a deferred loader that compiles the extension on first use. This function is used by TorchDrug to register and JIT-compile custom native operators or performance-critical C/C++/CUDA code so that models and data-processing code can run with native performance on CPU and, when available, GPU. The function automatically chooses sensible compilation flags when they are not provided, performs lazy evaluation so compilation is deferred until the extension is actually needed, and is implemented to be safe in multi-process scenarios (for example, DataLoader worker processes or distributed training). This wrapper ultimately forwards work to the machinery used by torch.utils.cpp_extension.load and returns a LazyExtensionLoader object that encapsulates the on-demand build and import behavior.` |
| `torchdrug_utils_torch_sparse_coo_tensor` | `torchdrug.utils.torch.sparse_coo_tensor` | `torchdrug/utils/torch.py` | `indices: torch.Tensor, values: torch.Tensor, size: list` | `Construct a sparse COO tensor without performing index validation. This function is a thin, high-performance wrapper used in the torchdrug library to build sparse tensors (COO format) for graph-structured data such as adjacency matrices or sparse node/edge features. It delegates construction to a low-level backend (torch_ext.sparse_coo_tensor_unsafe) and therefore avoids the index checks performed by torch.sparse_coo_tensor, providing faster construction for workloads in TorchDrug where indices are known to be valid in advance (for example, creating adjacency representations of molecular graphs or minibatch graph unions during training).` |
| `torchdrug_utils_torch_stack` | `torchdrug.utils.torch.stack` | `torchdrug/utils/torch.py` | `objs: list, *args, **kwargs` | `Stack a list of nested containers with the same structure. This utility is used in the TorchDrug codebase to merge a list of structurally identical objects (for example, per-sample graph or molecule attributes) into a single nested object where leaf tensors are combined by torch.stack. Typical TorchDrug uses include batching node features, edge attributes, atom types, or other registered node/edge/graph attributes so they can be processed efficiently by PyTorch models and moved to accelerators. The function recurses into nested containers that are either torch.Tensor, dict, list, or tuple, and preserves the original container types and nesting while stacking tensor leaves.` |

## ‚öñÔ∏è License

Original Code License: Apache-2.0

Wrapper Code & Documentation: Apache-2.0

*This file was automatically generated on February 26, 2026.*
