# robert

[üîô Back to Main Repo](../../../README.md) | [üîó Original Repo](https://github.com/jvalegre/robert)

![Tool Count](https://img.shields.io/badge/Agent_Tools-38-blue?style=flat-square)
![Category](https://img.shields.io/badge/Category-Chemistry-green?style=flat-square)
![Status](https://img.shields.io/badge/Import_Test-Passed-success?style=flat-square)

## üìñ Overview

ROBERT is a Python toolkit that automates building, refining, and optimizing regression (QSPR/cheminformatics) models‚Äîoptionally using RDKit‚Äîwhile generating validation metrics and a ready-to-share PDF report.

> **Note**: This documentation lists the **agent-ready wrapper functions** generated for this package. These functions have been strictly typed, docstring-enhanced, and tested for import stability within a standardized Apptainer environment.

## üõ†Ô∏è Available Agent Tools

Below is the list of **38** functions optimized for LLM tool-use.

| **Tool Name (Wrapper)**   | **Source**          | **File Path**     | **Arguments (Type)**        | **Description**                |
| ------------------------- | ------------------- | ----------------- | --------------------------- | ------------------------------ |
| `robert_aqme_filter_aqme_args` | `robert.aqme.filter_aqme_args` | `robert/aqme.py` | `aqme_db: str` | `robert.aqme.filter_aqme_args removes AQME-specific argument columns from a CSV file used in the AQME preprocessing step of the ROBERT package. This function is used in the AQME-related preprocessing pipeline of ROBERT (Refiner and Optimizer of a Bunch of Existing Regression Tools) to sanitize CSV inputs by removing columns that represent AQME arguments. Removing these columns prevents AQME-specific parameters from being treated as feature columns in downstream regression, machine-learning, or reporting steps handled by ROBERT.` |
| `robert_generate_utils_detect_best` | `robert.generate_utils.detect_best` | `robert/generate_utils.py` | `folder: str` | `robert.generate_utils.detect_best checks a folder of CSV result files produced by ROBERT regression experiments and selects the file combination that yielded the best training result, then copies that CSV and its associated "_db.csv" file into a "Best_model" location by replacing the path segment "Raw_data" with "Best_model". This function is used in the ROBERT pipeline to automatically detect which combination of model/features/parameters produced the most favorable training metric (as reported in each CSV) and to preserve both the selected result CSV and its paired database CSV for later inspection or reporting. It expects CSV files written by earlier ROBERT steps where each CSV contains at least an "error_type" column and a "combined_{error_type}" column (for example "combined_mae" when error_type is "mae"). The function reads files with UTF-8 encoding, ignores files that include "_db" in their filename when computing the scoring metric, and preserves index alignment by inserting NaN for those entries.` |
| `robert_report_utils_calc_penalty_r2` | `robert.report_utils.calc_penalty_r2` | `robert/report_utils.py` | `r2_val: float` | `robert.report_utils.calc_penalty_r2 computes a small integer penalty for a model's coefficient of determination (R¬≤) using predetermined thresholds. This penalty is intended to be used by ROBERT's report and scoring utilities to reduce the overall quality score of regression models with low predictive performance (for example, when assembling the ROBERT report or combining R¬≤ with other metrics such as MCC). This function implements a deterministic, pure scoring rule: it inspects the numeric R¬≤ value provided and returns a negative integer penalty according to fixed thresholds. The thresholds reflect conventions used within the ROBERT reporting pipeline: R¬≤ < 0.5 is considered poor and receives a larger penalty; 0.5 ‚â§ R¬≤ < 0.7 is considered marginal and receives a smaller penalty; R¬≤ ‚â• 0.7 receives no penalty. There are no side effects, no internal state changes, and no defaults beyond the numerical thresholds coded in the function. Behavior notes: - The function performs simple numeric comparisons; it does not validate that r2_val lies within [0, 1]. Inputs outside the typical R¬≤ range (e.g., negative values or values > 1) will be compared against the thresholds and penalized accordingly. - If r2_val is float('nan'), comparisons with NaN evaluate to False in Python and the function will return 0 (no penalty). - If r2_val is not a numeric type that supports comparison with floats, a TypeError (or comparable exception) will be raised by the comparison operations.` |
| `robert_report_utils_calc_score` | `robert.report_utils.calc_score` | `robert/report_utils.py` | `dat_files: dict, suffix: str, pred_type: str, data_score: dict` | `Calculates the ROBERT score for a given dataset/model split and updates the provided score dictionary used by ROBERT report generation. This function is part of the ROBERT package (Refiner and Optimizer of a Bunch of Existing Regression Tools) and combines scores produced by the prediction and verification steps into a single composite "robert_score" used in reports and downstream decision-making in cheminformatics machine-learning workflows. It first augments the provided data_score dictionary by calling get_predict_scores on the file referenced by dat_files['PREDICT'] and get_verify_scores on dat_files['VERIFY']. Then, depending on whether the prediction task is regression ('reg') or classification ('clas'), it computes component scores (reading existing keys from data_score with safe defaults) and assigns a final robert_score_{suffix} entry in data_score. The function clamps negative final scores to zero to avoid producing negative ROBERT scores.` |
| `robert_report_utils_combine_cols` | `robert.report_utils.combine_cols` | `robert/report_utils.py` | `columns: list` | `robert.report_utils.combine_cols constructs an HTML fragment that arranges a sequence of column contents into a single horizontal (multi-column) line using inline CSS flex layout. In the ROBERT project this helper is used when assembling pieces of the HTML-based report (for example the ROBERT_report.pdf styling pipeline) so that multiple data elements can be displayed side-by-side as equally weighted columns in report sections.` |
| `robert_report_utils_css_content` | `robert.report_utils.css_content` | `robert/report_utils.py` | `csv_name: str, robert_version: str` | `robert.report_utils.css_content returns a complete CSS stylesheet string tailored for ROBERT PDF reports, with the provided CSV filename and ROBERT version interpolated into header/footer content. This function is used by the ROBERT report generation pipeline to produce the CSS that an HTML-to-PDF renderer will apply when creating the ROBERT PDF report (see project README instructions for installing system libraries required by the PDF report workflow). The returned stylesheet encodes page geometry (A4, 2cm margin), page headers/footers (including page numbering, a bottom-left ROBERT version label, and a top-right CSV filename), global typography (Helvetica with fallbacks), logo/image selectors, and several layout utility classes (.dat-content, .img-PREDICT, hr rules). The csv_name and robert_version parameters are interpolated verbatim into CSS content rules so they appear in the generated PDF (csv_name appears at @top-right; robert_version appears at @bottom-left).` |
| `robert_report_utils_detect_predictions` | `robert.report_utils.detect_predictions` | `robert/report_utils.py` | `module_file: str` | `Detect whether a module file documents predictions coming from an external CSV test set and extract the associated metadata used by ROBERT report generation.` |
| `robert_report_utils_format_lines` | `robert.report_utils.format_lines` | `robert/report_utils.py` | `module_data: str, max_width: int = 122, cmd_line: bool = False, one_column: bool = False, spacing: str = ""` | `Format text block lines from a module string into HTML <pre> elements suitable for ROBERT report output, applying simple HTML escaping for the sequence "R2" (to render as R<sup>2</sup>), wrapping lines to a specified width, and optionally preparing a single-column variant with configurable indentation spacing. This function is used by the ROBERT reporting utilities (see README) to convert raw module or documentation text into justified HTML fragments that can be embedded into the project report (for example, ROBERT_report.pdf or HTML report sections). It accepts the raw text content as a single string, wraps each original line using Python's textwrap.fill, replaces occurrences of the literal substring "R2" with the HTML-safe superscript form "R<sup>2</sup>", and returns a single string containing one or more <pre style="text-align: justify;">...</pre> blocks. The output is intended for downstream inclusion in report-generation pipelines that expect HTML fragments.` |
| `robert_report_utils_get_col_score` | `robert.report_utils.get_col_score` | `robert/report_utils.py` | `score_info: str, data_score: dict, suffix: str, spacing: str, eval_only: bool` | `get_col_score Gather and format the HTML column that summarizes a model score for inclusion in the ROBERT report (PDF/HTML). This function is used by the robert.report_utils module to assemble a small HTML fragment that displays the model title, model type, partition/proportion label, descriptor point counts, and an HTML-formatted block of evaluation text. In the ROBERT workflow (see README), the output is intended to be embedded into the final report (the ROBERT_report.pdf/HTML) to present the score and brief metadata for either a "No PFI" or "PFI" model.` |
| `robert_report_utils_get_col_text` | `robert.report_utils.get_col_text` | `robert/report_utils.py` | `type_thres: str` | `robert.report_utils.get_col_text returns an HTML-formatted column string containing fixed abbreviation mappings used in the report "score" and "abbreviation" sections of the ROBERT PDF/HTML report. This helper assembles a sequence of hard-coded abbreviation descriptions (for example, "ACC: accuracy", "RF: random forest", "SHAP: Shapley additive explanations") into paragraph (<p>) elements with specific inline styles so the resulting string can be embedded directly into the report layout produced by ROBERT (a library for bridging machine learning and chemistry workflows described in the project README). The function is used during report generation to present concise explanatory text for abbreviations and threshold labels that appear in model evaluation and method-description sections of ROBERT-generated reports. It returns a single str containing multiple HTML paragraph elements; the first paragraph uses a larger negative top margin to reduce spacing relative to section headers and subsequent paragraphs use a smaller negative top margin to compact the column.` |
| `robert_report_utils_get_col_transpa` | `robert.report_utils.get_col_transpa` | `robert/report_utils.py` | `params_dict: dict, suffix: str, section: str, spacing: str` | `get_col_transpa generates an HTML snippet (column) that summarizes model-related parameters for the Reproducibility section of a ROBERT report.` |
| `robert_report_utils_get_csv_metrics` | `robert.report_utils.get_csv_metrics` | `robert/report_utils.py` | `file: str, suffix: str, spacing: str` | `robert.report_utils.get_csv_metrics retrieves the "External test" metrics line from a ROBERT PREDICT dat file and returns a small HTML fragment that can be embedded in the ROBERT report. This function is used by the ROBERT report generation pipeline to extract and present external test performance information (the "csv_test" results recorded by the PREDICT module) as an underlined heading plus an optional metrics paragraph formatted with inline CSS.` |
| `robert_report_utils_get_csv_pred` | `robert.report_utils.get_csv_pred` | `robert/report_utils.py` | `suffix: str, path_csv_test: str, y_value: str, names: str, spacing: str` | `Get the HTML snippet that summarizes external test predictions from a PREDICT csv_test file.` |
| `robert_report_utils_get_metrics` | `robert.report_utils.get_metrics` | `robert/report_utils.py` | `file: str, suffix: str, spacing: str` | `Get the formatted summary of regression metrics from a PREDICT ".dat" file for inclusion in ROBERT reports. This function opens a PREDICT dat file, locates the block that begins with the line containing the literal text "o Summary of results" and either the presence or absence of the substring "No_PFI:" depending on the suffix argument, extracts the nearby lines that contain the numeric summary reported by PREDICT, applies light post-processing (remove the first 8 characters of each metric line, replace the literal token "R2" with the HTML-safe "R<sup>2</sup>", and optionally prefix lines with the provided spacing), then wraps the concatenated lines inside an HTML <pre> element styled with "text-align: justify; margin-top: 10px;". The returned HTML fragment is intended to be embedded in ROBERT-generated reports (HTML or HTML-to-PDF pipelines) so the raw PREDICT summary appears as a preformatted, readable block in the final report.` |
| `robert_report_utils_get_outliers` | `robert.report_utils.get_outliers` | `robert/report_utils.py` | `file: str, suffix: str, spacing: str` | `robert.report_utils.get_outliers: Retrieve and format the outliers summary section for a ROBERT PREDICT/VERIFY report. This function reads a plain-text ".dat" report file produced by ROBERT PREDICT/VERIFY workflows, locates the textual region that documents saved outlier plots, extracts the train and test outlier lines via locate_outliers, and builds an HTML-formatted column fragment that can be embedded in the program's PDF/HTML report. In the ROBERT domain (chemistry-focused regression model reporting), this is used to present which samples were flagged as outliers and to include the corresponding outliers plot reference in the final report layout. The function does not modify the input file; it only reads and formats content for downstream report generation.` |
| `robert_report_utils_get_predict_scores` | `robert.report_utils.get_predict_scores` | `robert/report_utils.py` | `dat_predict: list, suffix: str, pred_type: str, data_score: dict` | `robert.report_utils.get_predict_scores calculates and aggregates numeric scores parsed from the textual output produced by the PREDICT module of the ROBERT package. It parses lines in dat_predict (a list of strings) to extract model type, cross-validation and test results (R2/RMSE for regression or MCC for classification), datapoints:descriptors ratio and outlier/proportion text, and computes derived metrics used by ROBERT for model quality assessment and report generation (scaled RMSE, combined scores, penalties, CV SD coverage). This function is used by the ROBERT reporting pipeline to convert raw PREDICT output into the standardized set of score fields stored in data_score for downstream PDF report generation and model comparison.` |
| `robert_report_utils_get_spacing_col` | `robert.report_utils.get_spacing_col` | `robert/report_utils.py` | `suffix: str, spacing_PFI: str` | `Assign spacing string for a report column based on whether a "PFI" column is present.` |
| `robert_report_utils_get_verify_scores` | `robert.report_utils.get_verify_scores` | `robert/report_utils.py` | `dat_verify: list, suffix: str, pred_type: str, data_score: dict` | `get_verify_scores calculates and stores verification scores extracted from the VERIFY module output lines for a ROBERT model report. This function is used in ROBERT's report utilities to parse the textual output produced by the VERIFY tests (part of the model validation workflow described in the README) and to derive numeric and categorical quality indicators for either regression or classification predictors. It inspects a sequence of lines (dat_verify) produced by VERIFY, selects the block corresponding to the requested suffix ('No PFI' or 'PFI'), evaluates whether specific subtests are flagged as UNCLEAR or FAILED, parses sorted cross-validation error/metric results, scales regression errors relative to a stored y_range, classifies each sorted result as pass/fail/min/max according to the VERIFY rules implemented here, and updates the provided data_score dictionary with computed fields used later in report generation and scoring summaries.` |
| `robert_report_utils_locate_outliers` | `robert.report_utils.locate_outliers` | `robert/report_utils.py` | `i: int, lines: list` | `Locate and extract the Train and Test outlier lines from a PREDICT summary section of a .dat file. This function is used in the ROBERT report generation pipeline to parse the "PREDICT" summary block produced by model evaluation tools and to collect the textual lines that list training and testing outliers for later inclusion in the PDF or text report. Starting from the line index i (typically the index where the "PREDICT" header was found), the function scans subsequent lines to find the "Train:" and "Test:" subsections and extracts up to the reported outlier entries. Extracted lines have the first six characters removed (commonly line numbering or fixed indentation in the .dat output) and long entries are wrapped at 54 characters (so an entry may contain an embedded newline). The function does not modify the input list and returns two new lists containing the extracted strings for Train and Test respectively.` |
| `robert_report_utils_remove_quot` | `robert.report_utils.remove_quot` | `robert/report_utils.py` | `name: str` | `Remove a single leading and/or trailing quotation mark from a string used as an identifier or label. This function is a small utility used by ROBERT's report generation utilities (robert.report_utils) to sanitize names that may have been wrapped in single (') or double (") quotation marks. In the context of ROBERT, this helps ensure chemical names, column headers, filenames, or other labels appear in generated reports (PDF/CSV/HTML) without surrounding quotes that would be visually distracting or semantically misleading. The function only examines the first and last character of the input string and removes one leading quote and/or one trailing quote if present; it does not alter interior characters, remove multiple quotes, or trim whitespace.` |
| `robert_report_utils_repro_info` | `robert.report_utils.repro_info` | `robert/report_utils.py` | `modules: list` | `robert.report_utils.repro_info retrieves and aggregates reproducibility metadata for a list of ROBERT modules by reading each module's "<module>_data.dat" file in the current working directory. This function is used by the ROBERT reporting utilities to populate the "Reproducibility" section of generated reports (for example the PDF report described in the README) and to support reproducibility tests by collecting version, citation, command-line, runtime and environment information recorded by individual modules.` |
| `robert_report_utils_revert_list` | `robert.report_utils.revert_list` | `robert/report_utils.py` | `list_tuple: list` | `robert.report_utils.revert_list swaps the order of a two-element list when the second element contains the literal substring 'No_PFI'. This helper is used by ROBERT report generation utilities to enforce a consistent ordering for two-component entries (for example, entries that may indicate presence/absence of permutation feature importance data) so downstream report formatting and comparisons behave predictably. This function implements a targeted conditional swap: it only changes the ordering when the input is a list of exactly two items and the second item contains 'No_PFI'. The implementation avoids in-place mutation with list.reverse() (a previously observed issue) by constructing and returning a new two-element list when swapping is needed; otherwise it returns the original list object unchanged.` |
| `robert_report_utils_score_rmse_mcc` | `robert.report_utils.score_rmse_mcc` | `robert/report_utils.py` | `pred_type: str, scaledrmse_mcc_val: float` | `Compute a discrete performance score from either a scaled RMSE value (regression) or an MCC value (classification) using fixed thresholds employed in ROBERT report generation and model evaluation. This function is used in the ROBERT reporting utilities to convert a single numeric performance metric into a small integer score that contributes to overall model quality summaries in automated reports. For regression models (pred_type == 'reg') the input scaledrmse_mcc_val is interpreted as a scaled root-mean-square error where smaller values indicate better performance; for classification models (any pred_type other than 'reg') the input is interpreted as Matthew's Correlation Coefficient (MCC) where larger values indicate better performance. The mapping of metric values to integer scores follows hard-coded thresholds so the function is deterministic and has no side effects.` |
| `robert_utils_Xy_split` | `robert.utils.Xy_split` | `robert/utils.py` | `csv_df: dict, csv_X: dict, X_scaled_df: dict, csv_y: numpy.ndarray, csv_external_df: dict, csv_X_external: dict, X_scaled_external_df: dict, csv_y_external: numpy.ndarray, test_points: list, column_names: list` | `robert.utils.Xy_split returns a dictionary containing training, optional test, and optional external sets extracted from provided dataset containers. This helper is used in ROBERT's machine-learning workflows (regression tasks in chemistry) to prepare inputs for model training, validation, and external testing by slicing feature matrices, scaled feature matrices, target arrays, and name columns according to a provided list of test indices. It organizes these subsets into keys that downstream functions in the pipeline expect (for example, X_train, y_train, X_test, y_test, X_external, y_external, and associated scaled variants and name lists).` |
| `robert_utils_command_line_args` | `robert.utils.command_line_args` | `robert/utils.py` | `exe_type: str, sys_args: dict` | `robert.utils.command_line_args loads default and user-defined command-line arguments for the ROBERT package, parses them according to the program's expected argument types, performs type conversions, and returns the processed configuration object used by downstream ROBERT workflows (CURATE, GENERATE, VERIFY, PREDICT, AQME, REPORT, etc.). This function is used by the ROBERT command-line entry points to combine a small set of programmatic overrides (sys_args) with the full set of available command-line options and defaults defined in the module, and to produce the final "args" object consumed by the rest of the application.` |
| `robert_utils_correct_hidden_layers` | `robert.utils.correct_hidden_layers` | `robert/utils.py` | `params: dict` | `robert.utils.correct_hidden_layers corrects and normalizes the 'hidden_layer_sizes' entry inside a parameter dictionary that is typically loaded from JSON for use with neural-network-based regression tools in ROBERT. The function ensures the value stored under the 'hidden_layer_sizes' key becomes an explicit Python list of integers representing the number of neurons per hidden layer (the same semantic used by scikit-learn MLP estimators), and mutates the input dictionary in place for downstream model construction and hyperparameter handling in the ROBERT regression pipeline. This function is used when JSON-serialized parameter sets store hidden layer sizes as strings (for example "[64,32]" or "64,32") or as lists of numeric/string elements; it attempts to parse those representations and produce a canonical list[int] that downstream code (e.g., model builders or hyperparameter evaluators in ROBERT) expects. The function implements the following concrete behavior from the source: - If params['hidden_layer_sizes'] is not an int, it treats the value as either a string or a list. If the value is a string that begins with '[' or ends with ']', the function strips the leading/trailing bracket characters. If the (possibly bracket-stripped) value is a string, it splits on commas and converts non-empty segments to ints. If the value is a list, it iterates over elements and converts non-empty elements to ints. Empty strings (''), if present in the split/list, are skipped. Parsed integers are collected into layer_arrays and then assigned back into params['hidden_layer_sizes']. - If params['hidden_layer_sizes'] is an int, the function reaches a code path that attempts to assign an undefined local variable to the output (this is an implementation bug in the current source) which will raise an UnboundLocalError at runtime. Behavioral notes, side effects, and failure modes: - The function mutates the input dictionary params in place by replacing params['hidden_layer_sizes'] with the parsed list of integers. It also returns the same dictionary. - Accepted input forms for params['hidden_layer_sizes'] (as handled by the current implementation) include: - a string representing a bracketed list, e.g. "[64,32]" - a comma-separated string without brackets, e.g. "64,32" - a list of elements (elements may be numeric or string-representations of integers) - an integer (handled only by the buggy branch described above; see failure modes) - Conversions use int(ele) for each non-empty element and therefore will raise ValueError if any non-empty element cannot be parsed as an integer (for example "64a" or "sixtyfour"). - If the params dictionary does not contain the key 'hidden_layer_sizes', a KeyError will be raised by the implementation. - If params is not a dict, typical attribute or indexing errors (TypeError) will be raised. - If params['hidden_layer_sizes'] is already an int, the current implementation contains a bug that will raise UnboundLocalError because the code assigns layer_arrays = ele where ele is not defined in that branch. This is a known failure mode of the current source and must be handled by callers or fixed in the implementation. - Empty items produced by splitting strings (empty strings) are skipped and not included in the resulting list.` |
| `robert_utils_dict_formating` | `robert.utils.dict_formating` | `robert/utils.py` | `dict_csv: dict` | `robert.utils.dict_formating converts string-encoded Python literals that originate from CSV-loaded pandas DataFrames into native Python objects for use in the ROBERT cheminformatics and machine-learning workflows. This function is intended to be used after reading rows from CSV files (for example, exported DataFrame rows where complex objects were saved as strings) so that downstream modules in ROBERT (feature handling, model construction, reporting) receive Python lists/dicts instead of their textual representations. The function looks for the keys 'X_descriptors' and 'params' in the input dictionary and, when present, replaces their string values with Python objects using ast.literal_eval. In the ROBERT domain, 'X_descriptors' typically contains molecular descriptor lists or nested structures representing features used for regression or classification models, and 'params' typically contains model hyperparameters or parameter dictionaries saved as strings. Converting these back to their native types is necessary for correct operation of model fitting, prediction, and report generation components.` |
| `robert_utils_format_lists` | `robert.utils.format_lists` | `robert/utils.py` | `value: str` | `robert.utils.format_lists transforms a string representation of a Python sequence into a normalized Python list suitable for downstream use in ROBERT workflows. In the ROBERT project (a toolkit bridging machine learning and chemistry), this function is used to normalize user-provided list-like inputs (for example: lists of descriptor names, feature names, SMILES strings, or hyperparameter entries supplied as configuration strings or command-line arguments) into a predictable Python list so downstream regression, feature-selection, and reporting code can operate on a uniform container.` |
| `robert_utils_get_prediction_results` | `robert.utils.get_prediction_results` | `robert/utils.py` | `model_data: dict, y: numpy.ndarray, y_pred_all: numpy.ndarray` | `robert.utils.get_prediction_results calculates standard evaluation metrics for a fitted model's predictions. This function is used in the ROBERT package (Refiner and Optimizer of a Bunch of Existing Regression Tools) to compute summary performance metrics for either regression or classification models, based on the model type declared in model_data['type']. The function chooses the metric set and minor numeric handling rules according to the 'type' field and returns a tuple of three floats that summarize predictive performance.` |
| `robert_utils_get_scoring_key` | `robert.utils.get_scoring_key` | `robert/utils.py` | `problem_type: str, error_type: str` | `robert.utils.get_scoring_key returns the appropriate scikit-learn scoring identifier or a custom scorer callable for use when evaluating machine learning models within ROBERT. The function maps a short, human-friendly error_type string (for example 'rmse', 'mae', 'r2', 'f1', 'acc', 'mcc') together with a problem_type indicator to the exact scoring key or scorer that downstream ROBERT model-evaluation utilities (such as cross-validation, GridSearchCV, or custom evaluation pipelines used in cheminformatics property- and reaction-prediction tasks) expect.` |
| `robert_utils_graph_vars` | `robert.utils.graph_vars` | `robert/utils.py` | `Xy_data: dict, set_types: list, csv_test: bool, path_n_suffix: str, sd_graph: bool` | `robert.utils.graph_vars sets numeric axis limits for regression result plots and composes the filesystem path and a reduced display path for the resulting PNG graph files used by ROBERT (the Refiner and Optimizer of a Bunch of Existing Regression Tools). This function is used in model evaluation and reporting workflows (for example, producing predicted vs observed plots in cheminformatics and regression benchmarks) to ensure consistent axis padding, to choose whether the plot shows single external results or multiple training/test sets, and to standardize filenames and relative paths for inclusion in reports. This function computes a symmetric padding "size_space" equal to 10% of the range of the relevant y values and returns the lower and upper axis limits after applying that padding. It also composes a full filesystem path for the PNG file (reg_plot_file) and a shortened, report-friendly path segment (path_reduced) that preserves the last components of the path. The behavior differs depending on whether csv_test is True (single external set plotting) or False (multiple sets including train and optionally test). The function does not write any files or create directories; it only inspects numeric values in Xy_data and formats path strings using path_n_suffix.` |
| `robert_utils_load_minimal_model` | `robert.utils.load_minimal_model` | `robert/utils.py` | `model: str` | `Load and return the predefined minimal hyperparameter set for a named estimator used by REFCV within the ROBERT package.` |
| `robert_utils_load_variables` | `robert.utils.load_variables` | `robert/utils.py` | `kwargs: dict, robert_module: str` | `Load default and user-defined variables for a ROBERT module and apply module-specific initialization. This function is used throughout the ROBERT package to convert a user-provided options dictionary into a prepared internal options object (hereafter "self"), to merge defaults, to import variables from a YAML file when requested, to normalize file names and model identifiers, to create destination folders and log files, and to perform initial sanity checks required before executing a specific ROBERT module (for example, GENERATE, CURATE, PREDICT, VERIFY, REPORT, AQME, AQME_TEST). It is the canonical entry point to prepare runtime configuration when launching ROBERT functionality described in the project README (machine-learning workflows and cheminformatics utilities).` |
| `robert_utils_mcc_scorer_clf` | `robert.utils.mcc_scorer_clf` | `robert/utils.py` | `y_true: numpy.ndarray, y_pred: numpy.ndarray` | `robert.utils.mcc_scorer_clf computes the Matthews correlation coefficient (MCC) between true class labels and predicted labels after coercing predictions to integer class labels. This function is intended for use in the ROBERT machine-learning utilities where classifier outputs sometimes arrive as floating-point values (for example, when a model's .predict() returns floats or when a regressor output is reused as a classifier). MCC is a robust single-value summary of binary or multiclass classification quality commonly used in cheminformatics workflows implemented in ROBERT, and it is especially informative for imbalanced class problems. This function forces the provided predicted values to integer labels by applying numpy.round followed by astype(int) and then delegates to sklearn.metrics.matthews_corrcoef to compute the coefficient. The rounding strategy is simple and deterministic: values with fractional part >= 0.5 are rounded up, others rounded down. The function does not modify the caller's y_pred array (it constructs a new integer array for scoring).` |
| `robert_utils_outlier_analysis` | `robert.utils.outlier_analysis` | `robert/utils.py` | `print_outliers: str, outliers_data: dict, outliers_set: str` | `robert.utils.outlier_analysis: Build a human-readable summary of outlier counts and per-instance outlier magnitudes for a given dataset split used in ROBERT regression workflows (chemistry-focused machine learning and regression model evaluation). This function is used by reporting utilities in ROBERT to produce text sections that quantify how many outliers were detected in a dataset split (train, validation, or test), compute the percentage of outliers relative to the total scaled points in that split, and append one-line entries for each outlier showing its identifier and standardized-deviation magnitude. The produced string is suitable for inclusion in console output, log files, or text reports (for example the ROBERT PDF report generator), enabling model developers and chemists to inspect and document problematic datapoints.` |
| `robert_utils_plot_metrics` | `robert.utils.plot_metrics` | `robert/utils.py` | `model_data: dict, suffix_title: str, verify_metrics: dict, verify_results: dict` | `robert.utils.plot_metrics creates and saves a bar plot that visualizes the results of VERIFY tests for a given regression model. This function is part of the ROBERT toolkit (Refiner and Optimizer of a Bunch of Existing Regression Tools) and is used in the VERIFY workflow to inspect which automated checks (tests) for a trained model passed, failed, or are unclear, and to record the figure for reproducibility and reporting.` |
| `robert_utils_scale_df` | `robert.utils.scale_df` | `robert/utils.py` | `csv_X: numpy.ndarray, csv_X_external: numpy.ndarray` | `Scale the feature matrix for training and (optionally) an external test set using scikit-learn's StandardScaler so that downstream regression models in the ROBERT pipeline receive mean-centered, unit-variance features. This function is used in ROBERT's preprocessing steps for quantitative structure- property/activity regression workflows: it fits a StandardScaler on the training descriptor matrix (csv_X) and applies the same scaling parameters to the external descriptor matrix (csv_X_external) when provided. The scaler is fitted only on csv_X to avoid data leakage from the test/external set.` |
| `robert_utils_sort_n_load` | `robert.utils.sort_n_load` | `robert/utils.py` | `Xy_data: dict` | `robert.utils.sort_n_load sorts the training feature and target arrays contained in Xy_data to produce a reproducible, stable ordering of rows for downstream regression model training and evaluation in the ROBERT workflow. This function is used in ROBERT's machine-learning/regression pipelines to ensure that when the same database is loaded with different row orders (for example because of file or OS-dependent ordering), the resulting X and y arrays are reordered deterministically so that model training, cross-validation splits, and results are reproducible across runs and platforms. The implementation converts inputs to numpy arrays, computes a stable argsort on the target values, and reindexes the feature matrix to preserve the original feature-target pairing.` |

## ‚öñÔ∏è License

Original Code License: MIT

Wrapper Code & Documentation: Apache-2.0

*This file was automatically generated on February 26, 2026.*
