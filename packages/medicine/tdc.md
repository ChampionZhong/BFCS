# tdc

[üîô Back to Main Repo](../../../README.md) | [üîó Original Repo](https://github.com/mims-harvard/TDC)

![Tool Count](https://img.shields.io/badge/Agent_Tools-118-blue?style=flat-square)
![Category](https://img.shields.io/badge/Category-Medicine-green?style=flat-square)
![Status](https://img.shields.io/badge/Import_Test-Passed-success?style=flat-square)

## üìñ Overview

TDC (Therapeutics Data Commons) is a Python library that provides standardized, AI-ready datasets, tasks, and benchmarks for developing and evaluating machine learning methods across drug discovery and therapeutic science.

> **Note**: This documentation lists the **agent-ready wrapper functions** generated for this package. These functions have been strictly typed, docstring-enhanced, and tested for import stability within a standardized Apptainer environment.

## üõ†Ô∏è Available Agent Tools

Below is the list of **118** functions optimized for LLM tool-use.

| **Tool Name (Wrapper)**   | **Source**          | **File Path**     | **Arguments (Type)**        | **Description**                |
| ------------------------- | ------------------- | ----------------- | --------------------------- | ------------------------------ |
| `tdc_chem_utils_evaluator_calculate_internal_pairwise_similarities` | `tdc.chem_utils.evaluator.calculate_internal_pairwise_similarities` | `tdc/chem_utils/evaluator.py` | `smiles_list: list` | `Calculates pairwise internal chemical similarities for a list of SMILES strings using molecular fingerprints. This function is used in TDC's cheminformatics utilities to quantify chemical similarity within a single set of molecules (for example, to assess dataset redundancy, chemical diversity, or to select nearest-neighbor analogs when preparing splits or analyses). It converts the input SMILES strings to molecule objects via get_mols, computes fingerprints via get_fingerprints, and then computes pairwise Tanimoto similarities using RDKit's DataStructs.BulkTanimotoSimilarity in a memory-efficient incremental manner. The returned matrix is symmetric and the diagonal is explicitly set to zero to avoid counting self-similarity in downstream thresholding or aggregation steps.` |
| `tdc_chem_utils_evaluator_calculate_pc_descriptors` | `tdc.chem_utils.evaluator.calculate_pc_descriptors` | `tdc/chem_utils/evaluator.py` | `smiles: list, pc_descriptors: list` | `Calculate physical‚Äìchemical (PC) descriptor vectors for a list of molecules represented as SMILES strings. This function is used in TDC's cheminformatics utilities to produce numerical feature vectors that summarize molecular properties (for example, molecular weight, logP, polar surface area) required by downstream tasks such as ADME prediction, model evaluation, and benchmark construction. For each SMILES string in the input list, the function calls the internal helper _calculate_pc_descriptors(smiles, pc_descriptors) to compute the requested descriptor values, collects the non-None results, and returns them as a NumPy array suitable as input features for machine learning models or statistical analyses.` |
| `tdc_chem_utils_evaluator_canonicalize` | `tdc.chem_utils.evaluator.canonicalize` | `tdc/chem_utils/evaluator.py` | `smiles: str` | `Convert a SMILES string into a deterministic canonical SMILES representation suitable for use in TDC data pipelines, evaluators, and molecule-generation workflows.` |
| `tdc_chem_utils_evaluator_continuous_kldiv` | `tdc.chem_utils.evaluator.continuous_kldiv` | `tdc/chem_utils/evaluator.py` | `X_baseline: numpy.ndarray, X_sampled: numpy.ndarray` | `tdc.chem_utils.evaluator.continuous_kldiv computes the continuous Kullback‚ÄìLeibler divergence between two empirical continuous distributions represented as numpy arrays. In the Therapeutics Data Commons (TDC) context, this function is used to quantify how a distribution of sampled molecular property values (for example, properties produced by a generative oracle or model) diverges from a baseline distribution (for example, property values in a reference dataset), enabling evaluation of distributional fidelity in generation and benchmarking workflows. This function fits Gaussian kernel density estimates (KDEs) to the two input arrays, evaluates the two estimated densities on a common grid spanning the combined support of the inputs, and then computes the KL divergence D_KL(P \|\| Q) using scipy.stats.entropy (natural-log base, result in nats). It applies small additive constants to avoid zeros in densities and to stabilize KDE evaluation. Note that the implementation mutates the input numpy arrays in-place by adding a small constant; pass copies if you need to preserve the original arrays.` |
| `tdc_chem_utils_evaluator_discrete_kldiv` | `tdc.chem_utils.evaluator.discrete_kldiv` | `tdc/chem_utils/evaluator.py` | `X_baseline: numpy.ndarray, X_sampled: numpy.ndarray` | `tdc.chem_utils.evaluator.discrete_kldiv calculates the discrete Kullback‚ÄìLeibler (KL) divergence between two empirical numeric distributions by binning their values into histograms and computing D_KL(P \|\| Q) = sum_i P_i log(P_i / Q_i). In the Therapeutics Data Commons (TDC) context, this function is useful for quantifying how a sampled distribution (for example, molecule property values produced by a generative oracle or model) diverges from a baseline distribution (for example, a reference dataset of experimental measurements or desired property distribution) when both are represented as one-dimensional numeric arrays.` |
| `tdc_chem_utils_evaluator_diversity` | `tdc.chem_utils.evaluator.diversity` | `tdc/chem_utils/evaluator.py` | `list_of_smiles: list` | `tdc.chem_utils.evaluator.diversity evaluates the internal chemical diversity of a set of molecules used in TDC generation and dataset analysis workflows. It computes the average pairwise Tanimoto distance between Morgan fingerprints for a deduplicated list of SMILES, providing a single scalar metric that quantifies how chemically diverse the input molecule set is (useful for assessing generative model outputs, dataset curation, and benchmark analysis in therapeutics discovery).` |
| `tdc_chem_utils_evaluator_fcd_distance` | `tdc.chem_utils.evaluator.fcd_distance` | `tdc/chem_utils/evaluator.py` | `generated_smiles_lst: list, training_smiles_lst: list` | `Compute the Fr√©chet ChemNet Distance (FCD) between a set of generated SMILES strings and a set of training SMILES strings using an available backend implementation (TensorFlow or PyTorch). In the Therapeutics Data Commons (TDC) generation context, FCD is used as a distributional similarity metric to evaluate how closely a molecular generative model's outputs match the chemical space of the training data; lower values indicate the generated distribution is closer to the training distribution. This function chooses the implementation at runtime: it attempts to use the TensorFlow-based FCD implementation (fcd) and its wrapper fcd_distance_tf, and if that import fails it attempts the PyTorch-based implementation (fcd_torch) and delegates to fcd_distance_torch. If neither implementation is available, an ImportError is raised instructing how to install a supported backend.` |
| `tdc_chem_utils_evaluator_fcd_distance_tf` | `tdc.chem_utils.evaluator.fcd_distance_tf` | `tdc/chem_utils/evaluator.py` | `generated_smiles_lst: list, training_smiles_lst: list` | `Evaluate the Fr√©chet ChemNet Distance (FCD) between two sets of molecules represented as SMILES strings using a TensorFlow-based ChemNet reference model and return a bounded similarity score derived from the FCD. This function is used in molecular generation and evaluation workflows (for example, in Therapeutics Data Commons tasks for molecule generation) to quantify how closely the distribution of generated molecules matches the distribution of molecules from a training set. Practically, it canonicalizes SMILES, feeds them through a pretrained ChemNet model to obtain high-level activations, computes multivariate Gaussian statistics (mean and covariance) for each set, computes the Fr√©chet distance between those Gaussians, and maps the Fr√©chet distance to a similarity score via the exponential transform implemented in the function. The function caches the loaded ChemNet model in the module-level global variable chemnet and writes the pretrained model file to the system temporary directory the first time it is needed.` |
| `tdc_chem_utils_evaluator_fcd_distance_torch` | `tdc.chem_utils.evaluator.fcd_distance_torch` | `tdc/chem_utils/evaluator.py` | `generated_smiles_lst: list, training_smiles_lst: list` | `Compute the Fr√©chet ChemNet Distance (FCD) between a set of generated molecules and a set of reference (training) molecules using the fcd_torch implementation on CPU. This function is used within Therapeutics Data Commons (TDC) workflows for quantitative evaluation of molecule generation models and oracles. FCD is a distributional metric computed in a pretrained ChemNet feature space and is intended to measure how closely the distribution of generated molecules matches the distribution of training molecules; in practical TDC benchmarking, lower FCD values indicate that generated molecules are more similar to the training distribution. The implementation invoked here sets an environment variable to permit duplicate OpenMP libraries, imports the fcd_torch.FCD class, instantiates an FCD evaluator with device="cpu" and n_jobs=8, and then computes the FCD by calling the evaluator with the two SMILES lists.` |
| `tdc_chem_utils_evaluator_get_fingerprints` | `tdc.chem_utils.evaluator.get_fingerprints` | `tdc/chem_utils/evaluator.py` | `mols: list, radius: int = 2, length: int = 4096` | `Converts a list of small molecules into ECFP (extended-connectivity/Morgan) fixed-length bit-vector fingerprints for use as molecular descriptors in machine-learning workflows (e.g., TDC benchmarks for activity, ADME, and safety prediction).` |
| `tdc_chem_utils_evaluator_get_mols` | `tdc.chem_utils.evaluator.get_mols` | `tdc/chem_utils/evaluator.py` | `smiles_list: list` | `tdc.chem_utils.evaluator.get_mols converts a sequence of SMILES strings into RDKit RDMol objects for downstream TDC tasks such as dataset processing, evaluation, or molecule-generation oracles.` |
| `tdc_chem_utils_evaluator_kl_divergence` | `tdc.chem_utils.evaluator.kl_divergence` | `tdc/chem_utils/evaluator.py` | `generated_smiles_lst: list, training_smiles_lst: list` | `tdc.chem_utils.evaluator.kl_divergence evaluates how closely a set of generated molecules matches the distribution of a reference training set using averaged Kullback‚ÄìLeibler (KL) divergences computed on a fixed set of physicochemical descriptors and an internal pairwise similarity measure. In the Therapeutics Data Commons (TDC) generation and benchmarking context, this function is used to quantify distributional similarity between molecules produced by a generative model (or oracle) and molecules in a training dataset; the resulting scalar is useful for model evaluation, benchmark reporting, and leaderboard comparisons where preservation of training distribution statistics is desired.` |
| `tdc_chem_utils_evaluator_novelty` | `tdc.chem_utils.evaluator.novelty` | `tdc/chem_utils/evaluator.py` | `generated_smiles_lst: list, training_smiles_lst: list` | `tdc.chem_utils.evaluator.novelty evaluates the novelty of a set of generated SMILES strings relative to a reference training set. In the Therapeutics Data Commons (TDC) context, this function quantifies how many generated small-molecule candidates are new compared to molecules seen during training, which is a common metric when assessing molecule generation oracles and generative models for drug discovery.` |
| `tdc_chem_utils_evaluator_single_molecule_validity` | `tdc.chem_utils.evaluator.single_molecule_validity` | `tdc/chem_utils/evaluator.py` | `smiles: str` | `Evaluate whether a single SMILES string corresponds to a chemically parsable molecule. This function is used throughout TDC to screen individual molecular inputs (for example in dataset loading, data processing, molecule generation oracles, and evaluation pipelines) and to ensure that downstream routines receive SMILES that can be converted to a molecular object for feature calculation or model scoring.` |
| `tdc_chem_utils_evaluator_uniqueness` | `tdc.chem_utils.evaluator.uniqueness` | `tdc/chem_utils/evaluator.py` | `list_of_smiles: list` | `tdc.chem_utils.evaluator.uniqueness evaluates the uniqueness of a collection of SMILES strings by canonicalizing and deduplicating them and returning the fraction of distinct molecules present. This function is typically used within the Therapeutics Data Commons (TDC) workflow to quantify molecular diversity of outputs from molecule generation oracles, distribution-learning models, and dataset curation steps; a higher value indicates greater diversity among the provided SMILES.` |
| `tdc_chem_utils_featurize__xyz2mol_AC2BO` | `tdc.chem_utils.featurize._xyz2mol.AC2BO` | `tdc/chem_utils/featurize/_xyz2mol.py` | `AC: numpy.ndarray, atoms: list, charge: int, allow_charged_fragments: bool = True, use_graph: bool = True` | `AC2BO converts an atom connectivity/count matrix (AC) and per-atom atomic numbers into a chemically plausible bond-order (BO) matrix using the valence-assignment algorithm implemented in this module (referred to in the code as "implementation of algorithm shown in Figure 2"). It is used in the TDC chemistry featurization pipeline to infer bond orders and valence-electron information from pairwise connectivity counts produced when converting 3D coordinate data into a molecular graph (the surrounding module is responsible for interpreting .xyz-like inputs and producing AC). The function implements the algorithmic steps referenced in the source: building per-atom candidate valences, computing unsaturated atoms (UA) and degree of unsaturation (DU), enumerating UA pairings, proposing BO matrices, and validating them against valence and total charge constraints. The returned BO matrix and the module-level atomic_valence_electrons structure are used downstream to construct molecular graphs and features for machine-learning tasks in TDC (for example, producing graph inputs for small-molecule predictive tasks and generation oracles).` |
| `tdc_chem_utils_featurize__xyz2mol_BO_is_OK` | `tdc.chem_utils.featurize._xyz2mol.BO_is_OK` | `tdc/chem_utils/featurize/_xyz2mol.py` | `BO: numpy.ndarray, AC: numpy.ndarray, charge: int, DU: list, atomic_valence_electrons: list, atoms: list, valences: list, allow_charged_fragments: bool = True` | `Sanity check for bond orders when converting Cartesian/XYZ-derived connectivity into a molecular graph. This function is used in the tdc.chem_utils.featurize._xyz2mol pipeline to validate whether a proposed bond-order matrix and related per-atom data are chemically consistent with integer total charge, per-atom valence limits, and the expected extra bond orders (DU). In the Therapeutics Data Commons (TDC) context this check prevents creating chemically impossible small-molecule graphs from XYZ-derived connectivity during featurization and ensures downstream featurizers and ML models receive chemically plausible molecular graphs.` |
| `tdc_chem_utils_featurize__xyz2mol_int_atom` | `tdc.chem_utils.featurize._xyz2mol.int_atom` | `tdc/chem_utils/featurize/_xyz2mol.py` | `atom: str` | `tdc.chem_utils.featurize._xyz2mol.int_atom maps a chemical element symbol string to a 1-based integer index used by the XYZ-to-molecule featurization utilities in TDC. This function is used in the pipeline that converts atomic coordinates and element labels (from XYZ files or similar sources) into integer-coded atom features required by downstream molecule construction and machine-learning featurizers.` |
| `tdc_chem_utils_featurize__xyz2mol_read_xyz_file` | `tdc.chem_utils.featurize._xyz2mol.read_xyz_file` | `tdc/chem_utils/featurize/_xyz2mol.py` | `filename: str, look_for_charge: bool = True` | `Reads a molecular geometry in XYZ file format and returns atomic numbers, formal charge, and 3D coordinates suitable for downstream featurization and molecule-reconstruction workflows in the TDC chem_utils.featurize pipeline (adapted from the xyz2mol project).` |
| `tdc_chem_utils_featurize__xyz2mol_str_atom` | `tdc.chem_utils.featurize._xyz2mol.str_atom` | `tdc/chem_utils/featurize/_xyz2mol.py` | `atom: int` | `tdc.chem_utils.featurize._xyz2mol.str_atom converts a 1-based integer atom identifier into a string atom label by indexing the module-level atom list. This function is used in the XYZ-to-molecule featurization pipeline within TDC to map numeric atom identifiers (for example, those parsed from XYZ coordinate files or simple integer atom codes produced during parsing) to their canonical string representations (such as element symbols) stored in the module's global __ATOM_LIST__. The returned string is intended for downstream featurizers and molecular feature extraction that require element labels (e.g., building atom feature vectors, constructing molecular graphs, or generating SMILES-compatible element tokens) in TDC's small-molecule and molecular featurization utilities.` |
| `tdc_chem_utils_featurize__xyz2mol_xyz2AC` | `tdc.chem_utils.featurize._xyz2mol.xyz2AC` | `tdc/chem_utils/featurize/_xyz2mol.py` | `atoms: list, xyz: numpy.ndarray, charge: int, use_huckel: bool = False` | `Convert a list of atom types and their 3D coordinates into an atom connectivity (AC) matrix and an RDKit molecule object used by TDC featurization pipelines. This function is used in therapeutic-molecule featurization within TDC to transform raw molecular geometry (atom identifiers and Cartesian coordinates) into two representations required by downstream workflows: (1) an atom connectivity matrix that encodes which atoms are bonded (used by graph-based featurizers and split/evaluation procedures) and (2) an RDKit molecule object (rdkit.Chem.rdchem.Mol) that can be used for chemistry-aware operations, canonicalization, and integration with other RDKit-based tools. The function dispatches to one of two connectivity-inference implementations: a Huckel-based method when use_huckel is True, and a van-der-Waals distance heuristic when use_huckel is False (the default). It does not perform file I/O; it constructs in-memory objects for immediate use by dataset processing, model input preparation, or oracle evaluation in TDC.` |
| `tdc_chem_utils_featurize__xyz2mol_xyz2AC_huckel` | `tdc.chem_utils.featurize._xyz2mol.xyz2AC_huckel` | `tdc/chem_utils/featurize/_xyz2mol.py` | `atomicNumList: list, xyz: numpy.ndarray, charge: int` | `tdc.chem_utils.featurize._xyz2mol.xyz2AC_huckel computes an atom connectivity (adjacency) matrix for a small molecule by constructing a prototype RDKit molecule from atomic numbers, placing a provided 3D conformer, and running an extended H√ºckel / reduced overlap population calculation (rdEHTTools) to infer bonds via an absolute pair population cutoff. This function is used in the TDC featurization pipeline to convert atomic-number + coordinate representations into a binary adjacency matrix suitable for molecular machine-learning tasks and benchmarks in TDC.` |
| `tdc_chem_utils_featurize__xyz2mol_xyz2mol` | `tdc.chem_utils.featurize._xyz2mol.xyz2mol` | `tdc/chem_utils/featurize/_xyz2mol.py` | `atoms: list, coordinates: numpy.ndarray, charge: int = 0, allow_charged_fragments: bool = True, use_graph: bool = True, use_huckel: bool = False, embed_chiral: bool = True` | `Generate an RDKit molecule object (or multiple candidate molecules) and an associated bond-order matrix from an explicit list of atom types and their 3D Cartesian coordinates. This function is used in TDC chemical featurization workflows to convert atomic coordinates (for example, from quantum calculations or molecular mechanics) into RDKit mol objects that can be further processed for machine learning tasks such as property prediction, featurization, or molecule generation/oracle evaluation.` |
| `tdc_chem_utils_featurize_molconvert_atom2onehot` | `tdc.chem_utils.featurize.molconvert.atom2onehot` | `tdc/chem_utils/featurize/molconvert.py` | `atom: str` | `Convert a chemical atom symbol to a one-hot encoded feature vector used by the TDC molecular featurization pipeline. This function is used by tdc.chem_utils.featurize.molconvert to turn a single atom symbol (for example, 'C' for carbon or 'Cl' for chlorine) into a numeric feature suitable for machine learning models used in TDC small-molecule tasks (e.g., ADME prediction, molecular generation oracles). The one-hot vector has a single 1 at the index corresponding to the atom in the module-level atom_types list and 0s elsewhere. The produced feature is a 2-D NumPy array shaped (1, N) so it can be concatenated or batched consistently with node/atom feature matrices used across TDC data functions and model input pipelines.` |
| `tdc_chem_utils_featurize_molconvert_mol2file2smiles` | `tdc.chem_utils.featurize.molconvert.mol2file2smiles` | `tdc/chem_utils/featurize/molconvert.py` | `molfile: str` | `tdc.chem_utils.featurize.molconvert.mol2file2smiles: Convert a MOL2-format file to a canonical SMILES string for use in TDC molecule featurization and dataset processing pipelines.` |
| `tdc_chem_utils_featurize_molconvert_mol_conformer2graph3d` | `tdc.chem_utils.featurize.molconvert.mol_conformer2graph3d` | `tdc/chem_utils/featurize/molconvert.py` | `mol_conformer_lst: list` | `Convert a list of (molecule, conformer) pairs into a list of 3D graph representations suitable for 3D molecular featurization and graph-based ML in TDC. This function is used in TDC's chem_utils featurization pipeline to turn RDKit-style molecule objects and their corresponding 3D conformers into numeric adjacency and bond-type matrices plus an index-to-atom mapping. The produced graphs are practical inputs for downstream tasks such as 3D graph neural networks, distance-based descriptors, and molecular property prediction in the TDC framework.` |
| `tdc_chem_utils_featurize_molconvert_molfile2smiles` | `tdc.chem_utils.featurize.molconvert.molfile2smiles` | `tdc/chem_utils/featurize/molconvert.py` | `molfile: str` | `tdc.chem_utils.featurize.molconvert.molfile2smiles converts a molecular file in MDL MOL format into a canonical SMILES string suitable for downstream featurization and machine-learning pipelines in TDC.` |
| `tdc_chem_utils_featurize_molconvert_raw3D2pyg` | `tdc.chem_utils.featurize.molconvert.raw3D2pyg` | `tdc/chem_utils/featurize/molconvert.py` | `raw3d_feature: tuple` | `tdc.chem_utils.featurize.molconvert.raw3D2pyg converts a raw 3D molecular feature tuple into a torch_geometric.data.Data object suitable for graph neural network (PyG) consumption in the TDC (Therapeutics Data Commons) small-molecule featurization pipeline.` |
| `tdc_chem_utils_featurize_molconvert_sdffile2coulomb` | `tdc.chem_utils.featurize.molconvert.sdffile2coulomb` | `tdc/chem_utils/featurize/molconvert.py` | `sdf: str` | `tdc.chem_utils.featurize.molconvert.sdffile2coulomb converts an MDL SDF file into Coulomb matrix feature vectors for downstream molecular machine learning tasks in TDC (for example, property prediction or molecular representation benchmarking). The function reads an SDF file, extracts SMILES strings for each molecule using sdffile2smiles_lst, and then computes Coulomb matrix features for those molecules using smiles_lst2coulomb. The resulting NumPy array is intended as an ML-ready numeric descriptor representing interatomic Coulombic interactions and relative atomic composition.` |
| `tdc_chem_utils_featurize_molconvert_sdffile2graph3d_lst` | `tdc.chem_utils.featurize.molconvert.sdffile2graph3d_lst` | `tdc/chem_utils/featurize/molconvert.py` | `sdffile: str` | `Convert an SDF file into a list of 3D molecular graph representations. This function is used in the TDC chem_utils featurize pipeline to produce 3D graph inputs for downstream molecular machine learning workflows (for example, graph neural networks or other graph-based featurizers used in TDC datasets and tasks). The implementation first parses the provided SDF file into a list of molecular conformers by calling sdffile2mol_conformer(sdffile) and then converts those conformers into graph representations via mol_conformer2graph3d(...). The returned graphs preserve per-atom indexing, inter-atomic geometric information, and bond-type information required for 3D-aware featurization and benchmarking within TDC.` |
| `tdc_chem_utils_featurize_molconvert_sdffile2mol_conformer` | `tdc.chem_utils.featurize.molconvert.sdffile2mol_conformer` | `tdc/chem_utils/featurize/molconvert.py` | `sdffile: str` | `Convert an SDF (Structure-Data File) into a list of molecule/conformer pairs suitable for downstream molecular featurization and machine learning workflows in TDC. This function reads the SDF given by sdffile using RDKit's PandasTools.LoadSDF, extracts the RDKit ROMol objects (stored in the DataFrame column "ROMol"), and for each molecule retrieves the first conformer (conformer id = 0). The result is a Python list of 2-tuples (mol, conformer) preserving the order of molecules as they appear in the SDF. This is typically used in TDC featurization pipelines to obtain 3D coordinate information for each molecule for tasks such as descriptor calculation, graph construction, or other 3D-aware machine learning models in drug discovery.` |
| `tdc_chem_utils_featurize_molconvert_sdffile2selfies_lst` | `tdc.chem_utils.featurize.molconvert.sdffile2selfies_lst` | `tdc/chem_utils/featurize/molconvert.py` | `sdf: str` | `Convert an SDF file into a list of SELFIES strings. This function is part of the TDC chem_utils.featurize.molconvert utilities and is used to produce a machine-learning-friendly, robust string representation (SELFIES) for each molecule contained in an SDF-format file. Concretely, the function first extracts SMILES strings from the provided SDF input by calling sdffile2smiles_lst(sdf), then converts each SMILES to a SELFIES string via smiles2selfies. SELFIES are a compact, unambiguous molecular string representation often used in generative models and featurization pipelines; in TDC workflows this conversion is used to prepare molecular inputs for tasks such as property prediction, generation, and benchmarking described in the TDC README.` |
| `tdc_chem_utils_featurize_molconvert_sdffile2smiles_lst` | `tdc.chem_utils.featurize.molconvert.sdffile2smiles_lst` | `tdc/chem_utils/featurize/molconvert.py` | `sdffile: str` | `tdc.chem_utils.featurize.molconvert.sdffile2smiles_lst converts a molecular SDF (Structure-Data File) on disk into a Python list of SMILES strings suitable for downstream featurization and machine-learning workflows in TDC. This function is used in the small-molecule data-processing pipeline to extract the canonical text representations (SMILES) produced by RDKit from an SDF file so that those strings can be passed to featurizers, graph builders, or TDC oracles and evaluators.` |
| `tdc_chem_utils_featurize_molconvert_selfies2smiles` | `tdc.chem_utils.featurize.molconvert.selfies2smiles` | `tdc/chem_utils/featurize/molconvert.py` | `selfies: str` | `Convert a molecular string in SELFIES format to a canonical SMILES string. This function decodes a SELFIES (Self-Referencing Embedded Strings) representation of a small molecule into a SMILES (Simplified Molecular Input Line Entry System) string and then canonicalizes the result. In the TDC (Therapeutics Data Commons) codebase this conversion is used when downstream data functions, featurizers, or molecule-generation oracles require a SMILES representation for model input, property evaluation, or dataset standardization. The implementation calls sf.decoder(selfies) to perform the SELFIES‚ÜíSMILES decode and then calls canonicalize(...) to produce a deterministic canonical SMILES suitable for consistent featurization and comparison across datasets and experiments.` |
| `tdc_chem_utils_featurize_molconvert_smiles2DGL` | `tdc.chem_utils.featurize.molconvert.smiles2DGL` | `tdc/chem_utils/featurize/molconvert.py` | `smiles: str` | `tdc.chem_utils.featurize.molconvert.smiles2DGL: Convert a SMILES string into a dgl.DGLGraph representing the 2D molecular graph used in TDC molecular featurization and graph-based ML pipelines.` |
| `tdc_chem_utils_featurize_molconvert_smiles2ECFP2` | `tdc.chem_utils.featurize.molconvert.smiles2ECFP2` | `tdc/chem_utils/featurize/molconvert.py` | `smiles: str` | `tdc.chem_utils.featurize.molconvert.smiles2ECFP2 converts a SMILES string for a small molecule into an ECFP2 (Morgan fingerprint with radius 1) numeric fingerprint suitable for machine learning workflows in TDC, producing a fixed-length numeric vector representation used by downstream models and dataset featurizers.` |
| `tdc_chem_utils_featurize_molconvert_smiles2ECFP4` | `tdc.chem_utils.featurize.molconvert.smiles2ECFP4` | `tdc/chem_utils/featurize/molconvert.py` | `smiles: str` | `tdc.chem_utils.featurize.molconvert.smiles2ECFP4 converts a SMILES string into an ECFP4 (Morgan radius 2) fingerprint and returns the fingerprint as a numeric 1D NumPy array suitable for machine learning featurization in therapeutic chemistry workflows. This function is used in TDC molecular featurization pipelines to produce a fixed-length binary fingerprint representation of a small molecule given its canonical SMILES. Internally it canonicalizes the SMILES, converts it to an RDKit molecule, computes the Morgan fingerprint with radius 2 and 2048 bits via RDKit AllChem.GetMorganFingerprintAsBitVect, and converts the resulting RDKit bit vector into a NumPy array of floats. ECFP4 fingerprints (Morgan radius 2) are commonly used as input features for property prediction, ADMET modeling, activity screening, and other single-instance prediction tasks in TDC.` |
| `tdc_chem_utils_featurize_molconvert_smiles2ECFP6` | `tdc.chem_utils.featurize.molconvert.smiles2ECFP6` | `tdc/chem_utils/featurize/molconvert.py` | `smiles: str` | `Convert a SMILES string into an ECFP6 (Morgan fingerprint with radius=3) bit vector and return it as a dense NumPy array suitable for machine learning feature input in the TDC molecular pipelines. This function is used across TDC to featurize small-molecule SMILES for downstream tasks such as single-instance property prediction, ADMET predictors, or molecule generation oracles. It canonicalizes the input SMILES, converts it to an RDKit Mol object, computes a 2048-bit Morgan bit fingerprint with radius 3 (commonly referred to as ECFP6), and converts the RDKit bit vector into a one-dimensional numpy.ndarray of float64 values (0.0 or 1.0) so the fingerprint can be consumed by numerical ML models and data loaders.` |
| `tdc_chem_utils_featurize_molconvert_smiles2PyG` | `tdc.chem_utils.featurize.molconvert.smiles2PyG` | `tdc/chem_utils/featurize/molconvert.py` | `smiles: str` | `Convert a SMILES string into a torch_geometric.data.Data graph suitable for use with PyTorch Geometric (PyG) graph neural networks in TDC molecular machine-learning workflows. This function is used in TDC to transform a textual molecule representation (SMILES) into a graph Data object that encodes atom-level features and bond connectivity so that downstream graph-based models (for example, ADMET/property predictors and other small-molecule tasks in TDC) can consume the molecule as input. Execution steps performed by this function: the input SMILES is canonicalized, parsed by RDKit (Chem.MolFromSmiles) into an RDKit Mol object, per-atom feature vectors are computed via get_atom_features and stacked into a torch tensor, element indices for each atom are computed against ELEM_LIST (but are computed locally and not attached to the returned Data), and bond connectivity is converted into an edge_index tensor by enumerating each bond in both directions (undirected bonds are represented as two directed edges). The returned Data contains node features (x) and edge_index suitable for PyG graph layers.` |
| `tdc_chem_utils_featurize_molconvert_smiles2daylight` | `tdc.chem_utils.featurize.molconvert.smiles2daylight` | `tdc/chem_utils/featurize/molconvert.py` | `s: str` | `tdc.chem_utils.featurize.molconvert.smiles2daylight converts a SMILES string into a 2048-dimensional Daylight-style binary fingerprint used by TDC for molecular featurization in machine learning tasks (for example, ADME and other small-molecule benchmarks). The function canonicalizes the input SMILES, constructs an RDKit Mol object, computes the RDKit FingerprintMol, and sets bits corresponding to the on-bits returned by the fingerprint. This fingerprint is commonly used as a fixed-length representation of molecular structure for downstream model input, evaluation, and dataset processing within the TDC library.` |
| `tdc_chem_utils_featurize_molconvert_smiles2graph2D` | `tdc.chem_utils.featurize.molconvert.smiles2graph2D` | `tdc/chem_utils/featurize/molconvert.py` | `smiles: str` | `convert SMILES string into a two-dimensional molecular graph feature suitable for graph-based molecular featurization in TDC's small-molecule workflows (e.g., single-instance prediction, ADME benchmarks, and molecule generation/oracle evaluations). This function canonicalizes the input SMILES string, parses it into an RDKit molecule, and returns a mapping from atom indices to element symbols and an adjacency matrix that encodes bond types as integer codes. The outputs are intended to be used for constructing graph inputs for graph neural networks, featurizers, or any downstream model that expects atom-wise indices and a bond-typed adjacency matrix.` |
| `tdc_chem_utils_featurize_molconvert_smiles2maccs` | `tdc.chem_utils.featurize.molconvert.smiles2maccs` | `tdc/chem_utils/featurize/molconvert.py` | `s: str` | `Convert a SMILES string into a MACCS structural fingerprint represented as a NumPy array. This function is used in TDC molecular featurization pipelines to produce fixed-length numerical descriptors (fingerprints) from a SMILES representation of a small molecule. It first normalizes the input SMILES by calling canonicalize(s) so the same molecule maps consistently to the same fingerprint in downstream tasks. It then uses RDKit's Chem.MolFromSmiles to parse the canonical SMILES into an RDKit Mol object, generates MACCS keys via MACCSkeys.GenMACCSKeys, and converts the resulting RDKit fingerprint into a one-dimensional numpy.ndarray of dtype numpy.float64 suitable for machine learning feature inputs (for example, as input features for TDC single-instance prediction tasks or other molecular ML models).` |
| `tdc_chem_utils_featurize_molconvert_smiles2mol` | `tdc.chem_utils.featurize.molconvert.smiles2mol` | `tdc/chem_utils/featurize/molconvert.py` | `smiles: str` | `Convert a SMILES string into an rdkit.Chem.rdchem.Mol object for use in TDC's molecule featurization and downstream ML pipelines. This function performs three steps: (1) canonicalize the input SMILES to a normalized/canonical SMILES representation (to ensure consistent representation across datasets and splits used in TDC benchmarks), (2) parse the canonical SMILES with RDKit via Chem.MolFromSmiles to produce an rdkit.Chem.rdchem.Mol, and (3) apply Chem.Kekulize to convert aromatic representations into an explicit Kekul√© bond assignment in-place on the returned Mol. The returned rdkit Mol is the standard object used by TDC featurizers, descriptor calculators, and graph converters (e.g., for GNN inputs, oracles, and other molecule-processing functions). If RDKit cannot parse the SMILES, the function returns None to signal an invalid or unsupported SMILES string.` |
| `tdc_chem_utils_featurize_molconvert_smiles2morgan` | `tdc.chem_utils.featurize.molconvert.smiles2morgan` | `tdc/chem_utils/featurize/molconvert.py` | `s: str, radius: int = 2, nBits: int = 1024` | `tdc.chem_utils.featurize.molconvert.smiles2morgan converts a SMILES string into a fixed-length Morgan (circular) fingerprint suitable for machine learning workflows in the Therapeutics Data Commons (TDC) ecosystem. In TDC this function is used to featurize small-molecule representations (SMILES) into numeric vectors for downstream tasks such as ADMET prediction, activity screening, and benchmark dataset preparation where a consistent, fixed-size molecular descriptor is required.` |
| `tdc_chem_utils_featurize_molconvert_smiles2rdkit2d` | `tdc.chem_utils.featurize.molconvert.smiles2rdkit2d` | `tdc/chem_utils/featurize/molconvert.py` | `s: str` | `tdc.chem_utils.featurize.molconvert.smiles2rdkit2d converts a SMILES string into a 200-dimensional normalized RDKit 2D descriptor vector suitable for use as a fixed-length molecular feature vector in TDC molecular ML pipelines (for example, small-molecule property prediction and ADMET benchmarks described in the TDC README). The function canonicalizes the input SMILES, computes descriptors via descriptastorus's RDKit2DNormalized generator, replaces any NaN descriptor values with zeros, and returns the descriptor vector as a numpy.array of length 200.` |
| `tdc_chem_utils_featurize_molconvert_smiles2selfies` | `tdc.chem_utils.featurize.molconvert.smiles2selfies` | `tdc/chem_utils/featurize/molconvert.py` | `smiles: str` | `tdc.chem_utils.featurize.molconvert.smiles2selfies: Convert a SMILES string into a SELFIES string for use in TDC molecule featurization and generation workflows. This function is part of the TDC chem_utils featurization utilities and is used to translate a molecule encoded as a SMILES string into the SELFIES representation. SMILES (Simplified Molecular-Input Line-Entry System) is a common text format for describing small-molecule chemical structures used throughout TDC datasets and tasks. SELFIES (Self-Referencing Embedded Strings) is a machine-learning-oriented, tokenizable molecular string format commonly used in generative models and oracles within TDC because it provides a robust representation for molecular generation. Internally, the function first canonicalizes the input SMILES (so that different equivalent SMILES map to a consistent representation) by calling canonicalize(smiles), then encodes the canonical SMILES to SELFIES by calling sf.encoder(smiles). There are no external side effects (no file I/O or global state changes); the operation is purely functional and returns the encoded string.` |
| `tdc_chem_utils_featurize_molconvert_smiles_lst2coulomb` | `tdc.chem_utils.featurize.molconvert.smiles_lst2coulomb` | `tdc/chem_utils/featurize/molconvert.py` | `smiles_lst: list` | `tdc.chem_utils.featurize.molconvert.smiles_lst2coulomb: Convert a list of SMILES strings into Coulomb-matrix features for molecular machine learning within the TDC workflows. This function is used in TDC (Therapeutics Data Commons) featurization pipelines to turn canonical 1D chemical representations (SMILES) into fixed-size numerical descriptors (Coulomb matrices) that can be consumed by downstream ML models for tasks such as property prediction, ADMET modeling, and benchmark evaluation. The implementation (from the local molconvert utilities) constructs internal Molecule objects from each SMILES string, performs a 3D geometry optimization with the UFF force field, and produces Coulomb matrix representations using a CoulombMatrix object configured with cm_type="UM" and n_jobs=-1. The output preserves input ordering so that each row of the returned array corresponds to the SMILES at the same index in smiles_lst.` |
| `tdc_chem_utils_featurize_molconvert_xyzfile2selfies` | `tdc.chem_utils.featurize.molconvert.xyzfile2selfies` | `tdc/chem_utils/featurize/molconvert.py` | `xyzfile: str` | `tdc.chem_utils.featurize.molconvert.xyzfile2selfies converts a molecular structure in an XYZ-format file into a SELFIES string representation. This function is intended for use in Therapeutics Data Commons (TDC) workflows that require a robust, canonical, graph-based string encoding of a small molecule for downstream machine learning tasks such as molecule generation, featurization for property prediction, or oracle evaluation. The function implements the conversion pipeline used in this module: it reads the input XYZ file, converts the 3D coordinates and element labels to a SMILES string using xyzfile2smiles, canonicalizes that SMILES using canonicalize to produce a standardized representation, and then encodes the canonical SMILES into SELFIES using smiles2selfies. The resulting SELFIES string is suitable as an input representation for TDC molecule generation oracles and other components that accept SELFIES as a molecular string format.` |
| `tdc_chem_utils_featurize_molconvert_xyzfile2smiles` | `tdc.chem_utils.featurize.molconvert.xyzfile2smiles` | `tdc/chem_utils/featurize/molconvert.py` | `xyzfile: str` | `tdc.chem_utils.featurize.molconvert.xyzfile2smiles converts an XYZ-format molecular geometry file into a canonical SMILES string using the module's conversion utilities. This function is intended for use in TDC workflows that require a text-based, connectivity-oriented molecular representation (SMILES) derived from 3D coordinate files for downstream featurization, dataset construction, oracle scoring, or model input.` |
| `tdc_chem_utils_oracle_oracle_SA` | `tdc.chem_utils.oracle.oracle.SA` | `tdc/chem_utils/oracle/oracle.py` | `s: str` | `tdc.chem_utils.oracle.oracle.SA: Compute the Synthetic Accessibility (SA) score for a molecule given its SMILES string. This function is used as a molecule-generation oracle within TDC to evaluate the synthesizability of candidate molecules during goal-oriented or distribution-learning tasks and other molecule-scoring workflows described in the TDC README.` |
| `tdc_chem_utils_oracle_oracle_askcos` | `tdc.chem_utils.oracle.oracle.askcos` | `tdc/chem_utils/oracle/oracle.py` | `smiles: str, host_ip: str, output: str = "plausibility", save_json: bool = False, file_name: str = "tree_builder_result.json", num_trials: int = 5, max_depth: int = 9, max_branching: int = 25, expansion_time: int = 60, max_ppg: int = 100, template_count: int = 1000, max_cum_prob: float = 0.999, chemical_property_logic: str = "none", max_chemprop_c: int = 0, max_chemprop_n: int = 0, max_chemprop_o: int = 0, max_chemprop_h: int = 0, chemical_popularity_logic: str = "none", min_chempop_reactants: int = 5, min_chempop_products: int = 5, filter_threshold: float = 0.1, return_first: str = "true"` | `tdc.chem_utils.oracle.oracle.askcos performs a retrosynthetic analysis query against a running ASKCOS server and returns a single scalar score or metric used as a molecule-generation oracle in the TDC (Therapeutics Data Commons) framework. This function is used by TDC molecule generation workflows to query ASKCOS (ASKCOS GitHub: https://github.com/connorcoley/ASKCOS) running behind an HTTP endpoint and to extract one of several summary metrics (plausibility score, estimated number of synthetic steps, synthesizability, or price) for a target molecule represented as a SMILES string. The function sends an initial price query and, if the price response indicates zero, invokes the ASKCOS Tree Builder API with configurable search and filtering parameters, optionally saves the raw JSON response to disk, analyzes the returned tree structure via tree_analysis, and returns the requested scalar metric. The function prints a short status line for each attempt when retrying the Tree Builder request.` |
| `tdc_chem_utils_oracle_oracle_canonicalize` | `tdc.chem_utils.oracle.oracle.canonicalize` | `tdc/chem_utils/oracle/oracle.py` | `smiles: str, include_stereocenters: bool = True` | `tdc.chem_utils.oracle.oracle.canonicalize: Produce a deterministic, RDKit-based canonical SMILES string from an input SMILES. This function is used throughout TDC for tasks that require a stable molecular representation (for example, molecule generation oracles, dataset canonicalization, deduplication, and downstream evaluation) and follows the canonicalization behavior implemented by RDKit; the underlying algorithmic approach is discussed in https://pubs.acs.org/doi/full/10.1021/acs.jcim.5b00543.` |
| `tdc_chem_utils_oracle_oracle_drd2` | `tdc.chem_utils.oracle.oracle.drd2` | `tdc/chem_utils/oracle/oracle.py` | `smile: str` | `tdc.chem_utils.oracle.oracle.drd2: Evaluate the predicted DRD2 activity score for a molecule given its SMILES string. This function is an oracle-style scorer used in TDC (Therapeutics Data Commons) molecule generation and evaluation pipelines to assign a quantitative DRD2 activity likelihood to a candidate small molecule. It parses the input SMILES string with RDKit, converts the parsed molecule to the feature/fingerprint representation expected by the pretrained DRD2 classifier, and returns the classifier's positive-class score as a Python float. The function lazily loads a module-level pretrained model (drd2_model) via load_drd2_model() on first invocation and stores it as a global variable, so subsequent calls reuse the loaded model and avoid repeated disk or network loads.` |
| `tdc_chem_utils_oracle_oracle_gsk3b` | `tdc.chem_utils.oracle.oracle.gsk3b` | `tdc/chem_utils/oracle/oracle.py` | `smiles: str` | `tdc.chem_utils.oracle.oracle.gsk3b evaluates a pre-trained GSK3B classification oracle on a single molecule represented by a SMILES string and returns a probability-like score used in molecule generation and scoring workflows. This function is used within TDC's molecule generation oracles to provide a scalar objective indicating the predicted likelihood that the input molecule interacts with or is active against the GSK3 beta (GSK3B) target. It converts the input SMILES to an RDKit molecule, computes a 2048-bit Morgan fingerprint (radius=2), converts that fingerprint to a NumPy feature vector, and then applies a cached scikit-learn style classifier (loaded via load_gsk3b_model()) to obtain the predicted probability for the positive class. The function caches the loaded model in the module global gsk3_model on first call to avoid repeated expensive model-loading operations (side effect). This cached global persists for the Python process lifetime or until reassigned.` |
| `tdc_chem_utils_oracle_oracle_ibm_rxn` | `tdc.chem_utils.oracle.oracle.ibm_rxn` | `tdc/chem_utils/oracle/oracle.py` | `smiles: str, api_key: str, output: str = "confidence", sleep_time: int = 30` | `tdc.chem_utils.oracle.oracle.ibm_rxn performs an automatic retrosynthesis query against the IBM RXN for Chemistry service using the rxn4chemistry client and returns either a numeric retrosynthetic confidence score or the raw prediction result. This function is used within TDC as an oracle-style utility for molecule generation and evaluation tasks (see TDC oracles in the README), where retrosynthetic plausibility or confidence can be used as a scoring function for generated SMILES. This function constructs an RXN4ChemistryWrapper with the provided api_key, creates a project named "test" on the IBM RXN service, requests an automatic retrosynthesis prediction for the supplied product SMILES, and polls the service at intervals controlled by sleep_time until the job status becomes "SUCCESS". Depending on the output parameter, it either extracts and returns the confidence from the first retrosynthetic path or returns the entire results structure produced by the rxn4chemistry client. Notes on practical significance and domain role: in molecule generation and optimization workflows (generation problem in TDC), retrosynthetic confidence indicates how readily a candidate molecule might be synthesized according to IBM RXN's retrosynthesis engine; using this function as an oracle helps rank or filter generated molecules by synthetic accessibility as judged by an automated retrosynthesis model. Behavior, side effects, defaults, and failure modes: - The function requires the external package rxn4chemistry and an active internet connection to contact the IBM RXN service. If rxn4chemistry is not importable, the function prints an installation hint (and may subsequently raise an exception depending on the runtime environment). - The function creates a project on the IBM RXN service with the literal name "test". This is a side effect on the remote account associated with the api_key and may be visible in that account's dashboard or usage logs. - The call is blocking: the function polls the remote job status in a loop and will sleep for sleep_time seconds between polls. The default sleep_time is 30 seconds; increase or decrease this to manage polling frequency and overall latency. - API authentication, network errors, or service-side failures (e.g., job rejection, timeouts, or unexpected response structures) can raise exceptions from the rxn4chemistry client or from dictionary access (KeyError). If output is not "confidence" or "result", the function raises NameError with the message "This output value is not implemented." - The confidence value returned when output is "confidence" is taken from results["retrosynthetic_paths"][0]["confidence"], i.e., the first predicted retrosynthetic path's confidence as provided by IBM RXN. The precise numeric scale and meaning of this confidence are defined by the IBM RXN service and should be interpreted according to that service's documentation.` |
| `tdc_chem_utils_oracle_oracle_load_pickled_model` | `tdc.chem_utils.oracle.oracle.load_pickled_model` | `tdc/chem_utils/oracle/oracle.py` | `name: str` | `tdc.chem_utils.oracle.oracle.load_pickled_model loads a pretrained Python object serialized with the pickle module from a file on disk. In the Therapeutics Data Commons (TDC) project this is typically used to restore pretrained machine learning models (for example, scikit-learn estimators) that serve as molecule-generation oracles or other prediction components in molecule-generation and property-prediction workflows described in the TDC README and tutorials.` |
| `tdc_chem_utils_oracle_oracle_parse_molecular_formula` | `tdc.chem_utils.oracle.oracle.parse_molecular_formula` | `tdc/chem_utils/oracle/oracle.py` | `formula: str` | `tdc.chem_utils.oracle.oracle.parse_molecular_formula: Parse a molecular formula string to extract element symbols and their integer counts for use in TDC molecule-generation oracles and data-processing functions. This function takes a plain chemical molecular formula (for example "C8H3F3Br") and returns the elemental composition as a sequence of (element_symbol, count) pairs. It is used in TDC's chem_utils and oracle code paths to provide a simple, fast breakdown of a formula for downstream scoring, filtering, or feature extraction in molecule generation and evaluation workflows. The implementation uses a regular expression to find contiguous element tokens and their optional numeric counts, preserves the order of appearance in the input string, and treats any omitted numeric count as 1.` |
| `tdc_chem_utils_oracle_oracle_penalized_logp` | `tdc.chem_utils.oracle.oracle.penalized_logp` | `tdc/chem_utils/oracle/oracle.py` | `s: str` | `Compute the penalized logP score for a molecule given as a SMILES string. This function implements a commonly used oracle in molecule generation benchmarks (as provided in TDC's "Molecule Generation Oracles" utilities) that combines three components relevant to drug-like molecule design: lipophilicity (logP), synthetic accessibility (SA), and a cycle/ring-size penalty. It parses the input SMILES with RDKit to obtain a molecule, computes MolLogP to quantify lipophilicity, computes an SA score via the calculateScore routine (a negative SA value increases the final score), and computes a cycle penalty based on the largest ring size beyond six atoms. Each component is standardized using fixed mean and standard deviation constants embedded in the implementation, and the final score is the sum of the three normalized components. This score is commonly used as an objective or oracle for goal-directed molecular generation and optimization tasks in TDC benchmarks.` |
| `tdc_chem_utils_oracle_oracle_qed` | `tdc.chem_utils.oracle.oracle.qed` | `tdc/chem_utils/oracle/oracle.py` | `smiles: str` | `tdc.chem_utils.oracle.oracle.qed evaluates the Quantitative Estimate of Drug-likeness (QED) score for a molecule given its SMILES representation. This function is used in TDC as a molecule-scoring oracle for generation and optimization tasks (see TDC "Molecule Generation Oracles") and provides a single scalar reward indicating predicted drug-likeness according to RDKit's QED implementation.` |
| `tdc_chem_utils_oracle_oracle_similarity` | `tdc.chem_utils.oracle.oracle.similarity` | `tdc/chem_utils/oracle/oracle.py` | `smiles_a: str, smiles_b: str` | `tdc.chem_utils.oracle.oracle.similarity evaluates the Tanimoto (fingerprint) similarity between two molecular representations given as SMILES strings. This function is used within TDC as a lightweight molecular similarity oracle for molecule generation and evaluation tasks (for example, scoring generated candidates against target molecules in goal-oriented generation), and it implements a specific, fixed fingerprinting protocol to ensure reproducible comparisons across calls. The function computes Morgan (circular) fingerprints with radius 2, 2048 bits, and chirality disabled, using RDKit's Chem/AllChem/DataStructs modules, and then returns the RDKit-computed Tanimoto similarity between the two bit vectors. The returned similarity is a numerical proxy for structural similarity between small molecules and is commonly used in drug discovery workflows to prioritize candidates, measure diversity, or define optimization objectives.` |
| `tdc_chem_utils_oracle_oracle_smiles_2_fingerprint_AP` | `tdc.chem_utils.oracle.oracle.smiles_2_fingerprint_AP` | `tdc/chem_utils/oracle/oracle.py` | `smiles: str` | `Convert a SMILES string into an RDKit Atom Pair fingerprint (Atom Pair, AP). This function is used in TDC chem_utils and molecule-generation/oracle contexts where compact, graph-derived molecular representations are required for similarity search, scoring, or as input features to generation or evaluation oracles. The function first converts the input SMILES string to an RDKit Mol object by calling smiles_to_rdkit_mol(smiles) and then computes an Atom Pair fingerprint using rdkit.Chem.AllChem.GetAtomPairFingerprint with a fixed maxLength=10, returning RDKit's sparse integer vector representation. The procedure is deterministic (given the same SMILES and RDKit version) and has no persistent side effects, but it depends on RDKit being available in the runtime environment.` |
| `tdc_chem_utils_oracle_oracle_smiles_2_fingerprint_ECFP4` | `tdc.chem_utils.oracle.oracle.smiles_2_fingerprint_ECFP4` | `tdc/chem_utils/oracle/oracle.py` | `smiles: str` | `tdc.chem_utils.oracle.oracle.smiles_2_fingerprint_ECFP4 converts a SMILES string into an ECFP4 (Morgan fingerprint with radius=2) representation used by TDC for molecule generation, similarity calculations, and as input features for predictive models and oracles.` |
| `tdc_chem_utils_oracle_oracle_smiles_2_fingerprint_ECFP6` | `tdc.chem_utils.oracle.oracle.smiles_2_fingerprint_ECFP6` | `tdc/chem_utils/oracle/oracle.py` | `smiles: str` | `tdc.chem_utils.oracle.oracle.smiles_2_fingerprint_ECFP6: Convert a SMILES string into an ECFP6 fingerprint (Morgan fingerprint with radius 3) used as a compact molecular descriptor in TDC's molecule generation and evaluation pipelines.` |
| `tdc_chem_utils_oracle_oracle_smiles_2_fingerprint_FCFP4` | `tdc.chem_utils.oracle.oracle.smiles_2_fingerprint_FCFP4` | `tdc/chem_utils/oracle/oracle.py` | `smiles: str` | `tdc.chem_utils.oracle.oracle.smiles_2_fingerprint_FCFP4 converts a SMILES string into an FCFP4 (feature-based Morgan) fingerprint using RDKit. This function is used in TDC molecule generation and oracle utilities to produce a compact, model-ready molecular descriptor that represents local atom environments (radius 2, feature-based) for similarity comparisons, scoring, and downstream machine learning models in generation and property-prediction workflows.` |
| `tdc_chem_utils_oracle_oracle_smiles_to_rdkit_mol` | `tdc.chem_utils.oracle.oracle.smiles_to_rdkit_mol` | `tdc/chem_utils/oracle/oracle.py` | `smiles: str` | `tdc.chem_utils.oracle.oracle.smiles_to_rdkit_mol: Convert a SMILES string into an RDKit Mol object suitable for downstream molecular processing and molecule-generation oracles in TDC. This function parses a SMILES (Simplified Molecular-Input Line-Entry System) string into an rdkit.Chem.rdchem.Mol object and performs RDKit sanitization to detect common structural problems (for example, invalid valence). It is intended for use in TDC workflows that require a validated RDKit molecule representation prior to oracle scoring, feature extraction, graph conversion, or other cheminformatics operations described in the TDC README (for example, molecule generation oracles and data processing utilities). The function does not modify any external state; it relies on RDKit's Chem.MolFromSmiles to build the molecule and Chem.SanitizeMol to validate it. If RDKit cannot parse the SMILES or if sanitization fails (e.g., due to invalid valence), the function returns None to indicate an invalid or unusable molecule rather than raising an exception.` |
| `tdc_chem_utils_oracle_oracle_smina` | `tdc.chem_utils.oracle.oracle.smina` | `tdc/chem_utils/oracle/oracle.py` | `ligand: numpy.ndarray, protein: numpy.ndarray, score_only: bool = False, raw_input: bool = False` | `tdc.chem_utils.oracle.oracle.smina docks a ligand to a protein pocket using the smina docking executable and can be used as a molecule-generation oracle (for example, to score candidate molecules during goal-oriented molecule generation or distribution learning in TDC). The function wraps a packaged static smina binary (oracle/smina.static), accepts either raw ML-format coordinates or prewritten SDF/PDB filenames, invokes external programs (openbabel and smina), and returns a numeric docking score when requested or otherwise invokes smina for its normal side effects (console output and any files the binary writes).` |
| `tdc_chem_utils_oracle_oracle_tree_analysis` | `tdc.chem_utils.oracle.oracle.tree_analysis` | `tdc/chem_utils/oracle/oracle.py` | `current: dict` | `tdc.chem_utils.oracle.oracle.tree_analysis analyzes the JSON-like output of a retrosynthetic "tree builder" oracle used in TDC molecule-generation/oracle workflows. It extracts summary metrics that quantify whether synthesis routes were found for a query compound, how many reaction steps are implied, an aggregated plausibility score for the route(s), a binary synthesizability indicator, and a price estimate returned by the oracle. This function is used by TDC oracles and downstream evaluation code (for example, when scoring generated molecules for synthesizability and estimated synthesis cost) to convert the nested tree representation produced by synthesis planners (ASKCOS-style trees) into simple scalar and dictionary diagnostics.` |
| `tdc_evaluator_centroid` | `tdc.evaluator.centroid` | `tdc/evaluator.py` | `X: numpy.ndarray` | `tdc.evaluator.centroid computes the centroid (mean position) of all points in a vectorset X and returns that centroid value. In the Therapeutics Data Commons (TDC) context, this function is useful for summarizing the central tendency of numeric feature vectors or embeddings (for example, molecular descriptors, learned representations, or coordinate-based features) when evaluating datasets or preprocessing data for model evaluation.` |
| `tdc_evaluator_kabsch` | `tdc.evaluator.kabsch` | `tdc/evaluator.py` | `P: numpy.ndarray, Q: numpy.ndarray` | `tdc.evaluator.kabsch computes the optimal rotation matrix that rigidly aligns two sets of paired points using the Kabsch algorithm. In the Therapeutics Data Commons (TDC) context, this function is used to align paired coordinate sets such as atomic coordinates of molecular conformations or structural fragments so that downstream comparisons (for example RMSD calculation, structural matching, docking post-processing, or evaluation of conformation generators) reflect only rotational differences and not translations. The function implements the covariance-based SVD approach described by the Kabsch algorithm and returns a D x D orthonormal rotation matrix U that, when applied to P, minimizes the root-mean-square deviation between P and Q.` |
| `tdc_evaluator_kabsch_rmsd` | `tdc.evaluator.kabsch_rmsd` | `tdc/evaluator.py` | `P: numpy.ndarray, Q: numpy.ndarray, W: numpy.ndarray = None, translate: bool = False` | `tdc.evaluator.kabsch_rmsd computes the root-mean-squared deviation (RMSD) between two sets of points after finding the optimal rotation that aligns P onto Q using the Kabsch algorithm. This function is intended for comparing 3D (or D-dimensional) coordinate sets such as atomic coordinates of molecular conformations in TDC benchmarks and evaluators where structural similarity between predicted and reference conformations is required.` |
| `tdc_evaluator_kabsch_rotate` | `tdc.evaluator.kabsch_rotate` | `tdc/evaluator.py` | `P: numpy.ndarray, Q: numpy.ndarray` | `tdc.evaluator.kabsch_rotate rotates the input point set P to best align with the reference point set Q using the Kabsch algorithm. In the context of TDC (Therapeutics Data Commons), this function is typically used to align molecular point clouds or atomic coordinates (predicted vs. reference conformations) prior to computing alignment-sensitive evaluation metrics such as RMSD; it computes a rigid-body orthogonal rotation (no scaling) that minimizes mean squared deviation between corresponding points.` |
| `tdc_evaluator_kabsch_weighted` | `tdc.evaluator.kabsch_weighted` | `tdc/evaluator.py` | `P: numpy.ndarray, Q: numpy.ndarray, W: numpy.ndarray = None` | `Compute the optimal rigid-body alignment (rotation and translation) that minimizes the weighted root-mean-square deviation (RMSD) between two paired point sets using the Kabsch algorithm. This function is intended for 3-dimensional point sets and is used in TDC evaluation workflows to align predicted molecular or structural coordinates (P) to reference coordinates (Q) and to produce a single scalar RMSD metric for benchmarking model predictions (for example, aligning predicted ligand/protein atom coordinates to experimental structures before computing an RMSD-based score).` |
| `tdc_evaluator_kabsch_weighted_rmsd` | `tdc.evaluator.kabsch_weighted_rmsd` | `tdc/evaluator.py` | `P: numpy.ndarray, Q: numpy.ndarray, W: numpy.ndarray = None` | `Compute the weighted root-mean-square deviation (RMSD) between two sets of points P and Q after optimal rigid-body alignment using the weighted Kabsch algorithm. This function is used in structural comparison tasks common in therapeutics and molecular modeling within TDC (for example, comparing predicted ligand or protein atom coordinates to reference structures to evaluate pose prediction or conformational similarity). The function delegates the core computation to kabsch_weighted and returns the scalar weighted RMSD value computed from the aligned coordinates.` |
| `tdc_evaluator_range_logAUC` | `tdc.evaluator.range_logAUC` | `tdc/evaluator.py` | `true_y: numpy.ndarray, predicted_score: numpy.ndarray, FPR_range: tuple = (0.001, 0.1)` | `Calculate the log-scaled area under the ROC curve (logAUC) restricted to a specified false positive rate (FPR) interval. This function is used in Therapeutics Data Commons (TDC) to evaluate binary classifiers for molecule prioritization and virtual screening in drug discovery, where only a small fraction of top-ranked candidates can be experimentally tested. By integrating the ROC curve on a logarithmic FPR axis over a small FPR_range (default (0.001, 0.1)), the metric emphasizes classifier performance at very low FPRs (the left side of the ROC curve), which corresponds to selecting only the highest-scoring compounds for costly follow-up experiments. A perfect classifier attains a logAUC of 1 on the default range; a random classifier achieves approximately 0.0215 on that same range (see References in the original implementation).` |
| `tdc_evaluator_rmsd` | `tdc.evaluator.rmsd` | `tdc/evaluator.py` | `V: numpy.ndarray, W: numpy.ndarray` | `tdc.evaluator.rmsd calculates the root-mean-square deviation (RMSD) between two sets of vectors. In the Therapeutics Data Commons (TDC) context, this function is used as a numeric evaluator to quantify average Euclidean deviation between predicted and reference vector representations (for example, predicted molecular coordinates, embeddings, or other D-dimensional descriptors) across N points. The implementation computes RMSD as sqrt(sum((V - W)**2) / N), where N is the number of points (rows) in V. The function converts its inputs to numpy arrays internally and returns a single scalar RMSD value that can be used to compare model predictions to ground truth in benchmarking and evaluation workflows.` |
| `tdc_model_server_tokenizers_scgpt_tokenize_batch` | `tdc.model_server.tokenizers.scgpt.tokenize_batch` | `tdc/model_server/tokenizers/scgpt.py` | `data: numpy.ndarray, gene_ids: numpy.ndarray, return_pt: bool = True, append_cls: bool = True, include_zero_gene: bool = False, cls_id: str = "<cls>"` | `Tokenize a batch of single-cell or bulk gene-expression vectors into per-sample token sequences suitable for the SCGPT tokenizer used by the TDC model server. This function converts each row in data (one sample / cell per row) into a sequence of gene identifiers and their corresponding expression counts; by default it maps gene identifiers to integer token ids using a downloaded "scgpt_vocab" vocabulary and returns PyTorch tensors for downstream SCGPT model input preparation in therapeutics workflows (for example, representing expressed genes per cell for input to models used in target discovery, activity screening, or other TDC tasks).` |
| `tdc_utils_label_binarize` | `tdc.utils.label.binarize` | `tdc/utils/label.py` | `y: list, threshold: float, order: str = "ascending"` | `Binarization of a label list given a pre-specified numeric threshold for use in TDC data processing and label transformation pipelines. This function converts a list of continuous or ordinal labels into binary labels (0/1) according to a threshold. It is used in TDC's data processing utilities when transforming regression-style or scored outputs into binary classes for downstream single-instance prediction tasks, leaderboard evaluation, or classifier training. The output is a new numpy array of integer 0/1 values and the input list is not modified in place.` |
| `tdc_utils_label_convert_back_log` | `tdc.utils.label.convert_back_log` | `tdc/utils/label.py` | `y: list` | `tdc.utils.label.convert_back_log: Convert a list of labels that are in log-scale ("p" units) back to linear nanomolar ("nM") concentration labels.` |
| `tdc_utils_label_convert_to_log` | `tdc.utils.label.convert_to_log` | `tdc/utils/label.py` | `y: list` | `Convert labels from nanomolar concentration units to negative-log "p" scale used in TDC label processing. This helper is part of TDC's data processing utilities for label transformation and is used when models and evaluation metrics expect potency or concentration labels on a logarithmic "p" scale (for example, converting IC50/EC50 values reported in nanomolar to pIC50-like values). The function converts the input list to a NumPy array and delegates the unit and log conversion to convert_y_unit by calling convert_y_unit(np.array(y), "nM", "p"). The operation is pure (no external side effects) and returns a NumPy array of float log-transformed labels suitable for downstream machine learning pipelines in TDC.` |
| `tdc_utils_label_convert_y_unit` | `tdc.utils.label.convert_y_unit` | `tdc/utils/label.py` | `y: list, from_: str, to_: str` | `label unit conversion helper function used in TDC data processing to standardize assay labels between nanomolar concentration units and negative-log molar ("p") units for downstream model training, evaluation, and leaderboard submission. This function is used in the TDC pipeline to convert lists of measured activity labels (for example, IC50/EC50 values reported in nanomolar or pIC-like units) so that datasets and evaluators operate on consistent units.` |
| `tdc_utils_label_label_dist` | `tdc.utils.label.label_dist` | `tdc/utils/label.py` | `y: list, name: str = None` | `tdc.utils.label.label_dist plots the distribution of a list of labels (y) using seaborn and matplotlib so users of the Therapeutics Data Commons (TDC) can visually inspect label properties such as skewness, central tendency, spread, and outliers for datasets used in therapeutic machine-learning tasks.` |
| `tdc_utils_label_label_transform` | `tdc.utils.label.label_transform` | `tdc/utils/label.py` | `y: list, binary: bool, threshold: float, convert_to_log: bool, verbose: bool = True, order: str = "descending"` | `tdc.utils.label.label_transform transforms a list of raw labels used in TDC benchmarks into a numpy array suitable for downstream evaluation or model training by optionally performing binarization or log-scale conversion. This helper function is used in TDC data processing workflows to prepare target values from datasets (for example continuous biochemical measurements such as Kd or IC50 reported in nM) into either binary class labels for classification tasks or into a log-transformed scale commonly used in pharmacology (e.g., p-scale). It is intended to be called by dataset loaders or preprocessing pipelines when a task requires label normalization or thresholding.` |
| `tdc_utils_load_atom_to_one_hot` | `tdc.utils.load.atom_to_one_hot` | `tdc/utils/load.py` | `atom: str, allowed_atom_list: list` | `tdc.utils.load.atom_to_one_hot converts a chemical atom label into a one-hot encoded numpy vector suitable for use in TDC molecular featurization pipelines and downstream machine learning models. This helper is used when building per-atom feature vectors (for example in graph-based molecular representations) where each allowed atom type is represented by a unique index and the function produces a vector with a single 1 at that index and 0s elsewhere.` |
| `tdc_utils_load_bi_distribution_dataset_load` | `tdc.utils.load.bi_distribution_dataset_load` | `tdc/utils/load.py` | `name: str, path: str, dataset_names: list, return_pocket: bool = False, threshold: int = 15, remove_protein_Hs: bool = True, remove_ligand_Hs: bool = True, keep_het: bool = False` | `tdc.utils.load.bi_distribution_dataset_load loads and returns processed protein-ligand datasets used for conditional molecular (bi-distribution) generation tasks in TDC. It is a high-level wrapper that accepts a rough dataset name, resolves it against available exact dataset names, optionally triggers downloading/unzipping of dataset archives, calls dataset-specific processing routines (for example, PDBBind, DUD-E, SCPDB, CrossDock), and returns the processed protein and ligand representations that downstream conditional generation models and evaluations consume.` |
| `tdc_utils_load_bm_download_wrapper` | `tdc.utils.load.bm_download_wrapper` | `tdc/utils/load.py` | `name: str, path: str` | `tdc.utils.load.bm_download_wrapper: Download and prepare a benchmark group for use in the Therapeutics Data Commons (TDC) benchmarks. This function resolves a user-provided approximate benchmark group name to the exact benchmark identifier used by the TDC registry, downloads the corresponding dataset archive from the Harvard Dataverse API, extracts it into a local directory, and returns the resolved exact benchmark group query name. In the TDC domain this is used to obtain benchmark groups (collections of dataset files and metadata) that are required for training, evaluation, and leaderboard submission workflows for therapeutic machine learning tasks.` |
| `tdc_utils_load_bm_group_load` | `tdc.utils.load.bm_group_load` | `tdc/utils/load.py` | `name: str, path: str` | `bm_group_load loads a benchmark group by downloading, processing, and making its files available under a local path. This utility is a thin wrapper around the internal bm_download_wrapper function and is used by TDC workflows to retrieve curated benchmark groups (for example, ADMET_Group) so they can be used for dataset splits, model training, and leaderboard submission as described in the TDC README.` |
| `tdc_utils_load_dataverse_download` | `tdc.utils.load.dataverse_download` | `tdc/utils/load.py` | `url: str, path: str, name: str, types: dict, id: int = None` | `dataverse_download downloads a dataset file from a Dataverse-style URL to local disk with a streaming progress bar and a deterministic filename pattern used by TDC dataset loaders.` |
| `tdc_utils_load_distribution_dataset_load` | `tdc.utils.load.distribution_dataset_load` | `tdc/utils/load.py` | `name: str, path: str, dataset_names: list, column_name: str` | `tdc.utils.load.distribution_dataset_load loads a single column of molecule representations for a distribution learning dataset after ensuring the dataset file is available locally. This function is a thin wrapper used in the Therapeutics Data Commons (TDC) to (1) resolve and, if necessary, download a distribution learning dataset using download_wrapper, (2) load the dataset into a pandas DataFrame using pd_load, and (3) return the specified column that contains molecule representations used for distribution learning (for example, SMILES strings typically used by TDC oracles). The function assumes the downloaded file is already processed into a table-like format with a column that holds molecule representations; it does not further process or validate per-entry molecular formats.` |
| `tdc_utils_load_download_wrapper` | `tdc.utils.load.download_wrapper` | `tdc/utils/load.py` | `name: str, path: str, dataset_names: list` | `Concise wrapper to locate and download a TDC dataset file (csv, pkl, or tsv) from the Harvard Dataverse given a fuzzy query name, saving it under a local directory. This function is used by the Therapeutics Data Commons (TDC) data loaders to resolve a user-provided dataset query into the exact dataset name present in the TDC name registries, create the target directory if missing, check for an existing local copy, and call the Dataverse download helper to retrieve one or more files for that dataset.` |
| `tdc_utils_load_general_load` | `tdc.utils.load.general_load` | `tdc/utils/load.py` | `name: str, path: str, sep: str` | `tdc.utils.load.general_load downloads (if necessary), processes, and loads a TDC dataset file into a pandas.DataFrame. This utility is used within the TDC (Therapeutics Data Commons) data-loading workflow to retrieve any dataset registered in TDC, making it available for downstream model training, evaluation, and benchmark submission as described in the TDC README. The function delegates fetching and pre-processing to the internal download_wrapper, determines the file extension using the module-level name2type mapping, prints a brief status message, and then reads the saved file using pandas.read_csv with the provided separator. It performs no further content validation beyond what pandas.read_csv enforces.` |
| `tdc_utils_load_generation_dataset_load` | `tdc.utils.load.generation_dataset_load` | `tdc/utils/load.py` | `name: str, path: str, dataset_names: list` | `tdc.utils.load.generation_dataset_load loads a processed dataset for a generation task in TDC, optionally downloading it first and returning the dataset columns used for generative model training and evaluation. This function is a thin wrapper that (1) selects or downloads a dataset by delegating to download_wrapper, (2) prints a progress message via print_sys, and (3) loads the processed dataset file via pd_load. It is intended for use with TDC's "generation" problem (generation of new desirable biomedical entities such as molecules or sequences) and returns the two pandas Series columns commonly used by generation benchmarks: an "input" series (conditioning inputs or prompts) and a "target" series (the desired generated entities, e.g., SMILES strings). Typical usage is to obtain training/validation/test inputs and targets for molecule generation oracles and leaderboards in TDC.` |
| `tdc_utils_load_generation_paired_dataset_load` | `tdc.utils.load.generation_paired_dataset_load` | `tdc/utils/load.py` | `name: str, path: str, dataset_names: list, input_name: str, output_name: str` | `tdc.utils.load.generation_paired_dataset_load loads and returns paired data series for a generation task from TDC datasets, handling download, local caching, and DataFrame column extraction for paired inputs and outputs used in generation problems (for example, scaffold-to-molecule or precursor-to-product pairs in molecular generation benchmarks).` |
| `tdc_utils_load_multi_dataset_load` | `tdc.utils.load.multi_dataset_load` | `tdc/utils/load.py` | `name: str, path: str, dataset_names: list` | `Summary: Load a processed multi-instance prediction dataset for TDC (Therapeutics Data Commons). This function is a thin wrapper that ensures a dataset file for multi-instance (>2) prediction tasks is available on disk (under the provided path) and then reads it into a pandas.DataFrame for downstream use in model training, evaluation, or further TDC data functions. It is intended for datasets in the TDC "multi_pred" problem tier, where each sample consists of multiple biomedical entities (for example, combinatorial therapies or multi-drug experiments) and where the on-disk file is already in a processed, model-ready tabular format.` |
| `tdc_utils_load_oracle_download_wrapper` | `tdc.utils.load.oracle_download_wrapper` | `tdc/utils/load.py` | `name: str, path: str, oracle_names: list` | `Wrapper to locate and (if needed) download a TDC molecule-generation oracle model checkpoint into a local directory and return the canonical oracle name.` |
| `tdc_utils_load_oracle_load` | `tdc.utils.load.oracle_load` | `tdc/utils/load.py` | `name: str, path: str = "./oracle", oracle_names: list = ['drd2', 'gsk3b', 'jnk3', 'fpscores', 'cyp3a4_veith', 'drd2_current', 'gsk3b_current', 'jnk3_current', 'qed', 'logp', 'sa', 'rediscovery', 'similarity', 'median', 'isomers', 'mpo', 'hop', 'celecoxib_rediscovery', 'troglitazone_rediscovery', 'thiothixene_rediscovery', 'aripiprazole_similarity', 'albuterol_similarity', 'mestranol_similarity', 'isomers_c7h8n2o2', 'isomers_c9h10n2o2pf2cl', 'isomers_c11h24', 'osimertinib_mpo', 'fexofenadine_mpo', 'ranolazine_mpo', 'perindopril_mpo', 'amlodipine_mpo', 'sitagliptin_mpo', 'zaleplon_mpo', 'sitagliptin_mpo_prev', 'zaleplon_mpo_prev', 'median1', 'median2', 'valsartan_smarts', 'deco_hop', 'scaffold_hop', 'novelty', 'diversity', 'uniqueness', 'validity', 'fcd_distance', 'kl_divergence', 'askcos', 'ibm_rxn', 'isomer_meta', 'rediscovery_meta', 'similarity_meta', 'median_meta', 'docking_score', 'molecule_one_synthesis', 'pyscreener', 'rmsd', 'kabsch_rmsd', 'smina', '1iep_docking', '2rgp_docking', '3eml_docking', '3ny8_docking', '4rlu_docking', '4unn_docking', '5mo4_docking', '7l11_docking', 'drd3_docking', '3pbl_docking', '1iep_docking_normalize', '2rgp_docking_normalize', '3eml_docking_normalize', '3ny8_docking_normalize', '4rlu_docking_normalize', '4unn_docking_normalize', '5mo4_docking_normalize', '7l11_docking_normalize', 'drd3_docking_normalize', '3pbl_docking_normalize', '1iep_docking_vina', '2rgp_docking_vina', '3eml_docking_vina', '3ny8_docking_vina', '4rlu_docking_vina', '4unn_docking_vina', '5mo4_docking_vina', '7l11_docking_vina', 'drd3_docking_vina', '3pbl_docking_vina']` | `tdc.utils.load.oracle_load is a convenience wrapper that resolves a user-provided, possibly imprecise oracle name to an exact oracle identifier, downloads any required oracle assets to local storage, performs any required processing, and returns the canonical oracle name. In the Therapeutics Data Commons (TDC) workflow, oracles are functions or datasets used by molecule generation tasks (goal-oriented and distribution-learning), and this function centralizes retrieval and local caching of those oracles so downstream code (for example, Oracle(...) callers or molecule generation pipelines) can instantiate and use them reproducibly. This function attempts to match the rough oracle name supplied by the caller against a known collection of exact oracle names (the oracle_names list provided by the module). If a match is found, the underlying oracle_download_wrapper is invoked to download and/or prepare the oracle assets into the filesystem path specified by path. Side effects include creating the target directory (path) if it does not exist and writing downloaded oracle files into that location. The function returns the resolved exact oracle name (a str) so callers can programmatically verify which oracle was loaded and pass that canonical name to other TDC utilities (for example, Oracle instantiation or benchmark bookkeeping). Note on defaults: path defaults to "./oracle" (a relative directory in the current working directory), and oracle_names defaults to the module-level list of available exact oracle names exposed by tdc.utils.load. The provided oracle_names list contains many commonly used oracles in TDC (e.g., property scorers, rediscovery and similarity tasks, MPO and docking-related oracles) and is used to disambiguate user inputs such as partial names or common aliases. Failure modes and exceptions: if the provided name cannot be resolved to any exact oracle name in oracle_names, or if the underlying download/processing fails (for example due to network errors, permission errors, or missing external dependencies), the underlying oracle_download_wrapper may raise an exception which is propagated to the caller. Callers should handle exceptions (e.g., ValueError, OSError, or network-related exceptions) as appropriate for their application to recover or to report the error. The function does not itself suppress or convert such exceptions.` |
| `tdc_utils_load_pd_load` | `tdc.utils.load.pd_load` | `tdc/utils/load.py` | `name: str, path: str` | `Load a local TDC dataset file into a pandas DataFrame for downstream model training, evaluation, and benchmark workflows in the Therapeutics Data Commons (TDC) suite. This function is used by TDC data loaders to materialize a saved dataset (by dataset name and local path) into an in-memory object that machine-learning workflows expect. It determines the file format from the internal mapping name2type and supports multiple file formats commonly used by TDC datasets.` |
| `tdc_utils_load_process_crossdock` | `tdc.utils.load.process_crossdock` | `tdc/utils/load.py` | `path: str, name: str = "crossdock", return_pocket: bool = False, threshold: int = 15, remove_protein_Hs: bool = True, remove_ligand_Hs: bool = True, keep_het: bool = False` | `tdc.utils.load.process_crossdock processes the CrossDock protein‚Äìligand docking benchmark and returns paired protein and ligand feature dictionaries suitable for downstream machine-learning workflows in therapeutics (e.g., pocket-based docking, binding-site modeling, and GNNs on protein‚Äìligand complexes). This function reads a preprocessed CrossDock dataset directory (for example, the layout produced by Luo et al., 2021, which stores pocket PDBs and ligand SDFs and an index.pkl). It uses RDKit to parse ligand molecules and Biopandas to parse PDB files, optionally strips hydrogen atoms, and aggregates per-complex atomic coordinates and atom-type annotations. The returned structures are lightweight Python dictionaries where each entry corresponds to one successfully processed complex from the CrossDock index. The function swallows individual parsing errors (counts them) and prints a short processing summary. This processor is intended to prepare CrossDock data for ML evaluation and model training as provided by the TDC benchmarks.` |
| `tdc_utils_load_process_pdbbind` | `tdc.utils.load.process_pdbbind` | `tdc/utils/load.py` | `path: str, name: str = "pdbbind", return_pocket: bool = False, threshold: int = 15, remove_protein_Hs: bool = True, remove_ligand_Hs: bool = True, keep_het: bool = False` | `tdc.utils.load.process_pdbbind processes a local PDBBind-style dataset directory and extracts per-complex protein and ligand atomic features suitable for downstream machine learning tasks in the Therapeutics Data Commons (TDC) ecosystem. This function expects a directory structure where each complex is stored in a subdirectory named by its PDBBind identifier and contains protein PDB files and ligand SDF files following the naming conventions used in PDBBind (e.g., "{id}/{id}_protein.pdb", "{id}/{id}_pocket.pdb", "{id}/{id}_ligand.sdf"). It reads protein coordinates using biopandas.PandasPdb and ligand molecules using RDKit, then delegates atom extraction and optional hydrogen removal to helper functions (extract_atom_from_protein and extract_atom_from_mol). The outputs are two dictionaries (protein and ligand) that collect per-complex coordinate arrays and atom-type lists; these are intended for use in TDC workflows that require numeric atomic coordinates and atom-type labels for model input, dataset split creation, and evaluation. Behavior and notable implementation details: - The function iterates over files in the given path using tqdm for progress reporting and ignores files named "readme" or "index". - If return_pocket is True, the function attempts to read the pocket PDB file named "{id}/{id}_pocket.pdb"; otherwise it reads "{id}/{id}_protein.pdb". - The threshold parameter is provided to control a pocket radius in the conceptual API (i.e., radius around ligand center to define a pocket) when pockets must be computed from full proteins, but in the current implementation threshold is not used; pocket selection is enacted only by reading precomputed pocket PDB files when return_pocket is True. - remove_protein_Hs and remove_ligand_Hs control whether hydrogen atoms are removed from the parsed protein or ligand prior to assembling coordinates and types; removal is implemented by the helper extraction functions. - keep_het controls whether HETATM records from the PDB (commonly cofactors or nonstandard residues) are included when extracting protein atoms. - Ligands are read from SDF files via RDKit with sanitize=False; if the helper extract_atom_from_mol deems a ligand contains unallowed atoms it may return None and that complex will be skipped. - The function suppresses exceptions raised while processing individual complexes (bare except), counts failures, and continues processing other files; after processing it prints the number of failed files. - If the provided path does not exist, the function terminates the process by calling sys.exit("Wrong path!"). - The function disables RDKit logging (RDLogger.DisableLog("rdApp.*")) and imports biopandas at runtime; missing dependencies (RDKit, biopandas) will raise ImportError at call time. - The function prints a "Processing..." message at start and a summary "processing done, {failure}/{total_ct} fails" at the end via print_sys; these side-effecting prints are intended to inform users during long-running preprocessing.` |
| `tdc_utils_load_process_scpdb` | `tdc.utils.load.process_scpdb` | `tdc/utils/load.py` | `path: str, name: str = "scPDB", return_pocket: bool = False, threshold: int = 15, remove_protein_Hs: bool = True, remove_ligand_Hs: bool = True, keep_het: bool = False` | `tdc.utils.load.process_scpdb processes the scPDB protein‚Äìligand structural dataset into two Python dictionaries of parsed features suitable for downstream machine-learning workflows in TDC (for example, creating per-complex coordinate and atom-type inputs for binding-site or pocket modeling). This function traverses a directory of scPDB entries, reads per-entry protein MOL2 files and ligand SDF files, extracts atom coordinates and atom types, and aggregates those features across all successfully parsed entries. It is intended for preparatory data processing in therapeutic-ML tasks (e.g., single-instance prediction and pocket-level analyses) that use structural protein‚Äìligand complexes from the scPDB resource. The implementation expects the scPDB data to be organized under path/name with one subdirectory per complex containing either site.mol2 (when return_pocket=True) or protein.mol2 (when return_pocket=False) and ligand.sdf. The function uses RDKit and biopandas.mol2 to read molecules and relies on helper functions extract_atom_from_mol and extract_atom_from_protein to produce coordinate and atom-type lists.` |
| `tdc_utils_load_property_dataset_load` | `tdc.utils.load.property_dataset_load` | `tdc/utils/load.py` | `name: str, path: str, target: str, dataset_names: list` | `tdc.utils.load.property_dataset_load loads a single-instance prediction dataset for Therapeutics Data Commons (TDC), performing download (via download_wrapper), column alignment, duplicate-column removal, and filtering so the caller receives three pandas.Series objects suitable for machine learning workflows (entity representation X, target labels y, and unique entity IDs). This function is used across TDC single-instance prediction tasks (for example ADME or activity screening datasets) to obtain the canonical input representation (e.g., molecule SMILES or sequence strings), the label of interest for supervised learning, and an identifier for each entity for traceability and leaderboard submission.` |
| `tdc_utils_load_receptor_download_wrapper` | `tdc.utils.load.receptor_download_wrapper` | `tdc/utils/load.py` | `name: str, path: str` | `receptor_download_wrapper(name, path) Wrapper that ensures a receptor structure (PDB and PDBQT) is available locally for TDC docking/oracle workflows by downloading files from the Harvard Dataverse when needed. This function is used in Therapeutics Data Commons (TDC) workflows that require receptor structures (for example, docking or molecule-generation oracle evaluation). Given an exact PDB identifier (pdbid) and a target filesystem path, the function checks for existing local copies of both the PDB and PDBQT files, creates the target directory if missing, and otherwise downloads the two files from a configured Harvard Dataverse endpoint. The function uses an internal mapping receptor2id to look up dataverse file identifiers and calls dataverse_download to fetch files; it prints progress messages via print_sys. On success the function returns the same pdbid string that was provided, allowing callers to confirm which receptor was prepared.` |
| `tdc_utils_load_receptor_load` | `tdc.utils.load.receptor_load` | `tdc/utils/load.py` | `name: str, path: str = "./oracle"` | `tdc.utils.load.receptor_load downloads, processes, and loads a receptor PDB file given a rough PDB identifier. It is a thin wrapper around receptor_download_wrapper that resolves a user-provided rough pdb name to the canonical PDB identifier used by TDC, saves the processed receptor file(s) under the specified oracle directory, and returns the exact resolved PDB identifier. In the TDC (Therapeutics Data Commons) workflow, this function is used when preparing receptor structures for downstream tasks such as molecule-generation oracles, docking, or structure-based scoring that require canonical receptor PDB files stored in the project's oracle directory.` |
| `tdc_utils_load_three_dim_dataset_load` | `tdc.utils.load.three_dim_dataset_load` | `tdc/utils/load.py` | `name: str, path: str, dataset_names: list` | `three_dim_dataset_load downloads (if necessary), processes, and loads a 3D molecular dataset for TDC 3D-molecule tasks and returns the loaded data plus the resolved dataset path and exact dataset name. This function is used within the Therapeutics Data Commons (TDC) ecosystem to obtain TDC benchmark datasets that contain three-dimensional molecular information needed for structure-aware machine learning workflows (for example, tasks that require atomic coordinates, conformer information, or structure-based feature extraction). Internally, the function calls zip_data_download_wrapper to select and/or download the exact dataset from the available dataset_names into the provided path, prints a loading message, and then uses pd_load to read the stored dataset into a pandas.DataFrame.` |
| `tdc_utils_load_zip_data_download_wrapper` | `tdc.utils.load.zip_data_download_wrapper` | `tdc/utils/load.py` | `name: str, path: str, dataset_names: list` | `tdc.utils.load.zip_data_download_wrapper downloads and unpacks a TDC dataset archive from the Harvard Dataverse given a fuzzy dataset query name, saving and extracting the dataset into a local directory structure used by TDC data loaders.` |
| `tdc_utils_misc_fuzzy_search` | `tdc.utils.misc.fuzzy_search` | `tdc/utils/misc.py` | `name: str, dataset_names: str` | `Fuzzy matching between a user-provided dataset name and the canonical dataset name used by the TDC (Therapeutics Data Commons) library. This function is used inside TDC data-loading and utility workflows to resolve minor differences in user input (case differences, an optional "tdc." prefix, or small typographical variations) to the exact dataset identifier that TDC expects when retrieving a dataset, evaluating a benchmark, or recording leaderboard submissions.` |
| `tdc_utils_misc_get_closet_match` | `tdc.utils.misc.get_closet_match` | `tdc/utils/misc.py` | `predefined_tokens: list, test_token: str, threshold: float = 0.8` | `Get the closest match for a user-provided token against a list of predefined tokens using Levenshtein-based similarity. This function is used in TDC utilities to robustly map free-form user inputs (for example, dataset names, task names, or configuration keys supplied to TDC data loaders or functions) to canonical tokens accepted by the library. It computes a case-insensitive Levenshtein similarity score (via fuzzywuzzy.fuzz.ratio) between the string form of each predefined token and the provided test_token, returns the predefined token with the highest similarity and the corresponding normalized score in [0.0, 1.0]. The function helps prevent user input errors by suggesting the closest valid token and by enforcing a minimum similarity threshold to accept a match; if the best match is below the threshold it prints available tokens (via print_sys) and raises a ValueError so callers can handle invalid inputs explicitly.` |
| `tdc_utils_misc_install` | `tdc.utils.misc.install` | `tdc/utils/misc.py` | `package: str` | `Install a pip package into the Python interpreter that is running the current process. This function is a thin utility used in the TDC (Therapeutics Data Commons) codebase to programmatically ensure that a required or optional Python package is available at runtime. It invokes the pip module using the same Python executable that launched the process (sys.executable) by calling subprocess.check_call([sys.executable, "-m", "pip", "install", package]). In the TDC domain, this is useful for installing optional dependencies needed by specific data loaders, data functions, or oracles so that downstream dataset retrieval and processing functions can run without manual intervention. The call is executed synchronously and blocks until pip completes; pip's normal output and error streams are forwarded to the current process.` |
| `tdc_utils_misc_load_dict` | `tdc.utils.misc.load_dict` | `tdc/utils/misc.py` | `path: str` | `tdc.utils.misc.load_dict: Load and return a Python object previously serialized with pickle from a local filesystem path. Opens the file at the given path in binary read mode and deserializes its contents using pickle.load. The file handle is managed with a context manager and is closed automatically when loading completes. In the Therapeutics Data Commons (TDC) project, this helper is used to restore persisted Python objects such as cached dataset splits, preprocessed data artifacts, or metadata produced by TDC data loaders and data functions so that downstream machine-learning experiments and evaluations can resume without recomputation.` |
| `tdc_utils_misc_print_sys` | `tdc.utils.misc.print_sys` | `tdc/utils/misc.py` | `s: str` | `tdc.utils.misc.print_sys: Print a string to the process standard error stream and flush immediately. This utility function is provided in the Therapeutics Data Commons (TDC) codebase to emit messages to the operating system's standard error stream (sys.stderr). It is used within TDC to report warnings, errors, or system-level status messages that should be separated from normal program output or machine-readable output (for example, when command output is being piped or captured). The implementation uses Python's built-in print with flush=True and file=sys.stderr to guarantee immediate delivery of the text to stderr.` |
| `tdc_utils_misc_to_submission_format` | `tdc.utils.misc.to_submission_format` | `tdc/utils/misc.py` | `results: dict` | `Convert evaluation results into a submission-ready summary for TDC leaderboards.` |
| `tdc_utils_query_cid2smiles` | `tdc.utils.query.cid2smiles` | `tdc/utils/query.py` | `cid: str` | `tdc.utils.query.cid2smiles retrieves a canonical SMILES string for a small molecule identified by a PubChem Compound ID (CID). This function is used in TDC data-processing and dataset workflows to translate PubChem numeric identifiers into the molecular representation (SMILES) required by downstream components such as data loaders, oracles, and model inputs.` |
| `tdc_utils_query_uniprot2seq` | `tdc.utils.query.uniprot2seq` | `tdc/utils/query.py` | `ProteinID: str` | `tdc.utils.query.uniprot2seq: Retrieve the amino-acid sequence string for a protein from the UniProt web service given a UniProt identifier. This function performs a synchronous HTTP GET to the UniProt FASTA endpoint, reads the returned FASTA file, strips the FASTA header (first line) and concatenates the remaining lines into a single continuous amino-acid sequence string. In the Therapeutics Data Commons (TDC) workflow, this is useful when a dataset or task requires the primary sequence of a protein (for example, for single-instance prediction tasks, feature extraction, or linking UniProt entries to sequence-based models).` |
| `tdc_utils_retrieve_get_label_map` | `tdc.utils.retrieve.get_label_map` | `tdc/utils/retrieve.py` | `name: str, path: str = "./data", target: str = None, file_format: str = "csv", output_format: str = "dict", task: str = "DDI", name_column: str = "Map"` | `Retrieve the biomedical meaning of encoded labels for a TDC dataset and return the mapping in a user-specified format.` |
| `tdc_utils_retrieve_get_reaction_type` | `tdc.utils.retrieve.get_reaction_type` | `tdc/utils/retrieve.py` | `name: str, path: str = "./data", output_format: str = "array"` | `Retrieve the reaction type labels for a RetroSyn reaction dataset. This function is used within the TDC (Therapeutics Data Commons) workflow to obtain reaction-category labels from a reaction dataset (specifically those indexed under the RetroSyn collection). It first performs a fuzzy match of the provided dataset name against known RetroSyn dataset names (via fuzzy_search) to find the canonical dataset identifier, then loads the dataset from disk using pd_load. The loaded dataset is expected to contain a "category" column that encodes the reaction type for each record; these reaction-type labels are commonly used for reaction classification, retrosynthesis evaluation, and other reaction-prediction tasks in drug discovery workflows supported by TDC.` |
| `tdc_utils_retrieve_retrieve_benchmark_names` | `tdc.utils.retrieve.retrieve_benchmark_names` | `tdc/utils/retrieve.py` | `name: str` | `tdc.utils.retrieve.retrieve_benchmark_names returns all benchmark dataset names associated with a queried benchmark group registered in TDC. This function is used by higher-level TDC utilities and user code to enumerate available benchmarks (datasets) that belong to a logically defined benchmark group (for example, 'ADMET_Group' as used in TDC leaderboards and examples in the README). It performs a fuzzy match of the provided group name against the internal benchmark registry and then collects dataset names from every learning task contained in the matched group so downstream code can present, iterate over, or submit results for those benchmarks.` |
| `tdc_utils_retrieve_retrieve_dataset_names` | `tdc.utils.retrieve.retrieve_dataset_names` | `tdc/utils/retrieve.py` | `name: str` | `Return all available dataset names for a given TDC learning task. This function looks up the module-level mapping dataset_names and returns the list of dataset identifiers that belong to the specified learning task in the Therapeutics Data Commons (TDC) hierarchy. In the TDC domain, tasks correspond to high-level learning problems (for example, the single-instance prediction task 'ADME') and each task exposes multiple dataset variants (for example, 'HIA_Hou'). The returned dataset names are intended to be used when instantiating dataset loaders (for example, passing a name to a task-specific constructor such as ADME(name='HIA_Hou')) or when enumerating available benchmarks for model development, evaluation, and leaderboard submission.` |
| `tdc_utils_retrieve_retrieve_label_name_list` | `tdc.utils.retrieve.retrieve_label_name_list` | `tdc/utils/retrieve.py` | `name: str` | `tdc.utils.retrieve.retrieve_label_name_list: Return the set of available label (target) names for a given TDC dataset. This function is part of the Therapeutics Data Commons (TDC) utilities for dataset discovery and metadata inspection. It accepts a rough dataset name provided by a user or higher-level code, uses a fuzzy lookup against the internal registry of dataset identifiers (via fuzzy_search and the module-level dataset_list), and returns the canonical list of target/label names that the matched dataset exposes. In the TDC domain, these label names identify the prediction targets used for model training, validation, testing, evaluation, and downstream tasks such as metric computation, data processing, and oracle scoring for drug discovery and therapeutic ML benchmarks.` |
| `tdc_utils_split_create_combination_generation_split` | `tdc.utils.split.create_combination_generation_split` | `tdc/utils/split.py` | `dict1: dict, dict2: dict, seed: int, frac: list` | `Create a random train/validation/test split for paired protein‚Äìligand coordinate and atom-type datasets used in TDC combination generation tasks. This function is intended for the "generation" problem in TDC where each example is a paired combination (e.g., a protein and a ligand) represented by coordinates and atom-type lists. It permutes example indices using NumPy's RNG, then slices the permuted index array according to the provided train/validation/test fractions to produce three partition dictionaries. The returned structure is suitable for downstream molecule- or complex-generation workflows (for example, goal-oriented or distribution-learning oracles in TDC) that require aligned protein and ligand inputs for each split.` |

## ‚öñÔ∏è License

Original Code License: MIT

Wrapper Code & Documentation: Apache-2.0

*This file was automatically generated on February 26, 2026.*
