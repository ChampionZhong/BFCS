# monai

[ðŸ”™ Back to Main Repo](../../../README.md) | [ðŸ”— Original Repo](https://github.com/Project-MONAI/MONAI)

![Tool Count](https://img.shields.io/badge/Agent_Tools-96-blue?style=flat-square)
![Category](https://img.shields.io/badge/Category-Medicine-green?style=flat-square)
![Status](https://img.shields.io/badge/Import_Test-Passed-success?style=flat-square)

## ðŸ“– Overview

MONAI is an open-source, PyTorch-based framework that provides end-to-end tools (data preprocessing, model architectures, training workflows, and evaluation utilities) for deep learning on medical and healthcare imaging data.

> **Note**: This documentation lists the **agent-ready wrapper functions** generated for this package. These functions have been strictly typed, docstring-enhanced, and tested for import stability within a standardized Apptainer environment.

## ðŸ› ï¸ Available Agent Tools

Below is the list of **96** functions optimized for LLM tool-use.

| **Tool Name (Wrapper)**   | **Source**          | **File Path**     | **Arguments (Type)**        | **Description**                |
| ------------------------- | ------------------- | ----------------- | --------------------------- | ------------------------------ |
| `monai_apps_auto3dseg_utils_get_name_from_algo_id` | `monai.apps.auto3dseg.utils.get_name_from_algo_id` | `monai/apps/auto3dseg/utils.py` | `id: str` | `Extract the algorithm name from an algorithm identifier used by MONAI's auto3dseg utilities. This utility is used in MONAI (a PyTorch-based framework for medical imaging) to parse compact algorithm identifiers that follow a convention used in Auto3DSeg workflows, model bundles, and the MONAI Model Zoo. Given an identifier that encodes the algorithm name, the cross-validation fold, and other metadata (conventionally "name_fold_other"), this function returns the human-meaningful algorithm name portion for use in experiment naming, logging, grouping results by algorithm across folds, and other bookkeeping tasks in 3D medical image segmentation pipelines.` |
| `monai_apps_nnunet_nnunet_bundle_convert_monai_bundle_to_nnunet` | `monai.apps.nnunet.nnunet_bundle.convert_monai_bundle_to_nnunet` | `monai/apps/nnunet/nnunet_bundle.py` | `nnunet_config: dict, bundle_root_folder: str, fold: int = 0` | `Convert a MONAI bundle to nnU-Net format for use in nnU-Net training and inference workflows in medical imaging. This function reads MONAI bundle checkpoint and metadata files from a bundle_root_folder, extracts and re-structures optimizer state and network weights, creates the expected nnU-Net folder layout under the nnUNet_results environment path, writes nnU-Net style checkpoint files (checkpoint_final.pth and checkpoint_best.pth), and copies required dataset and plan JSON files so the result can be consumed by nnU-Net training/evaluation code.` |
| `monai_apps_nnunet_nnunet_bundle_convert_nnunet_to_monai_bundle` | `monai.apps.nnunet.nnunet_bundle.convert_nnunet_to_monai_bundle` | `monai/apps/nnunet/nnunet_bundle.py` | `nnunet_config: dict, bundle_root_folder: str, fold: int = 0` | `Convert nnUNet model checkpoints and configuration to a MONAI bundle on disk for use in MONAI workflows and the MONAI Model Zoo. This function is used in the medical imaging domain to translate nnUNet v2 training outputs into the MONAI bundle layout (expected by MONAI examples and bundle-based inference/training workflows).` |
| `monai_apps_nnunet_utils_analyze_data` | `monai.apps.nnunet.utils.analyze_data` | `monai/apps/nnunet/utils.py` | `datalist_json: dict, data_dir: str` | `Analyze training data metadata and example files to infer dataset properties used by MONAI nnU-Net workflows. This function inspects the provided MONAI-style datalist JSON and the raw data directory to determine two properties that are commonly required when configuring segmentation networks and training pipelines: the number of input channels (used to set the model input layer) and the number of foreground classes (used to set the network output channels and loss/metric configuration). It loads actual image and label files from disk using MONAI's LoadImage transform with the options image_only=True, ensure_channel_first=True, simple_keys=True to obtain tensor-like image objects with channels-first ordering when possible. It logs the inferred values via logger.info and returns them as Python ints. Typical usage in the MONAI/nnU-Net context is to call this before building a network or preparing training configuration so the architecture and label handling match the dataset.` |
| `monai_apps_nnunet_utils_create_new_data_copy` | `monai.apps.nnunet.utils.create_new_data_copy` | `monai/apps/nnunet/utils.py` | `test_key: str, datalist_json: dict, data_dir: str, num_input_channels: int, output_datafolder: str` | `Create and organize a new copy of data to meet the directory layout and file naming expectations of nnU-Net V2 training and inference workflows. This function is used in MONAI-based preprocessing pipelines (for example, tutorials that provide a datalist .json) to convert an existing datalist_json and the raw image/label files in data_dir into a new dataset folder containing per-channel image NIfTI files, corresponding label NIfTI files, and an exported datalist.json that records the mapping to newly assigned case names.` |
| `monai_apps_nnunet_utils_create_new_dataset_json` | `monai.apps.nnunet.utils.create_new_dataset_json` | `monai/apps/nnunet/utils.py` | `modality: str, num_foreground_classes: int, num_input_channels: int, num_training_data: int, output_filepath: str` | `Create a new dataset.json file formatted for nnU-Net V2 from simple inputs. This utility constructs the minimal JSON structure that nnU-Net V2 expects for a dataset description and writes it to disk. It is intended for use in MONAI-based medical imaging workflows where researchers or engineers need to generate the required dataset metadata (channel names, label mapping, number of training cases, and file ending) programmatically so that nnU-Net V2 training/evaluation code can consume the dataset. The function maps input image modalities to channel indices, creates a label dictionary with a reserved background label (0) and sequential foreground class IDs (1..N), sets the number of training samples, and fixes the image file extension to ".nii.gz". The produced JSON is exported via ConfigParser.export_config_file(fmt="json", sort_keys=True, indent=4, ensure_ascii=False).` |
| `monai_apps_pathology_utils_compute_isolated_tumor_cells` | `monai.apps.pathology.utils.compute_isolated_tumor_cells` | `monai/apps/pathology/utils.py` | `tumor_mask: numpy.ndarray, threshold: float` | `Compute isolated tumor cell (ITC) labels from a labeled tumor segmentation mask. This function identifies Isolated Tumor Cells (ITCs) in a labeled tumor mask by measuring each labeled region's longest diameter (major axis length) using skimage.measure.regionprops and comparing it to a provided threshold. In pathology workflows (as used in MONAI's pathology utilities), ITCs are small tumor foci whose largest extent is below a configured threshold; this function returns the integer labels of regions considered ITCs so downstream code can count, remove, or further analyze these small regions in slide-level or patch-level pipelines.` |
| `monai_apps_pathology_utils_compute_multi_instance_mask` | `monai.apps.pathology.utils.compute_multi_instance_mask` | `monai/apps/pathology/utils.py` | `mask: numpy.ndarray, threshold: float` | `Compute a multi-instance segmentation mask from a binary tumor mask for pathology images.` |
| `monai_apps_reconstruction_networks_nets_utils_floor_ceil` | `monai.apps.reconstruction.networks.nets.utils.floor_ceil` | `monai/apps/reconstruction/networks/nets/utils.py` | `n: float` | `monai.apps.reconstruction.networks.nets.utils.floor_ceil returns the mathematical floor and ceil of a floating-point input, intended as a small utility used by MONAI reconstruction network code to convert continuous quantities (for example, spatial coordinates, fractional pixel indices, or computed sizes) into discrete integer values required for image grid indices, array shapes, or padding calculations in medical imaging workflows.` |
| `monai_apps_tcia_utils_match_tcia_ref_uid_in_study` | `monai.apps.tcia.utils.match_tcia_ref_uid_in_study` | `monai/apps/tcia/utils.py` | `study_uid: str, ref_sop_uid: str` | `Match the SeriesInstanceUID for a series in a TCIA study that contains the given SOPInstanceUID. This function is used in MONAI applications that integrate with The Cancer Imaging Archive (TCIA) to map a DICOM SOPInstanceUID (an individual image or instance) back to the SeriesInstanceUID (the DICOM identifier for the image series) within a given StudyInstanceUID. It performs TCIA metadata queries: first it retrieves all SeriesInstanceUID values for the study, then for each series it retrieves the SOPInstanceUID list and checks for a match. This is useful when one has a reference SOP instance and needs to know which series in the TCIA study contains that instance for downstream processing, loading, or indexing in MONAI workflows.` |
| `monai_apps_utils_get_filename_from_url` | `monai.apps.utils.get_filename_from_url` | `monai/apps/utils.py` | `data_url: str` | `Get the filename from the URL link. This utility issues HTTP requests to determine a sensible file name for a remote resource referenced by data_url and is used in MONAI workflows that download assets (for example model weights, bundles, or example datasets in the MONAI Model Zoo and tutorials) so files can be saved with an appropriate, human-readable name.` |
| `monai_auto3dseg_utils_check_and_set_optional_args` | `monai.auto3dseg.utils.check_and_set_optional_args` | `monai/auto3dseg/utils.py` | `params: dict` | `Convert a dictionary of optional parameters into a single command-line style string of the form " --key_1=value_1 --key_2=value_2 ...". This utility is used in MONAI's auto3dseg helper code to assemble optional arguments for command-line invocation patterns (for example, when constructing strings to pass into python-fire or bundle/Model Zoo launcher utilities). In the medical imaging Auto3DSeg workflow, it lets higher-level code represent optional CLI overrides as a Python dict and then convert them into the exact text fragment appended to a command that will modify runtime behavior (such as hyperparameters, input/output paths, or other optional flags).` |
| `monai_auto3dseg_utils_list_to_python_fire_arg_str` | `monai.auto3dseg.utils.list_to_python_fire_arg_str` | `monai/auto3dseg/utils.py` | `args: list` | `Convert a Python list into a single argument string formatted for use with python-fire. This utility is part of MONAI's auto3dseg utilities and is used in automated 3D segmentation workflows to serialize a list of values (for example, device indices, file paths, or other hyperparameter lists commonly used in medical imaging experiments) into one command-line argument that python-fire can receive. The function obtains each element's textual form via str(), joins those textual elements with commas, and wraps the whole result in single quotes so it can be passed as a single shell/CLI token to python-fire.` |
| `monai_auto3dseg_utils_verify_report_format` | `monai.auto3dseg.utils.verify_report_format` | `monai/auto3dseg/utils.py` | `report: dict, report_format: dict` | `Verify that a runtime report dictionary follows a keys-only format specification used by MONAI Auto3DSeg. This function is used in the monai.auto3dseg utilities to validate that a report produced by an Auto3DSeg training/evaluation workflow (for example, aggregated metrics, configuration summaries, or bundle reports) contains the keys and nested list structure described by a keys-only format dictionary. It checks presence of keys and the expected nested-list shape described by report_format without inspecting or validating the concrete values or value types. The function performs a recursive comparison that treats a single-element list in report_format as the element-format for items of a corresponding list in report.` |
| `monai_data_image_writer_register_writer` | `monai.data.image_writer.register_writer` | `monai/data/image_writer.py` | `ext_name: str, *im_writers` | `Register ImageWriter classes for a filename extension so MONAI's image-writing mechanism can resolve a file extension to one or more appropriate ImageWriter implementations used in medical imaging workflows. This function is used in MONAI (a PyTorch-based framework for healthcare imaging) to associate a filename extension (for example "nii" for NIfTI files) with a tuple of ImageWriter classes that know how to serialize image data to that format. When client code calls the higher-level image writing utilities, the extension string is used as a key to look up the registered writers and decide which writer(s) to try. Registration is additive and order-sensitive: writers passed to this function are given higher priority and placed before any previously registered writers for the same extension.` |
| `monai_data_image_writer_resolve_writer` | `monai.data.image_writer.resolve_writer` | `monai/data/image_writer.py` | `ext_name: str, error_if_not_found: bool = True` | `Resolve the available ImageWriter backends registered in MONAI for a given filename extension and return them as a sequence of writer callables.` |
| `monai_data_meta_obj_set_track_meta` | `monai.data.meta_obj.set_track_meta` | `monai/data/meta_obj.py` | `val: bool` | `monai.data.meta_obj.set_track_meta sets whether MONAI associates metadata with data objects used throughout the MONAI medical imaging data pipeline. This function configures a module-level boolean flag that controls whether metadata (for example, spatial affine, voxel spacing, orientation, original filename, channel dimension, and other dataset-specific attributes commonly preserved in medical imaging workflows) is tracked and attached to data objects by using MONAI's MetaObj subclasses. When tracking is enabled, MONAI returns enhanced objects that carry metadata alongside the raw data; when tracking is disabled, MONAI returns standard data containers (for example, torch.Tensor and numpy.ndarray) with empty or no metadata. By default this flag is True; most users should leave metadata tracking enabled to preserve spatial and provenance information required for preprocessing, resampling, visualization, and evaluation in healthcare imaging workflows.` |
| `monai_data_utils_collate_meta_tensor` | `monai.data.utils.collate_meta_tensor` | `monai/data/utils.py` | `batch: list` | `Collate a sequence of meta-tensor containers into a batched meta-tensor structure suitable for MONAI data pipelines. This function is used in MONAI (a PyTorch-based medical imaging framework) to assemble per-sample data items produced by a Dataset into a single batch that preserves both tensor data and associated metadata (for example spatial affine, origin, orientation stored in MONAI MetaTensor/MetaObj objects). It recursively inspects the first element of the provided sequence to determine how to collate: if elements are MONAI MetaObj instances, it delegates to collate_meta_tensor_fn to produce a single batched meta-tensor; if elements are mapping/dictionary-like it builds a dictionary whose values are the collated results for each key; if elements are tuples/lists it returns a list of collated results for each position; otherwise it falls back to torch.utils.data.dataloader.default_collate to produce a conventional tensor batch. This behavior enables DataLoader-style batching while preserving domain-specific metadata required for healthcare imaging workflows and downstream models.` |
| `monai_data_utils_collate_meta_tensor_fn` | `monai.data.utils.collate_meta_tensor_fn` | `monai/data/utils.py` | `batch: list, collate_fn_map: dict = None` | `Collate a sequence of MONAI MetaTensor-like objects into a single batched tensor that preserves per-sample metadata and records applied operations. This function is implemented for the MONAI medical-imaging data pipeline and is used to combine a list of per-sample tensors (for example, image volumes or labels) and their associated metadata into a single batched tensor for downstream model training or inference. It is called by collage_meta_tensor (internal MONAI utility) and therefore is not intended to be passed directly as a DataLoader collate_fn. The function delegates numerical/tensor stacking to torch.utils.data._utils.collate.collate_tensor_fn and then attaches three MONAI-specific attributes to the returned tensor: meta (a batched collection of per-sample metadata), applied_operations (a list of each sample's recorded transform history), and is_batch (a boolean marker set to True). This preserves important provenance information (e.g., spatial affine, original shape, spacing, keys) used in healthcare imaging workflows when composing batches for models.` |
| `monai_data_utils_dev_collate` | `monai.data.utils.dev_collate` | `monai/data/utils.py` | `batch: list, level: int = 1, logger_name: str = "dev_collate"` | `monai.data.utils.dev_collate recursively collates a list-style batch while emitting detailed critical-level log messages to help debug PyTorch DataLoader collate problems in MONAI data pipelines for medical imaging. It is intended for interactive debugging of batching behavior (for example, when collating multi-dimensional NumPy arrays or PyTorch tensors representing medical images and related metadata) and reports the internal decisions and errors at the "critical" logging level so messages are easy to spot when handling exceptions.` |
| `monai_data_utils_remove_extra_metadata` | `monai.data.utils.remove_extra_metadata` | `monai/data/utils.py` | `meta: dict` | `Remove extra metadata keys from a MONAI metadata dictionary in-place. This function is part of the monai.data.utils utilities and is used in MONAI preprocessing and data handling workflows to remove keys that are considered "extra metadata" according to MONAI conventions. It determines which keys to remove by calling get_extra_metadata_keys(), then delegates the actual removal to remove_keys(data=meta, keys=keys). Typical uses include cleaning a sample's metadata before serialization, logging, or passing the metadata into training/evaluation components so that large, temporary, or implementation-specific entries do not propagate through the pipeline.` |
| `monai_data_utils_remove_keys` | `monai.data.utils.remove_keys` | `monai/data/utils.py` | `data: dict, keys: list[str]` | `monai.data.utils.remove_keys removes one or more keys from a mapping in-place without returning a value. This utility function is intended for MONAI data-processing workflows (for example, preprocessing and transform pipelines in medical imaging) where sample dictionaries carry images, labels, and metadata and specific keys need to be discarded before further processing or saving. The function iterates over the provided list of keys and calls dict.pop(key, None) for each key so that missing keys are ignored silently. Because it modifies the input mapping directly, callers should not expect a new dictionary or any return value.` |
| `monai_data_utils_worker_init_fn` | `monai.data.utils.worker_init_fn` | `monai/data/utils.py` | `worker_id: int` | `monai.data.utils.worker_init_fn sets per-worker random seeds for MONAI dataset transforms when used as the PyTorch DataLoader worker initialization callback. This function is intended to be passed directly to PyTorch DataLoader via its worker_init_fn argument so that each worker process used for loading medical imaging data in MONAI-based training receives a distinct random seed. In MONAI workflows this avoids different workers producing identical random augmentations for the same samples, which preserves desired augmentation diversity and supports reproducible experiments across multiple workers. The function obtains PyTorch worker information via torch.utils.data.get_worker_info(), and then calls set_rnd(...) with the DataLoader worker's dataset and the worker-specific seed (worker_info.seed) so that the dataset-level random number generators used by MONAI transforms are initialized for that worker.` |
| `monai_engines_utils_default_metric_cmp_fn` | `monai.engines.utils.default_metric_cmp_fn` | `monai/engines/utils.py` | `current_metric: float, prev_best: float` | `monai.engines.utils.default_metric_cmp_fn: Default comparator for scalar metrics used by MONAI training and evaluation engines. This function implements a strict "greater-than" comparison to determine whether the metric computed in the current evaluation round represents an improvement over the best metric observed in previous rounds. In MONAI workflows (see README), such a comparator is typically used by components that track the best model state, save checkpoints, or drive early stopping decisions based on evaluation metrics for medical imaging tasks (for example, validation Dice score or accuracy).` |
| `monai_handlers_utils_stopping_fn_from_metric` | `monai.handlers.utils.stopping_fn_from_metric` | `monai/handlers/utils.py` | `metric_name: str` | `Returns a stopping function that reads a metric value by name from an Ignite Engine's state for use with ignite.handlers.EarlyStopping. This helper is used in MONAI training and evaluation workflows (medical imaging deep learning) to construct the score function required by ignite.handlers.EarlyStopping. MONAI engines (ignite.engine.Engine) commonly populate engine.state.metrics with validation or training metrics (for example "val_loss", "val_dice") after each epoch or iteration. The callable returned by this function simply accesses engine.state.metrics[metric_name] and returns that value, so the EarlyStopping handler can decide whether to stop based on that metric.` |
| `monai_inferers_merger_iterate_over_chunks` | `monai.inferers.merger.iterate_over_chunks` | `monai/inferers/merger.py` | `chunks: tuple, cdata_shape: tuple, slice_tuple: tuple = ()` | `Iterate over regularly spaced chunks of a multi-dimensional array and yield index tuples that select each chunk. This function is a small utility used by MONAI's inferers.merger logic when reconstructing outputs from tiled or chunked inference over medical images. Given a chunk shape and the number of chunks in each dimension (cdata_shape), it yields, one at a time, tuples of Python slice objects that can be used to index into a NumPy or PyTorch array/tensor to extract the corresponding tile. The function is implemented recursively to support an arbitrary number of spatial dimensions and is memory-efficient because it yields slices lazily rather than allocating a full list of indices.` |
| `monai_losses_perceptual_medicalnet_intensity_normalisation` | `monai.losses.perceptual.medicalnet_intensity_normalisation` | `monai/losses/perceptual.py` | `volume: numpy.ndarray` | `monai.losses.perceptual.medicalnet_intensity_normalisation: Normalize a medical image volume to zero mean and unit variance following the MedicalNet preprocessing convention. This function implements the intensity normalization used in the MedicalNet project (see referenced source in original implementation). It computes the global arithmetic mean and standard deviation of all voxels in the provided n-dimensional medical image volume (for example, a 3D MRI or CT scan stored as a NumPy array) and returns a new array where each voxel intensity is shifted and scaled to have zero mean and unit variance. This normalization is commonly applied as a preprocessing step in deep learning workflows for medical imaging (as in MONAI) to stabilize training, make network weights more comparable across inputs, and reduce sensitivity to absolute intensity scales between studies or scanners.` |
| `monai_metrics_confusion_matrix_check_confusion_matrix_metric_name` | `monai.metrics.confusion_matrix.check_confusion_matrix_metric_name` | `monai/metrics/confusion_matrix.py` | `metric_name: str` | `monai.metrics.confusion_matrix.check_confusion_matrix_metric_name: Check, normalize, and map a confusion-matrix metric name or alias to the canonical short name used by MONAI's confusion-matrix metric implementations. This function is used in MONAI's metrics and evaluation pipelines for healthcare imaging to allow flexible user-provided metric names (for example in configuration files, CLI arguments, or metric selection code) while ensuring the downstream confusion-matrix computation modules receive a single, canonical metric identifier. The routine performs two deterministic normalization steps on the input string: it replaces spaces with underscores and lowercases the result. It then maps common synonyms and longer descriptive names for confusion-matrix-derived metrics to their standardized short forms (for example, "sensitivity" -> "tpr", "precision" -> "ppv", "false_positive_rate" -> "fpr", "f1_score" -> "f1", etc.). The canonical names produced by this function correspond to the metric keys expected by MONAI's confusion-matrix metric implementations and therefore determine which formula is applied when computing the metric on medical image classification or segmentation results. This function has no side effects beyond returning the normalized name and does not modify the caller's objects.` |
| `monai_metrics_froc_compute_froc_score` | `monai.metrics.froc.compute_froc_score` | `monai/metrics/froc.py` | `fps_per_image: numpy.ndarray, total_sensitivity: numpy.ndarray, eval_thresholds: tuple = (0.25, 0.5, 1, 2, 4, 8)` | `Compute the CAMELYON-style FROC score (average sensitivity at predefined false positive rates per image). This function is modified from the official CAMELYON16 challenge evaluation code and implements the challenge's second evaluation metric: the average sensitivity (true positive rate) evaluated at a set of predefined false positive rates per whole-slide image. It is intended for use in medical imaging detection pipelines (for example, lesion/metastasis detection on whole-slide histopathology images) where model outputs are aggregated at multiple detection thresholds to produce per-threshold average false positives per image and corresponding sensitivities. The function linearly interpolates the provided sensitivity curve at the requested false-positive-per-image thresholds and returns the arithmetic mean of those interpolated sensitivities. The implementation reverses the input arrays before interpolation to satisfy numpy.interp's requirement that the interpolation x-coordinates be in increasing order.` |
| `monai_metrics_utils_get_code_to_measure_table` | `monai.metrics.utils.get_code_to_measure_table` | `monai/metrics/utils.py` | `spacing: tuple, device: str = None` | `monai.metrics.utils.get_code_to_measure_table returns a lookup table that maps a neighbourhood code (an integer index that encodes a local voxel/pixel neighbourhood configuration) to the corresponding geometric measure used in MONAI metrics: contour length for 2D data or surface area for 3D data. This function is used in MONAI's medical-imaging metric computations to convert local neighbourhood encodings into physical boundary contributions (lengths or areas) that can be summed to compute segmentation contour lengths or surface areas, taking into account the physical spacing of the image voxels/pixels and the target device for computation.` |
| `monai_networks_layers_convutils_polyval` | `monai.networks.layers.convutils.polyval` | `monai/networks/layers/convutils.py` | `coef: list, x: float` | `monai.networks.layers.convutils.polyval evaluates a polynomial at a given variable using Horner's method; this utility is part of MONAI's convolution-related utilities (monai.networks.layers.convutils) and can be used wherever a polynomial defined by coefficient sequences must be computed in medical imaging pipelines, for example when mapping parameters or constructing analytic filter responses.` |
| `monai_networks_layers_factories_adaptive_avgpooling_factory` | `monai.networks.layers.factories.adaptive_avgpooling_factory` | `monai/networks/layers/factories.py` | `dim: int` | `monai.networks.layers.factories.adaptive_avgpooling_factory returns the PyTorch Adaptive Average Pooling class corresponding to a requested spatial dimensionality. This factory function is used within MONAI (a PyTorch-based medical imaging framework) to select the correct adaptive average pooling layer type when building neural network architectures that operate on 1D signals, 2D image slices, or 3D volumes (common modalities in healthcare imaging workflows).` |
| `monai_networks_layers_factories_adaptive_maxpooling_factory` | `monai.networks.layers.factories.adaptive_maxpooling_factory` | `monai/networks/layers/factories.py` | `dim: int` | `Factory that returns the PyTorch adaptive max pooling class corresponding to a specified spatial dimension (1, 2, or 3). This function is used by MONAI's pooling factory (registered as Pool.factory_function("adaptivemax")) to map a simple dimension identifier into the concrete PyTorch nn.AdaptiveMaxPoolXd class so network-building code in medical imaging workflows can instantiate the appropriate adaptive max-pooling module for 1D signals, 2D images (slices), or 3D volumes. This factory does not create a layer instance; it returns the class object for the appropriate AdaptiveMaxPool module. The returned class can be instantiated as a normal PyTorch module (for example, returned_type(output_size)) and then used in model definitions to perform spatial down-sampling via maximum pooling in MONAI models for healthcare imaging.` |
| `monai_networks_layers_factories_avgpooling_factory` | `monai.networks.layers.factories.avgpooling_factory` | `monai/networks/layers/factories.py` | `dim: int` | `monai.networks.layers.factories.avgpooling_factory returns the PyTorch average pooling layer class corresponding to a requested spatial dimension. In the MONAI medical-imaging framework this factory is used to select the appropriate nn.AvgPoolNd class (1D, 2D, or 3D) for building network architectures that perform spatial downsampling or local averaging of feature maps (for example, when constructing encoder blocks or reducing resolution of volumetric medical images).` |
| `monai_networks_layers_factories_batch_factory` | `monai.networks.layers.factories.batch_factory` | `monai/networks/layers/factories.py` | `dim: int` | `monai.networks.layers.factories.batch_factory returns the PyTorch BatchNorm class corresponding to a requested spatial dimensionality (1D, 2D, or 3D). This factory function is used within MONAI's network-building utilities to select the appropriate torch.nn.BatchNorm layer class when constructing normalization layers for medical imaging models (for example, 2D for X-ray or slices and 3D for volumetric CT/MRI data). The function is decorated with Norm.factory_function("batch"), registering it under the "batch" normalization factory name used by MONAI.` |
| `monai_networks_layers_factories_constant_pad_factory` | `monai.networks.layers.factories.constant_pad_factory` | `monai/networks/layers/factories.py` | `dim: int` | `monai.networks.layers.factories.constant_pad_factory: Factory that returns the PyTorch nn.ConstantPad class for a specified spatial dimensionality (1, 2, or 3). This factory is used within MONAI preprocessing and network construction to select the appropriate constant-padding layer type for medical imaging data of different spatial dimensionalities. In the MONAI domain, 1D is typically used for sequential signals, 2D for slice-based images (e.g., X-rays or individual MRI/CT slices), and 3D for volumetric medical scans (e.g., full CT or MRI volumes). The function performs no tensor allocation or layer instantiation itself; it returns the class object (for example, nn.ConstantPad3d) so callers can instantiate a layer with specific padding and fill value (e.g., nn.ConstantPad3d(padding, value)) according to the PyTorch API.` |
| `monai_networks_layers_factories_conv_factory` | `monai.networks.layers.factories.conv_factory` | `monai/networks/layers/factories.py` | `dim: int` | `monai.networks.layers.factories.conv_factory: Return the PyTorch convolution module class appropriate for a specified spatial dimensionality used in MONAI medical imaging networks. This factory function maps an integer spatial dimensionality used in medical imaging deep learning workflows to the corresponding torch.nn convolution class. In MONAI, selecting the correct convolution dimensionality is essential when designing networks for different data modalities: 1 for temporal or 1D signal data, 2 for 2D image slices (e.g., individual radiology slices), and 3 for volumetric image data (e.g., CT or MRI volumes). The function is registered as the "conv" factory and is intended to be used when building or configuring network layers so that subsequent layer construction uses the appropriate nn.ConvXd class for the chosen dimension. The function performs no in-place side effects; it only returns a class object.` |
| `monai_networks_layers_factories_convtrans_factory` | `monai.networks.layers.factories.convtrans_factory` | `monai/networks/layers/factories.py` | `dim: int` | `Factory function in monai.networks.layers.factories that selects and returns the appropriate PyTorch transposed convolution class for a given spatial dimensionality. In the MONAI framework (a PyTorch-based library for deep learning in healthcare imaging), this factory is used when constructing network components that require learnable upsampling or decoder layers (for example, the decoder path of a segmentation model). The function returns the class (not an instance) corresponding to nn.ConvTranspose1d, nn.ConvTranspose2d, or nn.ConvTranspose3d so callers can instantiate the layer with desired channel counts, kernel sizes, strides, padding, and other convolutional parameters.` |
| `monai_networks_layers_factories_dropout_factory` | `monai.networks.layers.factories.dropout_factory` | `monai/networks/layers/factories.py` | `dim: int` | `monai.networks.layers.factories.dropout_factory returns the PyTorch dropout layer class corresponding to a specified spatial dimensionality used in MONAI network construction for medical imaging models. In MONAI this factory is registered via the Dropout.factory_function decorator under the name "dropout" and is used to select the correct dropout class when building or configuring networks for 1D, 2D, or 3D imaging tasks (for example, time-series, slice-based, or volumetric medical image models) so that callers can instantiate the appropriate nn.Dropout, nn.Dropout2d, or nn.Dropout3d layer.` |
| `monai_networks_layers_factories_instance_factory` | `monai.networks.layers.factories.instance_factory` | `monai/networks/layers/factories.py` | `dim: int` | `monai.networks.layers.factories.instance_factory selects and returns the appropriate PyTorch Instance Normalization layer class for a specified spatial dimensionality used in MONAI medical-imaging networks. This factory function is registered via Norm.factory_function("instance") and is intended for use in MONAI model construction and layer factory patterns where the normalization layer class must be chosen based on the spatial dimension of the data (e.g., 1D biomedical signals, 2D image slices, or 3D volumetric scans). The function does not create an instance of the normalization layer; it returns the corresponding nn.InstanceNormXd class so the caller can instantiate it with the required arguments (for example, num_features, affine, track_running_stats) according to PyTorch's API. The mapping is: dim == 1 -> torch.nn.InstanceNorm1d, dim == 2 -> torch.nn.InstanceNorm2d, dim == 3 -> torch.nn.InstanceNorm3d.` |
| `monai_networks_layers_factories_instance_nvfuser_factory` | `monai.networks.layers.factories.instance_nvfuser_factory` | `monai/networks/layers/factories.py` | `dim: int` | `monai.networks.layers.factories.instance_nvfuser_factory returns a normalization layer class optimized for 3D instance normalization when available (apex.normalization.InstanceNorm3dNVFuser) and falls back to the appropriate torch.nn.InstanceNorm{1,2,3} classes for other dimensionalities or when the NVFuser implementation is not available. This factory is used in MONAI to select an efficient InstanceNorm layer for medical imaging deep learning pipelines, where 3D volumetric data (e.g., CT or MRI) often benefits from a specialized, CUDA-accelerated implementation. This function examines the requested spatial dimensionality and either: - returns the NVIDIA APEX NVFuser accelerated class apex.normalization.InstanceNorm3dNVFuser when dim == 3 and the NVFuser implementation is installed and importable; or - returns the corresponding torch.nn.InstanceNorm1d or torch.nn.InstanceNorm2d class when dim is 1 or 2; or - returns torch.nn.InstanceNorm3d when dim == 3 but the NVFuser implementation is not installed or not importable. Behavioral notes, practical significance, and side effects: This factory returns the layer class itself (not an instantiated layer). Callers must instantiate the returned class with appropriate constructor arguments (for example, affine and track_running_stats) consistent with torch.nn.InstanceNorm* semantics. The NVFuser implementation (apex.normalization.InstanceNorm3dNVFuser) is a customized autograd implementation provided by NVIDIA APEX that can be faster on CUDA for 3D volumes; it requires a CUDA-enabled environment and is not supported on Windows. Because the NVFuser variant uses custom autograd logic, it is currently not compatible with TorchScript; if TorchScript compatibility is required, use torch.nn.InstanceNorm3d instead. When the factory chooses a non-NVFuser fallback, it issues a Python warning via warnings.warn to inform the user about the fallback. If dim != 3 and dim is in {1, 2}, a warning indicates which torch.nn.InstanceNorm class will be used. If NVFuser is not installed or not importable, a warning indicates that torch.nn.InstanceNorm3d will be used instead. The function uses optional_import to import the NVFuser class; the returned value is the first element of optional_import(...)[0], i.e., the class object. Failure modes and limits: The function assumes dim is an integer representing spatial dimensionality. It is designed for dim values 1, 2, or 3. If dim is outside the range 1..3, the function will attempt to index an internal tuple and will raise an IndexError; callers should validate dim before calling if there is any chance it is outside this range. The NVFuser path requires that apex.normalization.InstanceNorm3dNVFuser be installed and importable; otherwise the function falls back to torch.nn.InstanceNorm3d. The NVFuser implementation is not TorchScript compatible and requires CUDA on a non-Windows OS; attempting to use it in a CPU-only environment, on Windows, or with TorchScript will fail or produce unsupported behavior. Installation reference: If you intend to use the NVFuser implementation, install NVIDIA APEX per its repository instructions: https://github.com/NVIDIA/apex#installation` |
| `monai_networks_layers_factories_maxpooling_factory` | `monai.networks.layers.factories.maxpooling_factory` | `monai/networks/layers/factories.py` | `dim: int` | `Max pooling layer class factory for 1D, 2D, or 3D spatial data used in MONAI network construction. Returns the PyTorch max pooling layer class corresponding to the requested spatial dimensionality so callers within MONAI (a PyTorch-based medical imaging deep learning framework) can instantiate pooling layers appropriate for their network architectures. In the medical imaging domain, max pooling layers reduce spatial resolution and help build hierarchical feature representations; this factory centralizes the selection of the correct torch.nn MaxPool class (imported as nn in this module) based on a simple integer dimension argument.` |
| `monai_networks_layers_factories_replication_pad_factory` | `monai.networks.layers.factories.replication_pad_factory` | `monai/networks/layers/factories.py` | `dim: int` | `Replication padding layer class selector for 1D, 2D, and 3D spatial tensors used by MONAI's layer factory. This function is used in MONAI (Medical Open Network for AI) to map a requested spatial dimensionality to the corresponding PyTorch replication padding layer class when the "replicationpad" pad type is requested from the Pad factory. In medical imaging workflows within MONAI, replication padding is commonly applied to multi-dimensional image tensors to extend boundaries by copying edge values; this helper returns the appropriate nn.ReplicationPad class so the caller or factory can instantiate a padding layer with concrete padding sizes for preprocessing or network layers.` |
| `monai_networks_layers_factories_split_args` | `monai.networks.layers.factories.split_args` | `monai/networks/layers/factories.py` | `args: tuple` | `monai.networks.layers.factories.split_args normalizes an argument specification into a (type, kwargs) pair suitable for MONAI factory-style layer construction utilities. This function is part of MONAI's layer factory utilities used by network/layer factories to accept flexible type specifications from configuration or code. It accepts either a single string naming a layer/type (for example a key used with monai.networks.layers.Act) or an explicit pair consisting of a name or callable that identifies the object to instantiate and a dict of keyword arguments to pass to that object's constructor. The normalized output is intended for direct use with factory mappings that construct PyTorch/MONAI layer objects from a type-specifier and keyword arguments.` |
| `monai_networks_layers_weight_init_trunc_normal_` | `monai.networks.layers.weight_init.trunc_normal_` | `monai/networks/layers/weight_init.py` | `tensor: torch.Tensor, mean: float = 0.0, std: float = 1.0, a: float = -2.0, b: float = 2.0` | `Initialize the given tensor in-place with samples from a truncated normal distribution. This function is used within MONAI for network weight initialization in medical imaging models (for example, initializing convolution and linear layer weights before training). It fills the provided n-dimensional torch.Tensor with random values drawn from a normal distribution with specified mean and standard deviation, but truncated to lie within the interval [a, b]. The implementation is based on the pytorch-image-models truncated normal routine (https://github.com/rwightman/pytorch-image-models) and performs the assignment under torch.no_grad to avoid tracking these operations in autograd. Typical usage is to call this once after creating parameter tensors to produce stable initial weights (defaults: mean=0.0, std=1.0, a=-2.0, b=2.0).` |
| `monai_networks_nets_efficientnet_get_efficientnet_image_size` | `monai.networks.nets.efficientnet.get_efficientnet_image_size` | `monai/networks/nets/efficientnet.py` | `model_name: str` | `monai.networks.nets.efficientnet.get_efficientnet_image_size returns the required input image spatial size (single dimension) for a specified EfficientNet model variant used in MONAI's imaging networks.` |
| `monai_networks_nets_mednext_create_mednext` | `monai.networks.nets.mednext.create_mednext` | `monai/networks/nets/mednext.py` | `variant: str, spatial_dims: int = 3, in_channels: int = 1, out_channels: int = 2, kernel_size: int = 3, deep_supervision: bool = False` | `Create a configured MedNeXt model instance for medical imaging tasks by selecting one of the predefined model-size variants. This factory constructs a MedNeXt encoder-decoder network (used in MONAI for deep learning on healthcare imaging data) with variant-specific expansion ratios and block counts optimized for different model capacities, and with shared common settings (residual connections enabled, group normalization, no global response normalization, and 32 initial filters). The created MedNeXt is intended for use in segmentation or classification pipelines that operate on multi-dimensional medical images (e.g., 2D or 3D volumes) and integrates with MONAI training and inference workflows.` |
| `monai_networks_nets_resnet_get_medicalnet_pretrained_resnet_args` | `monai.networks.nets.resnet.get_medicalnet_pretrained_resnet_args` | `monai/networks/nets/resnet.py` | `resnet_depth: int` | `get_medicalnet_pretrained_resnet_args: Return the configuration tuple (bias_downsample, shortcut_type) that matches the MedicalNet pretrained ResNet weight conventions for a given ResNet depth. This function is used in MONAI (a PyTorch-based medical imaging deep learning framework) when constructing ResNet variants that will load pretrained weights from MedicalNet/model zoo. It encodes the known conventions for whether the downsample convolution uses a bias term and which residual shortcut variant ("A" or "B") was used when the MedicalNet weights were produced. Using the values returned by this function ensures the model architecture matches the weight parameter shapes and naming expected by the pretrained checkpoint, avoiding mismatches when loading weights for medical imaging tasks (classification, segmentation, or feature extraction).` |
| `monai_networks_nets_resnet_get_pretrained_resnet_medicalnet` | `monai.networks.nets.resnet.get_pretrained_resnet_medicalnet` | `monai/networks/nets/resnet.py` | `resnet_depth: int, device: str = "cpu", datasets23: bool = True` | `monai.networks.nets.resnet.get_pretrained_resnet_medicalnet downloads and returns pretrained ResNet weights from the TencentMedicalNet repository on the Hugging Face Hub that are intended for medical imaging tasks and for use with MONAI ResNet model implementations.` |
| `monai_networks_nets_swin_unetr_compute_mask` | `monai.networks.nets.swin_unetr.compute_mask` | `monai/networks/nets/swin_unetr.py` | `dims: tuple, window_size: tuple, shift_size: tuple, device: str` | `Computes an attention region mask for shifted-window self-attention as used by Swin Transformer and the Swin-UNETR model in MONAI. This function builds a binary-region index map over a 2D or 3D input grid (height/width or depth/height/width) and converts that map into an attention mask that prevents cross-window attention after a cyclic shift. The implementation follows the approach in Liu et al., "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows" and the reference implementation in the Microsoft Swin-Transformer repository. In MONAI this mask is used by swin_unetr network components to ensure attention is computed only within the appropriate local windows for medical image segmentation tasks, and it is intended to be added to attention logits before softmax so masked positions receive a large negative bias (here -100.0) and contribute near-zero probability after softmax.` |
| `monai_networks_nets_swin_unetr_filter_swinunetr` | `monai.networks.nets.swin_unetr.filter_swinunetr` | `monai/networks/nets/swin_unetr.py` | `key: str, value: torch.Tensor` | `filter_swinunetr Converts and filters parameter keys from a pretrained checkpoint (from the Disruptive Autoencoders / SSL weights referenced in the repository) so they can be loaded into the MONAI SwinUNETR model using utilities such as monai.networks.utils.copy_model_state. This function inspects the incoming state-dict key (string) and either returns a renamed key paired with the original tensor value or returns None to indicate the parameter should be skipped. It is intended to be used when adapting checkpoint key naming conventions (for example, checkpoints that use an "encoder." prefix) to MONAI's SwinUNETR naming convention (which expects a "swinViT." prefix and slightly different internal key layout). This function does not modify the tensor contents, move tensors across devices, or validate tensor shapes; those checks and any loading errors are handled by the caller (e.g., copy_model_state or torch.nn.Module.load_state_dict).` |
| `monai_networks_nets_swin_unetr_get_window_size` | `monai.networks.nets.swin_unetr.get_window_size` | `monai/networks/nets/swin_unetr.py` | `x_size: tuple, window_size: tuple, shift_size: tuple = None` | `Compute adjusted window size (and optional adjusted shift size) for Swin-style windowed attention given an input spatial size. This function implements the behavior used in the Swin Transformer family (see Liu et al., "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows") and in MONAI's Swin UNETR network: it ensures local window sizes do not exceed the corresponding input spatial dimensions and disables window shifting on any dimension where the window equals or exceeds the input size. The result is suitable for downstream use when partitioning image patches or feature maps into local windows for self-attention in medical imaging models.` |
| `monai_networks_nets_swin_unetr_window_partition` | `monai.networks.nets.swin_unetr.window_partition` | `monai/networks/nets/swin_unetr.py` | `x: torch.Tensor, window_size: tuple` | `window partition operation used by Swin Transformerâ€“based models (for example Swin UNETR in MONAI) to split an input feature map or volume into non-overlapping local windows. This function implements the partitioning described in "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows" (Liu et al.) and is intended for use in medical imaging deep-learning pipelines where local windowed self-attention is applied to 2D feature maps or 3D volumes.` |
| `monai_networks_nets_swin_unetr_window_reverse` | `monai.networks.nets.swin_unetr.window_reverse` | `monai/networks/nets/swin_unetr.py` | `windows: torch.Tensor, window_size: tuple, dims: tuple` | `monai.networks.nets.swin_unetr.window_reverse reconstructs a tensor of local windowed features back into the original spatial layout used by Swin Transformer style models (for example within the Swin-UNETR architecture used in medical imaging in MONAI). It reverses the window partitioning performed during windowed self-attention so that per-window feature vectors are rearranged into a contiguous volume or image that matches the original spatial dimensions. This function is used in the Swin-UNETR pipeline to reassemble processed local windows (the output of window-based attention or processing) into a full 2D image or 3D volume so downstream modules (decoders, up-samplers, loss computation) can operate on the restored spatial grid.` |
| `monai_networks_nets_vista3d_vista3d132` | `monai.networks.nets.vista3d.vista3d132` | `monai/networks/nets/vista3d.py` | `encoder_embed_dim: int = 48, in_channels: int = 1` | `monai.networks.nets.vista3d.vista3d132 returns a configured VISTA3D model instance implementing the exact network configuration used in the paper at https://arxiv.org/abs/2406.05285. This factory function builds a 3D image encoder (SegResNetDS2) and two task heads (PointMappingSAM and ClassMappingClassify), wires them into a VISTA3D model, and returns the assembled model for use in medical imaging workflows (for example, 3D segmentation, point-based mapping, and classification in healthcare imaging datasets). The implementation treats class indices larger than 132 as zero-shot (i.e., out-of-support classes are handled as unseen by the model).` |
| `monai_networks_schedulers_rectified_flow_timestep_transform` | `monai.networks.schedulers.rectified_flow.timestep_transform` | `monai/networks/schedulers/rectified_flow.py` | `t: torch.Tensor, input_img_size_numel: torch.Tensor, base_img_size_numel: int = 32768, scale: float = 1.0, num_train_timesteps: int = 1000, spatial_dim: int = 3` | `Applies a resolution-aware remapping to diffusion timesteps used by the rectified flow scheduler in MONAI. This function converts original timestep indices into adjusted timesteps that account for differences between the current input image voxel count and a reference (base) image voxel count. In the MONAI medical-imaging diffusion training workflow, this helps scale the effective progression through training timesteps when images have different spatial resolutions or sizes so that denoising or diffusion dynamics remain comparable across resolutions.` |
| `monai_networks_trt_compiler_cuassert` | `monai.networks.trt_compiler.cuassert` | `monai/networks/trt_compiler.py` | `cuda_ret: tuple` | `monai.networks.trt_compiler.cuassert is an error-reporting helper used by MONAI's TensorRT compilation and CUDA-interfacing code to validate CUDA API call results and surface failures during medical imaging model compilation and inference workflows.` |
| `monai_networks_trt_compiler_get_dynamic_axes` | `monai.networks.trt_compiler.get_dynamic_axes` | `monai/networks/trt_compiler.py` | `profiles: list` | `get_dynamic_axes(profiles) calculates a mapping of input/output tensor names to the axes that should be treated as dynamic when exporting a PyTorch model to ONNX, intended for use in MONAI workflows that convert models for TensorRT compilation. This function inspects a set of "profiles" describing minimum, optimal, and maximum sizes for each tensor dimension and returns the axis indices where the minimum and maximum differ. In the MONAI medical imaging domain, this allows onnx.export(..., dynamic_axes=...) to mark spatial or batch dimensions that can vary across inputs so downstream tools (ONNX runtime, TensorRT) can generate appropriate, optimized engines for variable-sized medical images.` |
| `monai_transforms_lazy_utils_is_compatible_apply_kwargs` | `monai.transforms.lazy.utils.is_compatible_apply_kwargs` | `monai/transforms/lazy/utils.py` | `kwargs_1: dict, kwargs_2: dict` | `monai.transforms.lazy.utils.is_compatible_apply_kwargs checks whether two mappings of keyword arguments are compatible for combination by a lazy transform "apply" operation in MONAI's transform pipeline. This function is intended for use within MONAI's lazy transform system (used in medical imaging preprocessing and compositional transform APIs described in the project README) to decide if two per-call kwargs dictionaries can be merged or applied together when composing transforms. Each argument dictionary is expected to represent keyword arguments that would be passed to an individual transform's apply method during lazy execution (for example, per-item options carried through a composed sequence of transforms). The current implementation is a predicate function used by higher-level code that composes or merges kwargs before invoking apply.` |
| `monai_transforms_lazy_utils_kwargs_from_pending` | `monai.transforms.lazy.utils.kwargs_from_pending` | `monai/transforms/lazy/utils.py` | `pending_item: dict` | `monai.transforms.lazy.utils.kwargs_from_pending extracts a dictionary of keyword arguments used to configure downstream lazy transforms from a "pending" transform item recorded in MONAI's lazy transform pipeline. This function is used in MONAI's lazy (deferred) transformation system for medical imaging preprocessing, where transform operations may collect metadata (such as interpolation mode, padding mode, target shape, and dtype) to be applied later when the actual tensor/image is materialized. The returned dictionary contains only the keys that should be forwarded as kwargs to the transform implementation (for example, resampling or resizing operations) so that composed, deferred transforms can be applied consistently across a preprocessing pipeline.` |
| `monai_transforms_lazy_utils_requires_interp` | `monai.transforms.lazy.utils.requires_interp` | `monai/transforms/lazy/utils.py` | `matrix: numpy.ndarray, atol: float = 0.001` | `monai.transforms.lazy.utils.requires_interp checks whether a given affine transformation matrix can be implemented by simple axis operations (flip, permutation, pad/slice) or whether it requires voxel-wise interpolation during resampling. This function is used in MONAI preprocessing and lazy transform code to decide whether a spatial transform represented by an affine matrix can be realized by cheap array operations (no interpolation, e.g., memory-only permutation/flip) or must be performed with interpolation (resampling voxels), which is more computationally expensive and can change image intensities. The function inspects the translation column and the top-left submatrix of the affine matrix to determine if the transform is an integer-translation plus axis-permutation/flip (returns a mapping) or requires interpolation (returns None). Internally the input is converted to a NumPy array for numeric checks; the function does not modify the provided matrix.` |
| `monai_transforms_spatial_functional_convert_box_to_points` | `monai.transforms.spatial.functional.convert_box_to_points` | `monai/transforms/spatial/functional.py` | `bbox: torch.Tensor, mode: int` | `Convert an axis-aligned bounding box tensor to corner point coordinates usable by MONAI spatial transforms. This function is used in MONAI to convert per-box coordinate encodings (common in medical imaging tasks such as lesion/ROI annotation and localization) into explicit corner point coordinates that downstream components can sample, transform, or visualize. The function interprets each row of bbox according to a box mode resolved by get_boxmode(mode) and then uses the mode-specific boxes_to_corners routine to produce corner coordinates. For 2D boxes the output contains four 2D points per box; for 3D boxes the output contains eight 3D points per box. The function does not modify its inputs in-place and returns a new tensor.` |
| `monai_transforms_spatial_functional_convert_points_to_box` | `monai.transforms.spatial.functional.convert_points_to_box` | `monai/transforms/spatial/functional.py` | `points: numpy.ndarray` | `Converts a set of corner points for rectangular (2D) or cuboid (3D) regions into axis-aligned bounding boxes. This function is intended for medical imaging workflows (see MONAI README) where annotations or detections are often provided as the corner points of a rectangle in 2D or a cuboid in 3D. Given a batch of such corner points, the function computes the axis-aligned bounding box that encloses each set of corners by taking the elementwise minimum and maximum along the corner dimension and concatenating them. The result is suitable for downstream preprocessing, cropping, augmentation, or evaluation steps that expect boxes in (min_coords, max_coords) form.` |
| `monai_transforms_spatial_functional_flip` | `monai.transforms.spatial.functional.flip` | `monai/transforms/spatial/functional.py` | `img: torch.Tensor, sp_axes: tuple, lazy: bool, transform_info: dict` | `monai.transforms.spatial.functional.flip flips image data along specified spatial axes for use in MONAI preprocessing and data-augmentation pipelines for medical imaging. This function implements the flip eagerly (applies torch.flip to the tensor data) or lazily (registers a transform as metadata to be applied later in a TraceableTransform workflow) depending on the lazy flag. The function assumes channel-first tensors (channel dimension first) as used throughout MONAI transform utilities and constructs/updates an affine-like transform matrix describing the flip so downstream traceable metadata can track the spatial change.` |
| `monai_transforms_spatial_functional_orientation` | `monai.transforms.spatial.functional.orientation` | `monai/transforms/spatial/functional.py` | `img: torch.Tensor, original_affine: numpy.ndarray, spatial_ornt: numpy.ndarray, lazy: bool, transform_info: dict` | `monai.transforms.spatial.functional.orientation changes the orientation of a channel-first image tensor to the spatial orientation specified by spatial_ornt. This function is used in MONAI medical imaging pipelines to standardize or convert image voxel axis ordering and flips (for example, converting images to a canonical orientation across datasets). It supports eager execution (apply permutation and flips immediately) or lazy execution (record the transform metadata for deferred application), integrating with MONAI's MetaTensor and TraceableTransform metadata tracking.` |
| `monai_transforms_spatial_functional_rotate90` | `monai.transforms.spatial.functional.rotate90` | `monai/transforms/spatial/functional.py` | `img: torch.Tensor, axes: tuple, k: int, lazy: bool, transform_info: dict` | `Functional implementation of rotate90 used by MONAI for spatial rotations of channel-first medical image tensors. This function composes an affine rotation (90-degree increments) and optionally performs the numerical rotation on the tensor data or records the rotation lazily as transform metadata for later application. It is commonly used in preprocessing pipelines for healthcare imaging (2D slices or 3D volumes) where reproducible metadata tracking is required for downstream transforms, visualization, or inverse mapping.` |
| `monai_transforms_utils_check_boundaries` | `monai.transforms.utils.check_boundaries` | `monai/transforms/utils.py` | `boundaries: list` | `Check boundaries for Signal transforms. Validate that the provided boundaries argument is a list of exactly two float values used by MONAI Signal transforms. In the MONAI medical-imaging preprocessing domain, Signal transforms operate on 1D signals or time-series (for example, signals derived from imaging modalities or physiologic traces). This utility enforces that the transform receives a well-formed interval or pair of limits (lower and upper boundary) so downstream windowing, clipping, or scaling operations behave deterministically and consistently across a preprocessing pipeline.` |
| `monai_transforms_utils_img_bounds` | `monai.transforms.utils.img_bounds` | `monai/transforms/utils.py` | `img: numpy.ndarray` | `monai.transforms.utils.img_bounds computes the bounding indices of non-zero content along the first two axes of a NumPy array. It is intended for use in MONAI preprocessing pipelines (medical imaging) to find the first and last rows/columns (axis 0 and axis 1) that contain any foreground (non-zero) values so callers can derive a tight in-plane bounding box for cropping or centering operations. This function inspects axis 0 and axis 1 of the provided image array using numpy.any to detect non-zero elements. It returns a 1D numpy array of four integer indices: the minimum and maximum index where axis 0 contains any non-zero elements, followed by the minimum and maximum index where axis 1 contains any non-zero elements.` |
| `monai_transforms_utils_in_bounds` | `monai.transforms.utils.in_bounds` | `monai/transforms/utils.py` | `x: float, y: float, margin: float, maxx: float, maxy: float` | `monai.transforms.utils.in_bounds checks whether a 2D point (x, y) lies inside a rectangular valid region defined by a uniform border margin and the maximum coordinates. In the MONAI medical-imaging context this helper is typically used by spatial transforms and patch/ROI samplers to ensure candidate coordinates for cropping, patch extraction, or kernel placement lie within safe image boundaries.` |
| `monai_transforms_utils_is_positive` | `monai.transforms.utils.is_positive` | `monai/transforms/utils.py` | `img: numpy.ndarray` | `monai.transforms.utils.is_positive returns a boolean mask indicating which elements of a medical-image array are strictly greater than zero.` |
| `monai_transforms_utils_paste` | `monai.transforms.utils.paste` | `monai/transforms/utils.py` | `orig: numpy.ndarray, block: numpy.ndarray, loc: tuple` | `monai.transforms.utils.paste pastes a smaller numpy.ndarray block into a larger numpy.ndarray origin array at a specified location, computing appropriate slice ranges and preserving the leading channel dimension commonly used in MONAI medical imaging data. This utility is used in MONAI preprocessing and augmentation pipelines to insert image patches or sub-volumes (block) into a reference image/volume (orig) at spatial coordinates (loc), for example when reconstructing a full volume from tiled patches or applying localized edits.` |
| `monai_transforms_utils_paste_slices` | `monai.transforms.utils.paste_slices` | `monai/transforms/utils.py` | `tup: tuple` | `monai.transforms.utils.paste_slices computes two Python slice objects that specify how to paste a 1-D block (along the last axis) into a larger target volume. The function is intended for use in MONAI image-processing pipelines (PyTorch-based medical imaging workflows) when stitching or pasting extracted slices/blocks back into a full image volume: it returns the slice to select the destination region in the target and the corresponding slice to select the source region in the block so that overlapping regions are handled correctly.` |
| `monai_transforms_utils_rand_choice` | `monai.transforms.utils.rand_choice` | `monai/transforms/utils.py` | `prob: float = 0.5` | `monai.transforms.utils.rand_choice returns a boolean that is True with probability prob and False otherwise. It is intended for use in MONAI transform pipelines and data-augmentation logic to make stochastic decisions (for example, whether to apply a particular spatial or intensity augmentation during preprocessing or training of medical imaging models).` |
| `monai_transforms_utils_scale_affine` | `monai.transforms.utils.scale_affine` | `monai/transforms/utils.py` | `spatial_size: tuple, new_spatial_size: tuple, centered: bool = True` | `Compute a homogeneous affine scaling matrix that maps coordinates from an original spatial size to a new spatial size. This utility is used in MONAI preprocessing and spatial transforms for medical imaging workflows to build an (r+1) x (r+1) affine matrix that applies axis-wise scaling when an image or volume is resized. The function determines r as the maximum of the number of spatial dimensions in spatial_size and new_spatial_size, computes per-dimension scale factors as original_dim / max(new_dim, 1) to avoid division by zero, and constructs a square affine matrix suitable for homogeneous coordinate transformations used by downstream resampling and transform utilities. If centered is True (the default), the function adjusts the translation components so the scaling is performed about the image center; if False, scaling is performed about the origin/corner. The function does not modify input arguments and returns a new numeric matrix object.` |
| `monai_transforms_utils_squarepulse` | `monai.transforms.utils.squarepulse` | `monai/transforms/utils.py` | `sig: torch.Tensor, duty: float = 0.5` | `monai.transforms.utils.squarepulse computes a periodic square-wave signal from an input time-like tensor using PyTorch operations. This implementation is intended for use in MONAI workflows (medical imaging preprocessing, synthetic signal generation, or augmentation pipelines) where a reproducible, PyTorch-native square pulse is required; it reproduces the behavior of scipy.signal.square by comparing the phase against a duty cycle fraction of a 2*pi period.` |
| `monai_transforms_utils_sync_meta_info` | `monai.transforms.utils.sync_meta_info` | `monai/transforms/utils.py` | `key: str, data_dict: dict, t: bool = True` | `monai.transforms.utils.sync_meta_info: Synchronize metadata and transform trace information between a MetaTensor stored under a key in a dictionary and the corresponding separate meta and transform entries used by MONAI transform pipelines. This function is used in MONAI (a PyTorch-based medical imaging deep learning framework) preprocessing and transform pipelines to keep an image/tensor's metadata and provenance of applied transforms consistent and discoverable. It ensures that the entry at data_dict[key] (expected to be or wrapped as a monai.data.MetaTensor) and the associated meta dictionary and transform-trace entries (derived via PostFix.meta(key) and TraceableTransform.trace_key(key)) reflect the same metadata and applied_operations. This is important for downstream operations that rely on accurate medical-imaging metadata (for example spatial metadata, affine, spacing) and for reproducible transform provenance in model training, validation, or inference workflows.` |
| `monai_transforms_utils_zero_margins` | `monai.transforms.utils.zero_margins` | `monai/transforms/utils.py` | `img: numpy.ndarray, margin: int` | `monai.transforms.utils.zero_margins returns True if all values within margin indices of the edges of img along dimensions 1 and 2 are zero, otherwise returns False. This utility is intended for MONAI preprocessing and transform checks in medical imaging workflows (for example verifying zero padding or cleared borders in channel-first image arrays used with PyTorch).` |
| `monai_transforms_utils_create_transform_ims_get_2d_slice` | `monai.transforms.utils_create_transform_ims.get_2d_slice` | `monai/transforms/utils_create_transform_ims.py` | `image: numpy.ndarray, view: int, is_label: bool` | `monai.transforms.utils_create_transform_ims.get_2d_slice extracts a single 2D slice from a numpy image array. For a 2D input it returns the input unchanged; for an input with more than two dimensions it extracts the central slice along the specified axis (view) and squeezes that axis to produce a 2D array. When the image represents a label map (is_label=True), all voxel values equal to 0 are replaced with numpy.nan to mark background/no-label regions for downstream visualization or processing. This function is used in MONAI preprocessing/visualization utilities where 2D representations of 2D or 3D medical images are required (for example, rendering a central slice for inspection or debugging). It operates on numpy.ndarray objects and performs slicing and optional in-place modification of the returned array.` |
| `monai_transforms_utils_create_transform_ims_get_data` | `monai.transforms.utils_create_transform_ims.get_data` | `monai/transforms/utils_create_transform_ims.py` | `keys: list` | `monai.transforms.utils_create_transform_ims.get_data: Download a small example medical imaging dataset (MarsAtlas), run a short MONAI dictionary-based transform pipeline on the image and label files, and return the resulting spatially padded dictionary of volumes ready for example/demonstration use.` |
| `monai_transforms_utils_create_transform_ims_get_stacked_2d_ims` | `monai.transforms.utils_create_transform_ims.get_stacked_2d_ims` | `monai/transforms/utils_create_transform_ims.py` | `im: numpy.ndarray, is_label: bool` | `monai.transforms.utils_create_transform_ims.get_stacked_2d_ims: Extract the three orthogonal 2D views from a 3D medical image volume and return them as a stacked list of 2D images for downstream transforms, visualization, or model input preparation in MONAI pipelines. This function is used in MONAI pre-processing/transform utilities to produce the three orthogonal slices (one per spatial axis) from a volumetric numpy.ndarray. It calls get_2d_slice(im, i, is_label) for i in range(3) and returns the three resulting 2D images in axis order i = 0, 1, 2. The caller is expected to have ensured consistent image sizing (for example, by applying SpatialPadd earlier in a typical MONAI pipeline). The is_label flag is forwarded to get_2d_slice so that label-specific handling performed there (such as discrete processing or different interpolation rules) is preserved.` |
| `monai_transforms_utils_create_transform_ims_get_stacked_before_after` | `monai.transforms.utils_create_transform_ims.get_stacked_before_after` | `monai/transforms/utils_create_transform_ims.py` | `before: numpy.ndarray, after: numpy.ndarray, is_label: bool = False` | `monai.transforms.utils_create_transform_ims.get_stacked_before_after returns the processed (stacked) representations of the provided "before" and "after" image arrays by delegating each array to get_stacked_2d_ims. This function is used in MONAI transform/visualization pipelines for medical imaging to produce 2D visual summaries of 2D or 3D image inputs so that "before" and "after" states of a transform can be compared side-by-side or inspected.` |
| `monai_transforms_utils_create_transform_ims_pre_process_data` | `monai.transforms.utils_create_transform_ims.pre_process_data` | `monai/transforms/utils_create_transform_ims.py` | `data: dict, ndim: int, is_map: bool, is_post: bool` | `Prepare a sample dictionary for a transform that requires 2D input by optionally extracting the central slice along the last dimension and returning either the full map or a single image/label array. This helper is used by monai.transforms.utils_create_transform_ims when constructing preprocessing transforms for medical imaging pipelines in MONAI; it converts multi-dimensional medical volumes (e.g., 3D stacks) to 2D by selecting the middle index of the last axis when ndim == 2 so downstream 2D-only transforms receive an appropriate 2D input.` |
| `monai_transforms_utils_create_transform_ims_save_image` | `monai.transforms.utils_create_transform_ims.save_image` | `monai/transforms/utils_create_transform_ims.py` | `images: list, labels: list, filename: str, transform_name: str, transform_args: dict, shapes: list, colorbar: bool = False` | `Save image to file, arranging "before" and "after" views in a compact grid and ensuring there is no whitespace around the edge. This utility is intended for MONAI transform visualization in medical imaging workflows: it displays grayscale image panels (one or more orthogonal views) arranged in rows (typically two rows: before and after a transform), optionally overlays segmentation/annotation label maps, composes a human-readable transform title from transform_name and transform_args, and writes the resulting figure to the filesystem using matplotlib. The function also configures matplotlib rendering (monospace font, dark background) to produce consistent figures suitable for inclusion in reports, debugging logs, or model documentation.` |
| `monai_transforms_utils_create_transform_ims_update_docstring` | `monai.transforms.utils_create_transform_ims.update_docstring` | `monai/transforms/utils_create_transform_ims.py` | `code_path: str, transform_name: str` | `monai.transforms.utils_create_transform_ims.update_docstring: Update a MONAI transform source or documentation file to include a pointer to the transform's example image hosted in the Project-MONAI DocImages repository.` |
| `monai_transforms_utils_pytorch_numpy_unification_unravel_indices` | `monai.transforms.utils_pytorch_numpy_unification.unravel_indices` | `monai/transforms/utils_pytorch_numpy_unification.py` | `idx: list, shape: tuple` | `Compute unravelled coordinates for a sequence of flat indices and return them as a stacked NumPy array or PyTorch tensor. This utility is used in MONAI's pytorch/numpy unification helpers (monai.transforms.utils_pytorch_numpy_unification) to convert flattened indices (for example, indices produced by argmax over a flattened image or a flattened region of interest) into multi-dimensional coordinates that correspond to positions in medical imaging volumes or tensors used in MONAI transforms and post-processing.` |
| `monai_utils_component_store_is_variable` | `monai.utils.component_store.is_variable` | `monai/utils/component_store.py` | `name: str` | `Check whether a given string is a valid Python variable name and is not a reserved Python keyword. This utility is used in MONAI (a PyTorch-based framework for medical imaging deep learning) to validate candidate identifiers that may be used as variable names, attribute names, configuration keys, or registry/component names (for example when building or populating a component store of models, transforms, losses, or other reusable objects). Ensuring a name is both a valid identifier and not a keyword helps avoid syntax errors, prevents accidental shadowing of language keywords, and supports safe dynamic creation of attributes or generated code in MONAI workflows.` |
| `monai_utils_dist_string_list_all_gather` | `monai.utils.dist.string_list_all_gather` | `monai/utils/dist.py` | `strings: list[str], delimiter: str = " "` | `Utility to gather a list of Python strings from all processes in a distributed job and return the concatenated list of strings from every rank. This function is used in MONAI distributed training and utilities to share small pieces of textual information (for example file names, subject IDs, small metadata or logging messages) across multiple processes when running multi-GPU or multi-node workflows. It implements the pattern documented by PyTorch-Ignite's all_gather for strings: each rank joins its local list of strings into one long UTF-8 encoded byte sequence using a delimiter, uses a tensor-based all-gather (via ignite distributed APIs when ignite is available or native torch.distributed when initialized) and then decodes and splits the gathered byte sequences back into a flattened Python list ordered by rank (rank 0 results first, then rank 1, etc.). If no distributed backend is active (world size <= 1), the input list is returned unchanged.` |
| `monai_utils_misc_list_to_dict` | `monai.utils.misc.list_to_dict` | `monai/utils/misc.py` | `items: list` | `monai.utils.misc.list_to_dict: Convert a list of "key=value" string items into a Python dictionary suitable for simple configuration parsing in MONAI workflows (for example, parsing command-line or bundle parameter overrides used in training/evaluation pipelines). This function accepts a sequence of text tokens where each token is expected to represent either a bare key ("a") or a key/value assignment ("key=value"). It is commonly used in MONAI to convert simple string-based parameter specifications into native Python types so they can be applied to configuration dictionaries for model training, inference, or pre-/post-processing pipelines. Behavior: - Each element in items is split at the first "=" into a key and a value. If an element contains no "=", the value for that key becomes None. This supports shorthand flags or presence indicators. - Surrounding whitespace and single-quote characters are removed from both keys and values by stripping the characters " '". - After splitting and stripping, the function attempts to convert the textual value to a native Python object using ast.literal_eval (so numeric literals, lists, dicts, tuples, and quoted strings will become their Python equivalents). - If ast.literal_eval raises a ValueError, the function then attempts to interpret the value as a boolean using distutils.util._strtobool; if that succeeds the boolean value is returned. - If both conversions fail, the original stripped string is used as the value. - Duplicate keys are considered an error: the function raises KeyError when the same key is encountered more than once. - If items is an empty list (no elements), an empty dictionary is returned. Limitations and failure modes: - The parameter type is list; passing a non-list is not documented and may lead to unexpected behavior. An empty list yields {}. - ast.literal_eval exceptions other than ValueError (for example, SyntaxError) are not explicitly caught by the implementation and will propagate to the caller. - The boolean conversion relies on distutils.util._strtobool semantics; values not recognized by that helper will not be converted to booleans and will fall back to the raw string. - Keys and values have only the characters " '" stripped; other surrounding characters are preserved.` |
| `monai_utils_module_damerau_levenshtein_distance` | `monai.utils.module.damerau_levenshtein_distance` | `monai/utils/module.py` | `s1: str, s2: str` | `Calculates the Damerauâ€“Levenshtein distance between two strings, returning the minimum number of single-character edits (insertions, deletions, substitutions, or adjacent transpositions) required to transform s1 into s2. In the MONAI context this routine is used for spelling correction and string similarity tasks that arise in medical-imaging workflows (for example, normalizing metadata keys, matching label names, correcting typographical errors in annotations or clinical text before model training and analysis). This implementation follows the Damerauâ€“Levenshtein definition (see https://en.wikipedia.org/wiki/Damerauâ€“Levenshtein_distance) and is designed to be a small, dependency-free utility for preprocessing and validation steps in MONAI pipelines. It performs an exact computation using a dynamic programming table (implemented as a dict) and treats an adjacent transposition of two characters as a single edit operation.` |
| `monai_utils_module_get_package_version` | `monai.utils.module.get_package_version` | `monai/utils/module.py` | `dep_name: str, default: str = "NOT INSTALLED or UNKNOWN VERSION."` | `Get the installed version string for a given Python package name, or return a provided default message when the package is not available or does not expose a version. This function is used throughout MONAI (a PyTorch-based framework for medical imaging AI) to detect and report versions of optional or required third-party packages (for example, imaging libraries, dataset handlers, or utilities). It attempts to import the package by name and then read its __version__ attribute. The practical significance is to enable reproducible experiments, compatibility checks, diagnostic messages, and runtime guards within MONAI code paths that depend on specific dependency versions.` |
| `monai_utils_module_parse_version_strs` | `monai.utils.module.parse_version_strs` | `monai/utils/module.py` | `lhs: str, rhs: str` | `monai.utils.module.parse_version_strs parses two version strings and returns two iterables of their parsed components (integers for numeric leading segments, otherwise strings). This helper is intended for basic version-component extraction used in MONAI workflows such as comparing package, dependency, or model-bundle version identifiers when deciding compatibility or branching behavior in medical imaging pipelines. It implements a minimal, packaging-independent strategy: remove any git-style build metadata after "+" and split on "."; each segment is stripped of surrounding whitespace and, if it begins with decimal digits, those leading digits are converted to an int while any trailing non-digit suffix in that segment is discarded.` |
| `monai_utils_module_version_geq` | `monai.utils.module.version_geq` | `monai/utils/module.py` | `lhs: str, rhs: str` | `Returns True if version `lhs` is later than or equal to version `rhs` according to a best-effort comparison of version strings used by MONAI to gate features and enforce dependency compatibility (for example, checking PyTorch or other package versions before enabling code paths). The function first normalizes inputs by casting them to Python strings, then attempts to use the packaging.version.Version class when available for a robust semantic comparison. If packaging.version is unavailable, it falls back to an element-wise comparison produced by parse_version_strs. This function is therefore useful within MONAI to programmatically decide whether the running environment satisfies a minimum or specific version requirement without raising on common invalid-version formats (it prefers a permissive result in that case).` |
| `monai_utils_module_version_leq` | `monai.utils.module.version_leq` | `monai/utils/module.py` | `lhs: str, rhs: str` | `monai.utils.module.version_leq determines whether one version string (lhs) denotes an earlier or equal release than another version string (rhs). This function is used within MONAI for simple dependency and compatibility checks (for example, to determine whether a runtime or dependency version such as PyTorch satisfies a minimum or maximum required version). It accepts arbitrary inputs but first coerces them to Python str. It attempts to use the standard packaging.version.Version objects for robust semantic version comparison when the packaging library is available; if packaging.version is not available it falls back to a deterministic, segment-wise textual/numeric comparison implemented by parse_version_strs. Behavior details and practical significance: - The function returns True when lhs represents a version earlier than or equal to rhs, and False when lhs represents a later version than rhs. This boolean result is suitable for gating feature availability or enforcing dependency constraints in MONAI workflows. - Inputs are coerced to strings at the start (lhs and rhs are converted via str(lhs) and str(rhs)), so callers may pass objects that implement __str__. - When the optional packaging.version module is present (imported via optional_import), the function constructs packaging.version.Version(lhs) and packaging.version.Version(rhs) and returns the result of the <= operator on those Version objects. This provides standard semantic-version semantics when available and is the preferred comparison path. - If packaging.version.Version raises packaging.version.InvalidVersion for the provided strings, the implementation treats this as a conservative success and returns True. This behavior avoids blocking execution for unknown or nonstandard version formats when attempting to ensure compatibility in MONAI environments. - If packaging.version is not available (optional_import indicates absence), the function uses parse_version_strs(lhs, rhs) as a fallback. In the fallback: - The two version strings are parsed into corresponding sequences of segments (as returned by parse_version_strs). - The function iterates segment-wise over zipped segments from both sequences. For the first pair of unequal segments: - If both segments are integers, they are compared numerically (l < r). - Otherwise, the segments are compared lexicographically as strings (f"{l}" < f"{r}"). - If all compared segments are equal for the length of the shorter parsed sequence, the function returns True. Practically, this means versions that are identical up to the shorter prefix are considered earlier-or-equal (for example, "1.2" is treated as <= "1.2.0" in the fallback logic). - The function has no side effects: it does not perform I/O, modify global state, or change its arguments. It is deterministic for the same inputs and available environment (presence or absence of packaging.version). Failure modes and error handling: - The function never intentionally raises exceptions for normal comparison of strings. If packaging.version is available but either lhs or rhs cannot be parsed into a valid packaging.version.Version, packaging.version.InvalidVersion is caught and the function returns True. - If parse_version_strs is unable to parse the provided strings and itself raises an exception, that exception will propagate; callers who expect to handle malformed custom version formats may need to validate inputs or handle exceptions from parse_version_strs. - The function does not validate that inputs conform to any specific versioning scheme beyond what packaging.version or parse_version_strs accept.` |
| `monai_utils_type_conversion_dtype_numpy_to_torch` | `monai.utils.type_conversion.dtype_numpy_to_torch` | `monai/utils/type_conversion.py` | `dtype: numpy.dtype` | `Convert a numpy dtype to the corresponding torch dtype used for PyTorch tensors in MONAI pipelines. This utility is used throughout MONAI to map numpy array data types (for example, from image pre-processing or data loading steps) to the torch.dtype that should be used when creating or interpreting PyTorch tensors for model input, loss computation, and other deep-learning operations in medical imaging workflows.` |
| `monai_utils_type_conversion_get_numpy_dtype_from_string` | `monai.utils.type_conversion.get_numpy_dtype_from_string` | `monai/utils/type_conversion.py` | `dtype: str` | `monai.utils.type_conversion.get_numpy_dtype_from_string: Return a numpy.dtype object corresponding to a dtype name provided as a string. This utility is used in the MONAI medical-imaging deep learning codebase to convert textual dtype specifications found in configuration, metadata, or serialized bundle files into concrete numpy dtype objects (for example to allocate numpy arrays, cast data for preprocessing pipelines, or interoperate with PyTorch tensors).` |
| `monai_utils_type_conversion_get_torch_dtype_from_string` | `monai.utils.type_conversion.get_torch_dtype_from_string` | `monai/utils/type_conversion.py` | `dtype: str` | `Get a torch.dtype corresponding to a textual dtype name. This function is used in MONAI to convert a textual dtype identifier commonly found in configuration files, model/bundle metadata, or user-supplied parameters into a PyTorch dtype object that can be applied when creating tensors, models, or performing dtype-sensitive operations in medical imaging deep learning workflows. The function implements this by delegating to two helpers: it first parses the input string into a numpy.dtype via get_numpy_dtype_from_string and then maps that numpy dtype to the equivalent torch.dtype via dtype_numpy_to_torch. Typical input strings are the Numpy-style dtype names such as "float32" or "int64"; for example, passing "float32" produces torch.float32. This function has no side effects beyond performing the conversion.` |

## âš–ï¸ License

Original Code License: Apache-2.0

Wrapper Code & Documentation: Apache-2.0

*This file was automatically generated on February 26, 2026.*
