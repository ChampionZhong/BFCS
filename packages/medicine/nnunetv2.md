# nnunetv2

[üîô Back to Main Repo](../../../README.md) | [üîó Original Repo](https://github.com/MIC-DKFZ/nnUNet)

![Tool Count](https://img.shields.io/badge/Agent_Tools-20-blue?style=flat-square)
![Category](https://img.shields.io/badge/Category-Medicine-green?style=flat-square)
![Status](https://img.shields.io/badge/Import_Test-Passed-success?style=flat-square)

## üìñ Overview

`nnunetv2` is an automated U-Net‚Äìbased deep learning framework for biomedical image semantic segmentation that analyzes your dataset and configures an appropriate training and inference pipeline with minimal manual tuning.

> **Note**: This documentation lists the **agent-ready wrapper functions** generated for this package. These functions have been strictly typed, docstring-enhanced, and tested for import stability within a standardized Apptainer environment.

## üõ†Ô∏è Available Agent Tools

Below is the list of **20** functions optimized for LLM tool-use.

| **Tool Name (Wrapper)**   | **Source**          | **File Path**     | **Arguments (Type)**        | **Description**                |
| ------------------------- | ------------------- | ----------------- | --------------------------- | ------------------------------ |
| `nnunetv2_dataset_conversion_Dataset042_BraTS18_convert_folder_with_preds_back_to_BraTS_labeling_convention` | `nnunetv2.dataset_conversion.Dataset042_BraTS18.convert_folder_with_preds_back_to_BraTS_labeling_convention` | `nnunetv2/dataset_conversion/Dataset042_BraTS18.py` | `input_folder: str, output_folder: str, num_processes: int = 12` | `Converts all nifti prediction files in a folder to the BraTS (BraTS18) labeling convention and writes the converted nifti files to an output folder. This function is used in the nnU-Net dataset conversion utilities to take model prediction outputs (nifti files, typically generated by nnU-Net inference) and transform their label encoding back to the labeling convention required by the Brain Tumor Segmentation (BraTS) 2018 challenge. It locates all files in input_folder with the suffix ".nii.gz", ensures output_folder exists, and then runs the conversion in parallel using a multiprocessing pool. The actual per-file conversion is delegated to load_convert_labels_back_to_BraTS; filenames (basenames) discovered by subfiles (join=False) are passed together with input_folder and output_folder to that worker function. This function enables preparing predicted segmentations for evaluation or submission to BraTS-style benchmarks and for downstream analyses that expect BraTS label semantics.` |
| `nnunetv2_dataset_conversion_Dataset043_BraTS19_convert_folder_with_preds_back_to_BraTS_labeling_convention` | `nnunetv2.dataset_conversion.Dataset043_BraTS19.convert_folder_with_preds_back_to_BraTS_labeling_convention` | `nnunetv2/dataset_conversion/Dataset043_BraTS19.py` | `input_folder: str, output_folder: str, num_processes: int = 12` | `nnunetv2.dataset_conversion.Dataset043_BraTS19.convert_folder_with_preds_back_to_BraTS_labeling_convention converts all prediction NIfTI files in a folder to the BraTS labeling convention and writes the converted files to a target folder. This function is used in the nnU-Net dataset conversion utilities to postprocess model prediction outputs for the BraTS (Brain Tumor Segmentation) domain so that labels follow the BraTS challenge / dataset labeling convention expected by downstream evaluation and analysis. It reads every file with the suffix ".nii.gz" found in input_folder, invokes the module-level helper load_convert_labels_back_to_BraTS on each file to perform the label mapping back to the BraTS convention, and saves the converted NIfTI files into output_folder. The function creates output_folder if it does not exist, and it processes files in parallel using Python's multiprocessing (spawn start method) to improve throughput for large prediction sets.` |
| `nnunetv2_dataset_conversion_Dataset137_BraTS21_convert_folder_with_preds_back_to_BraTS_labeling_convention` | `nnunetv2.dataset_conversion.Dataset137_BraTS21.convert_folder_with_preds_back_to_BraTS_labeling_convention` | `nnunetv2/dataset_conversion/Dataset137_BraTS21.py` | `input_folder: str, output_folder: str, num_processes: int = 12` | `Convert all NIfTI prediction files in input_folder to the BraTS21 labeling convention and save the converted files to output_folder. This function is part of the dataset conversion utilities for the nnU-Net V2 project and is used when working with the BraTS (Brain Tumor Segmentation) dataset variant BraTS21. In practical use, nnU-Net prediction outputs (segmentation label volumes in NIfTI format, .nii.gz) are sometimes produced with internal label ids that differ from the BraTS challenge labeling convention. This function automates reading those prediction files, converting their label ids back to the convention expected by BraTS21 (so that downstream evaluation or submission to BraTS21-compatible tools is correct), and writing the converted NIfTI files to a specified output directory. The conversion work for each file is delegated to load_convert_labels_back_to_BraTS in parallel worker processes.` |
| `nnunetv2_dataset_conversion_Dataset218_Amos2022_task1_convert_amos_task1` | `nnunetv2.dataset_conversion.Dataset218_Amos2022_task1.convert_amos_task1` | `nnunetv2/dataset_conversion/Dataset218_Amos2022_task1.py` | `amos_base_dir: str, nnunet_dataset_id: int = 218` | `Convert AMOS2022 Task 1 (post-challenge) into the nnU-Net v2 raw dataset folder structure and metadata, with the AMOS validation set merged into the training set. This function is used within the dataset conversion stage of nnU-Net to prepare the AMOS2022 dataset for training and cross-validation in the nnU-Net pipeline (see documentation/dataset_format.md). The conversion enforces selection of CT cases only (based on the numeric suffix of case identifiers), creates the required nnU-Net raw subfolders (imagesTr, imagesTs, labelsTr), copies and renames image and label files into the nnU-Net expected naming scheme, and generates a dataset.json describing modalities and label mappings so that nnU-Net can automatically configure segmentation pipelines and run 5-fold cross-validation.` |
| `nnunetv2_dataset_conversion_Dataset219_Amos2022_task2_convert_amos_task2` | `nnunetv2.dataset_conversion.Dataset219_Amos2022_task2.convert_amos_task2` | `nnunetv2/dataset_conversion/Dataset219_Amos2022_task2.py` | `amos_base_dir: str, nnunet_dataset_id: int = 219` | `Converts the AMOS2022 task2 dataset (post-challenge release) into the nnU-Net raw dataset layout so it can be used by nnU-Net training and 5-fold cross-validation pipelines. This function is used in the nnU-Net dataset conversion stage (see README -> "Dataset conversion") to transform the AMOS2022 directory and dataset.json into the folder structure, filenames and dataset.json format expected by nnU-Net. It also incorporates the AMOS validation cases into the nnU-Net training set (AMOS does not specify how validation should be used), which enables nnU-Net's recommended 5-fold cross-validation instead of a single train/val split.` |
| `nnunetv2_dataset_conversion_convert_raw_dataset_from_old_nnunet_format_convert` | `nnunetv2.dataset_conversion.convert_raw_dataset_from_old_nnunet_format.convert` | `nnunetv2/dataset_conversion/convert_raw_dataset_from_old_nnunet_format.py` | `source_folder: str, target_dataset_name: str` | `nnunetv2.dataset_conversion.convert_raw_dataset_from_old_nnunet_format.convert converts a dataset organized in the old nnU-Net (v1) task layout (commonly named TaskXXX_YYY with directories like imagesTr and labelsTr and a dataset.json that uses keys such as "modality" and "labels") into the nnunetv2 raw dataset layout under the global nnUNet_raw directory (datasets in v2 are typically called DatasetXXX_YYY). This function is used when migrating datasets created for the old nnU-Net to the nnunetv2 expected raw format so they can be processed by nnU-Net V2 preprocessing and training pipelines.` |
| `nnunetv2_evaluation_evaluate_predictions_save_summary_json` | `nnunetv2.evaluation.evaluate_predictions.save_summary_json` | `nnunetv2/evaluation/evaluate_predictions.py` | `results: dict, output_file: str` | `Save a JSON summary of evaluation metrics for nnU-Net prediction runs, converting any non-JSON-friendly keys (notably tuple keys used to represent labels or regions) into string keys before writing. This function is used in the nnU-Net evaluation pipeline to persist aggregated and per-case metrics produced when evaluating segmentation predictions. In the nnU-Net domain (biomedical semantic segmentation), metric dictionaries often use tuples to represent composite label/region identifiers; JSON does not allow non-string mapping keys, so this function performs a deterministic conversion of those keys and writes a deep-copied summary to disk. The function expects the results dictionary to contain a 'mean' mapping of metrics aggregated across cases and a 'metric_per_case' list where each entry contains a 'metrics' mapping for that case. It converts keys in results['mean'] and in each results['metric_per_case'][i]['metrics'] by applying the repository's label_or_region_to_key conversion helper, then writes the converted structure using save_json with sort_keys=True (so that keys such as "foreground_mean" appear first and the output ordering is stable).` |
| `nnunetv2_evaluation_find_best_configuration_dumb_trainer_config_plans_to_trained_models_dict` | `nnunetv2.evaluation.find_best_configuration.dumb_trainer_config_plans_to_trained_models_dict` | `nnunetv2/evaluation/find_best_configuration.py` | `trainers: List[str], configs: List[str], plans: List[str]` | `nnunetv2.evaluation.find_best_configuration.dumb_trainer_config_plans_to_trained_models_dict: Create a deterministic enumeration of trained-model descriptors by taking the Cartesian product of the provided trainer identifiers, configuration names, and plan identifiers. This helper is used in the evaluation pipeline to produce a simple list of candidate trained-model specifications that downstream code (for example: model lookup, evaluation, or selection logic in find_best_configuration) can iterate over when empirically determining the best U-Net configuration for a dataset. The name "dumb" reflects that this function performs no validation, filtering, or existence checks ‚Äî it only composes the inputs into dictionaries.` |
| `nnunetv2_experiment_planning_experiment_planners_network_topology_get_pool_and_conv_props` | `nnunetv2.experiment_planning.experiment_planners.network_topology.get_pool_and_conv_props` | `nnunetv2/experiment_planning/experiment_planners/network_topology.py` | `spacing: list, patch_size: list, min_feature_map_size: int, max_numpool: int` | `get_pool_and_conv_props computes per-axis pooling and convolution kernel configurations used by nnU-Net's automatic network topology planner. This function analyzes image spacing and patch size to decide how many downsampling (pooling) operations to perform along each axis, which axes to pool together at each stage, and which convolution kernel sizes to use at each network stage. It mirrors the behavior of get_pool_and_conv_props_v2 from the old nnU-Net implementation and is used during experiment planning to generate a U-Net topology that respects voxel anisotropy, a minimum feature map size in the bottleneck, and a maximum number of pooling operations per axis.` |
| `nnunetv2_experiment_planning_experiment_planners_network_topology_pad_shape` | `nnunetv2.experiment_planning.experiment_planners.network_topology.pad_shape` | `nnunetv2/experiment_planning/experiment_planners/network_topology.py` | `shape: tuple, must_be_divisible_by: list` | `Compute a padded spatial shape such that each dimension is divisible by the corresponding divisibility factor. This function is used during nnU-Net experiment planning (experiment_planning.experiment_planners.network_topology) to ensure patch sizes and image shapes are compatible with U-Net downsampling/pooling schedules and other topology rules: the returned shape is the minimal shape greater than or equal to the input shape for which each axis length is a multiple of the requested divisor.` |
| `nnunetv2_experiment_planning_plan_and_preprocess_api_extract_fingerprints` | `nnunetv2.experiment_planning.plan_and_preprocess_api.extract_fingerprints` | `nnunetv2/experiment_planning/plan_and_preprocess_api.py` | `dataset_ids: List[int], fingerprint_extractor_class_name: str = "DatasetFingerprintExtractor", num_processes: int = 8, check_dataset_integrity: bool = False, clean: bool = True, verbose: bool = True` | `nnunetv2.experiment_planning.plan_and_preprocess_api.extract_fingerprints Extract dataset fingerprints for one or more nnU-Net datasets and persist them for use by the experiment planning pipeline. This function automates the dataset analysis step described in the nnU-Net README: it computes a "dataset fingerprint" for each dataset id provided (an analysis of image sizes, spacings, modalities, class balance and other dataset properties). Those fingerprints are used by nnU-Net's rule-based experiment planning to configure architecture topology, patch sizes, batch sizes and other pipeline parameters automatically. The function locates a fingerprint extractor class implementation by name inside the nnunetv2.experiment_planning package, instantiates/uses it (via recursive class lookup) and then invokes the per-dataset extractor routine extract_fingerprint_dataset for every id in dataset_ids. This operation performs file IO and dataset analysis and therefore can be CPU- and disk-intensive; it may run work in parallel using multiple processes.` |
| `nnunetv2_experiment_planning_verify_dataset_integrity_verify_dataset_integrity` | `nnunetv2.experiment_planning.verify_dataset_integrity.verify_dataset_integrity` | `nnunetv2/experiment_planning/verify_dataset_integrity.py` | `folder: str, num_processes: int = 8` | `nnunetv2.experiment_planning.verify_dataset_integrity.verify_dataset_integrity: Verify that a dataset folder is correctly structured and internally consistent for use with nnU-Net's automatic experiment planning and preprocessing. This function performs file-system and content-level checks that prevent common dataset preparation mistakes that would cause downstream failures during nnU-Net pipeline generation, training, or inference. Performs the following concrete checks and actions (practical significance: ensures the dataset adheres to nnU-Net expectations so automatic configuration, preprocessing and training can proceed without subtle errors): - Requires a dataset.json file in folder and validates presence of required metadata keys. This is critical because nnU-Net's planner and readers rely on dataset.json to know modalities, label mappings, file endings and the expected number of training cases. - If dataset.json contains a top-level "dataset" key, the function expects dataset.json to list explicit image and label file paths and checks that each referenced image and label file exists. This mode is used when dataset.json fully enumerates file locations. - If the "dataset" key is absent (legacy layout), the function requires imagesTr and labelsTr subfolders and checks that a label file exists for every training case reported in dataset.json. This preserves backwards compatibility with the common nnU-Net folder layout. - Validates that dataset.json contains the required keys ['labels', 'channel_names', 'numTraining', 'file_ending'] and reports which keys are missing or unused. This prevents mis-specified metadata that would break label interpretation and I/O. - Computes expected_num_training from dataset_json['numTraining'] and compares it to the number of discovered training cases. Mismatch indicates mis-specified dataset.json or missing files. - Determines num_modalities from dataset_json['channel_names'] (or legacy 'modality') to validate that image files contain the expected number of channels/modalities; this prevents errors where readers load images with unexpected channel counts. - Uses get_filenames_of_train_images_and_targets to construct the mapping from case identifiers to image file paths and label file paths. - Instantiates LabelManager(dataset_json['labels'], regions_class_order=dataset_json.get('regions_class_order')) to derive the expected label set. If LabelManager reports an ignore label, that label is included in the allowed label set. Enforces that label values are strictly consecutive (0, 1, 2, ...) because nnU-Net expects consecutive label numbering for consistent region handling. - Determines the appropriate reader/writer class by calling determine_reader_writer_from_dataset_json(dataset_json, sample_image_path) to ensure file I/O uses the correct backend (practical significance: supports different image formats and metadata readers supported by nnU-Net). - In a multiprocessing spawn Pool (num_processes workers), calls verify_labels on every label file with the determined reader/writer class and the expected label set to detect unexpected label values in segmentation images. Unexpected labels cause a RuntimeError and list the offending files. - In the same multiprocessing pool, calls check_cases for each case to validate that image and label shapes, voxel spacings and other spatial metadata are compatible (pixel/voxel grid alignment). Mismatches cause a RuntimeError and identify problematic cases. - Prints a short confirmation banner on successful completion to indicate that no integrity errors were detected. Failure modes and exceptions (how the function signals problems and what they mean): - AssertionError is raised early for missing dataset.json, missing mandatory keys in dataset.json, missing imagesTr/labelsTr folders in legacy mode, or non-consecutive labels. These indicate structural or metadata problems that must be corrected before planning. - FileNotFoundError is raised when dataset.json enumerates file paths (via the "dataset" key) but referenced image or label files are missing. The exception message includes lists of missing image and label paths for debugging. - RuntimeError is raised when verify_labels or check_cases detect content-level problems: unexpected label values in segmentation images or mismatched shapes/spacings between images and labels. The RuntimeError messages prompt inspection of printed output to find offending files. - Other I/O or reader-specific exceptions may be raised by the underlying reader/writer class when reading files; these propagate and indicate problematic files or unsupported formats. Performance and resource notes: - The default num_processes is 8. The function uses multiprocessing.get_context("spawn").Pool(num_processes) to parallelize label and image checks; "spawn" is explicitly chosen to avoid forking issues with certain readers and libraries. Reduce num_processes on machines with limited CPU or memory to avoid excessive resource contention. - The function performs read-only checks except for printing to stdout; it does not modify dataset files or metadata.` |
| `nnunetv2_preprocessing_cropping_cropping_create_nonzero_mask` | `nnunetv2.preprocessing.cropping.cropping.create_nonzero_mask` | `nnunetv2/preprocessing/cropping/cropping.py` | `data: numpy.ndarray` | `nnunetv2.preprocessing.cropping.cropping.create_nonzero_mask: Create a boolean foreground mask for cropping by marking spatial voxels/pixels where any input channel is nonzero and filling interior holes.` |
| `nnunetv2_preprocessing_cropping_cropping_crop_to_nonzero` | `nnunetv2.preprocessing.cropping.cropping.crop_to_nonzero` | `nnunetv2/preprocessing/cropping/cropping.py` | `data: numpy.ndarray, seg: numpy.ndarray = None, nonzero_label: int = -1` | `nnunetv2.preprocessing.cropping.cropping.crop_to_nonzero crops an image volume (and an optional segmentation) to the minimal axis-aligned bounding box that contains all nonzero voxels in the input image data. This function is used in nnU-Net preprocessing to reduce memory use and accelerate downstream processing by removing empty background regions while preserving the channel (first) axis ordering expected by nnU-Net pipelines. The function relies on the helper functions create_nonzero_mask, get_bbox_from_mask and bounding_box_to_slice to compute the mask, bounding box and corresponding slicer.` |
| `nnunetv2_preprocessing_normalization_map_channel_name_to_normalization_get_normalization_scheme` | `nnunetv2.preprocessing.normalization.map_channel_name_to_normalization.get_normalization_scheme` | `nnunetv2/preprocessing/normalization/map_channel_name_to_normalization.py` | `channel_name: str` | `nnunetv2.preprocessing.normalization.map_channel_name_to_normalization.get_normalization_scheme returns the ImageNormalization class that should be used to normalize intensities for a given input channel name in the nnU-Net preprocessing pipeline. This function maps a human-readable channel identifier (for example modality identifiers encountered in biomedical imaging such as CT or MR, or other channel names produced when converting a dataset to the nnU-Net format) to a concrete normalization scheme class defined in nnunetv2.preprocessing.normalization.default_normalization_schemes. The chosen class is intended to be used by the preprocessing stage of nnU-Net to standardize image intensities before training or inference, which is critical for robust segmentation across diverse datasets as described in the nnU-Net README.` |
| `nnunetv2_training_dataloading_utils_unpack_dataset` | `nnunetv2.training.dataloading.utils.unpack_dataset` | `nnunetv2/training/dataloading/utils.py` | `folder: str, unpack_segmentation: bool = True, overwrite_existing: bool = False, num_processes: int = 8, verify: bool = False` | `Unpack all .npz files in a dataset folder into .npy arrays using a multiprocessing pool. This function is part of the nnU-Net v2 data preparation utilities and is used to convert dataset archives produced during dataset conversion or preprocessing into the flat numpy (.npy) files that the nnU-Net dataloading pipeline expects at training time. It locates all files with the .npz extension under the provided folder, and invokes the internal converter (_convert_to_npy) in parallel across multiple worker processes (multiprocessing.get_context("spawn").Pool). Typical use is to run this after dataset conversion so that the nnU-Net training dataloader can read per-sample numpy arrays instead of compressed archives, improving I/O patterns and integration with the rest of the preprocessing/training pipeline.` |
| `nnunetv2_training_loss_dice_get_tp_fp_fn_tn` | `nnunetv2.training.loss.dice.get_tp_fp_fn_tn` | `nnunetv2/training/loss/dice.py` | `net_output: torch.Tensor, gt: torch.Tensor, axes: tuple = None, mask: torch.Tensor = None, square: bool = False` | `get_tp_fp_fn_tn(net_output, gt, axes=None, mask=None, square=False) Summary: Compute per-class true positives (TP), false positives (FP), false negatives (FN) and true negatives (TN) from network outputs and ground-truth labels for semantic segmentation tasks used in nnU-Net. This function is intended for probabilistic network outputs (soft predictions) and one-hot / label-map ground truth as produced or consumed by nnU-Net training and evaluation pipelines. It is useful for building Dice-like losses, metric computation, and any other logic that requires soft-counts of TP/FP/FN/TN aggregated over specified axes (for example spatial dimensions). Detailed behavior: net_output is treated as the model prediction for each class/channel and is multiplied with a derived one-hot ground-truth mask to obtain soft TP/FP/FN/TN contributions: TP = net_output * y_onehot FP = net_output * (~y_onehot) FN = (1 - net_output) * y_onehot TN = (1 - net_output) * (~y_onehot) This formulation treats net_output as the probability (or soft score) assigned to each class/channel; therefore values outside the interval [0, 1] will lead to unintuitive or invalid interpretations (e.g., negative FN/TN) and are not recommended. The one-hot encoding of ground truth is created without gradient tracking to save memory; subsequent multiplications with net_output will produce gradients only with respect to net_output (so gradients flow as expected into the network outputs). If mask is provided, it is broadcasted/tiled over the channel dimension and spatial dimensions and applied multiplicatively to TP/FP/FN/TN. This masks out invalid voxels/pixels (mask value 1 = valid, 0 = invalid) which is important in biomedical imaging pipelines (for example when ignoring padded regions or regions outside the field-of-view). If square is True, TP/FP/FN/TN are squared elementwise prior to any summation. This option can be used to implement squared-error style contributions or to change the emphasis of large errors before aggregation. The axes argument controls which dimensions are summed away. By default (axes is None) the function will sum across all spatial dimensions (i.e., all dims except batch and channel) which yields per-batch-per-class aggregated counts (shape typically (b, c)). If axes is an empty tuple () no summation is performed and the returned tensors keep the full shape of net_output (after any one-hot conversion). The device and final dtype follow the arithmetic: typically the returned tensors live on the same device as net_output and have a floating dtype derived from net_output.` |
| `nnunetv2_utilities_collate_outputs_collate_outputs` | `nnunetv2.utilities.collate_outputs.collate_outputs` | `nnunetv2/utilities/collate_outputs.py` | `outputs: List[dict]` | `nnunetv2.utilities.collate_outputs.collate_outputs: Collate a list of per-step output dictionaries produced by nnU-Net training/validation steps into a single dictionary that aggregates values across the list. This function is used by the default train_step and validation_step implementations in nnU-Net to combine outputs (for example per-batch losses, numpy prediction arrays, or lists of identifiers) from multiple executions into a single structure suitable for epoch-level logging, metric computation, or further postprocessing in the semantic segmentation training pipeline. This collator expects a homogeneous list of dictionaries where each dictionary has the same keys and the same kind of value for each key. It is intentionally minimal: it handles three specific value types in a reproducible way and raises an error for other types. It performs no in-place modification of the input list; it returns a newly constructed dictionary. Because nnU-Net is applied to biomedical image segmentation tasks, typical use-cases include collating per-batch scalar losses into a list of loss values, stacking numpy prediction arrays into a batch axis for metric computation, or concatenating lists of case identifiers or file names produced during validation.` |
| `nnunetv2_utilities_overlay_plots_select_slice_to_plot` | `nnunetv2.utilities.overlay_plots.select_slice_to_plot` | `nnunetv2/utilities/overlay_plots.py` | `image: numpy.ndarray, segmentation: numpy.ndarray` | `nnunetv2.utilities.overlay_plots.select_slice_to_plot selects a representative axial slice index from a 3D segmentation volume for visualization (overlay) by finding the slice that contains the largest amount of foreground voxels. This function is used in the nnU-Net visualization utilities to pick a single 2D slice from a 3D case (for example, a CT or MRI volume) so that overlays of model predictions and image intensities show the most content-bearing slice. The image parameter is accepted to preserve a stable API and allow future replacement logic that may use image intensities; in the current implementation image is not used.` |
| `nnunetv2_utilities_overlay_plots_select_slice_to_plot2` | `nnunetv2.utilities.overlay_plots.select_slice_to_plot2` | `nnunetv2/utilities/overlay_plots.py` | `image: numpy.ndarray, segmentation: numpy.ndarray` | `nnunetv2.utilities.overlay_plots.select_slice_to_plot2 selects a single slice index (along the first axis) from a 3D image/segmentation pair for visualization. It is intended for nnU-Net overlay plotting utilities to choose a representative 2D slice that contains the largest amount of foreground across all non-background classes (useful when creating overlay plots of predicted or ground-truth segmentations for medical image segmentation tasks).` |

## ‚öñÔ∏è License

Original Code License: Apache-2.0

Wrapper Code & Documentation: Apache-2.0

*This file was automatically generated on February 26, 2026.*
